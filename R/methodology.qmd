---
title: "Methodology"
author: 
  - Jolyon Miles-Wilson
  - Celestin Okoroji
date: "`r format(Sys.time(), '%e %B %Y')`"
always_allow_html: true
format: 
  html:
    page-layout: full
    self-contained: true
    code-fold: true
    code-tools: true
    code-summary: "Code"
    toc: true
    toc-depth: 5
  docx:  # or use `word:` – both work
    toc: true
    toc-depth: 5
execute: 
  echo: false
  warning: false
number-sections: true


---

```{r packages}
library(haven)
library(poLCA)
library(Hmisc)
library(dplyr)
library(ggplot2)
library(tidyr)
library(skimr)
library(kableExtra)
#library(MASS)
library(wesanderson)
library(ggrepel)
library(here)
library(emmeans)
#library(devtools)
#install_version("sjstats", version = "0.18.2")
library(sjstats)
library(readr)
library(sjPlot)
library(nnet)
library(apaTables)
library(survey)
library(svyVGAM)
library(aod)
library(stringr)
library(future)
library(future.apply)
```

```{r palette}
rm(list = ls())
options(scipen = 999)
colours <- wes_palette("GrandBudapest2",4,"discrete")
better_colours <- c('#8dd3c7','#bebada','#fb8072','#80b1d3','#fdb462')
many_colours <- c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a','#ffff99','#b15928','#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69','#fccde5','#d9d9d9','#bc80bd','#ccebc5','#ffed6f')
```

```{r functions}
extract_glm_coefs <- function(mod, only_sig=F, decimal_places = 3){
  coefs <- coef(summary(mod)) 
  if(only_sig==T){
    coefs <- coefs[which(coefs[,4] < .05),]
  }
  coefs <- as_tibble(coefs, rownames="variable") %>% # specify new variable to add rownames to 
    mutate(
    or = round(exp(Estimate), decimal_places), .after=Estimate
    )
}

extract_lm_coefs <- function(mod, only_sig = F){
  coefs <- coef(summary(mod)) 
  if(only_sig==T){
    coefs <- coefs[which(coefs[,4] < .05),]
  }
  coefs <- as_tibble(coefs, rownames="variable") # specify new variable to add rownames to 
}

get_pvalue <- function(model){
  f_value <- summary(model)$fstatistic
  p_value <- pf(f_value['value'], f_value['numdf'], f_value['dendf'], lower.tail = F)
  attributes(p_value) <- NULL
  return(p_value)
}


# Modified from https://tech.popdata.org/pma-data-hub/posts/2021-08-15-covid-analysis/

tidy.svyVGAM <- function(
  x, 
  conf.int = FALSE, 
  conf.level = 0.95,
  exponentiate = FALSE, 
  ...
){
  ret <- as_tibble(summary(x)$coeftable, rownames = "term")
  colnames(ret) <- c("term", "estimate", "std.error", "statistic", "p.value")
  coefs <- tibble::enframe(stats::coef(x), name = "term", value = "estimate")
  ret <- left_join(coefs, ret, by = c("term", "estimate"))
  
  if (conf.int){
    ci <- broom:::broom_confint_terms(x, level = conf.level, ...)
    ret <- dplyr::left_join(ret, ci, by = "term")
  }
  if (exponentiate){
    ret <- broom:::exponentiate(ret)
  }

  # Split on last colon
  ret <- ret %>%
    mutate(
      y.level = ifelse(str_detect(term, ":"), sub(".*:(.+)$", "\\1", term), NA),
      term = ifelse(str_detect(term, ":"), sub(":(?!.*:).*$", "", term, perl = TRUE), term)
    ) %>%
    arrange(y.level) %>%
    relocate(y.level, .before = term)
  
  ret
}



```

```{r data, output=FALSE}
data <- readRDS("../Data/2025-06-23 - Cleaned_data.rds")

# Specify data to be used in income analysis
income_data <- filter(data, income_drop_all==0)
```

```{r age_stats}
age_statistics <- data %>%
  summarise(
    mean = mean(Age, na.rm=T),
    median = median(Age, na.rm=T),
    min = min(Age,na.rm=T),
    max = max(Age,na.rm=T),
    stdev = sd(Age, na.rm=T),
    wtd_mean = weighted.mean(Age, w = NatRepemployees, na.rm = T),
    wtd_median = wtd.quantile(Age, w = NatRepemployees, probs = c(.5), na.rm = T),
    wtd_min = wtd.quantile(Age, w = NatRepemployees, probs = c(0), na.rm = T),
    wtd_max = wtd.quantile(Age, w = NatRepemployees, probs = c(1), na.rm = T),
    wtd_stdev = sqrt(wtd.var(Age, w = NatRepemployees, na.rm = T)),
    N = n()
  )

readr::write_csv(age_statistics, file = "../outputs/methodology/data/age_stats.csv")

```

```{r gender_stats}
gender_statistics <- data %>%
  group_by(Gender) %>%
  summarise(
    n = n(),
    Frequency = sum(NatRepemployees)
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    percentage = 100 * (n / N),
    wtd_percentage = 100 * (Frequency / Sum)
  )

readr::write_csv(gender_statistics, file="../outputs/methodology/data/gender_statistics.csv")
```

```{r ethnicity_stats}
ethnicity_statistics <- data %>%
  group_by(Ethnicity_labelled) %>%
  summarise(
    n = n(), # count cases
    Frequency = sum(NatRepemployees) # count weighted cases
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    percentage = 100 * (n / N),
    wtd_percentage = 100 * (Frequency / Sum)
  )

write_csv(ethnicity_statistics, file="../outputs/methodology/data/ethnicity_statistics_census.csv")
```

-   [ ] Add css file to improve styling?

# Participants and Design

\[**Insert Name of Report**\] contains data from two studies. The first of these studies was a nationally representative survey of `r nrow(data)` \[**Workers?**\] conducted by Opinium Research between 25th November 2023 and the 21st December 2023.

To achieve a robust estimate of outsourced workers, the sample was weighted by age, gender, and education, region, and ethnicity. The ethnic minority sub-sample (1,435 respondents) was also weighted separately by age, gender, and region to ensure that findings related to ethnic minority adults were fully representative. Targets were estimated using data from the Labour Force Survey, the 2021 Census for England and Wales, and the Northern Ireland Census.

This sample had median age `r age_statistics$median` (SD = `r round(age_statistics$stdev,2)`). `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Female")],0)`% of respondents identified as female, `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Male")],0)`% as male, `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Other")],2)`% as other, and `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Prefer not to say")],2)`% preferred not to identify a gender. `r round(ethnicity_statistics$percentage[which(ethnicity_statistics$Ethnicity_labelled == "English / Welsh / Scottish / Northern Irish / British")],0)`% of respondents identified as 'English / Welsh / Scottish / Northern Irish / British' (see @sec-ethnicity for a detailed breakdown of ethnicity).

A follow-up survey of Outsourced workers (as defined in @sec-study1) was conducted by Opinium Research between 19th April to the 16th of May 2024 with a total sample of 1814. The purpose of this study was to further probe the experiences of outsourced workers and to understand the impact of outsourcing on their work and lives (see @sec-study2).

Soft quotas on age, gender, and region were implemented to ensure broad representativeness, and the final data was weighted to targets based on age, gender, education, region, and ethnicity. The targets were based on the weighted data from study 1. The survey population had a mean Age of 38.9 (SD = 13.0). 42.4% Female and 65.5% White British. A small proportion of respondents had previously participated in study 1 and met the outsourced criteria (5%).

Both surveys were administered online.

An initial pilot study aimed to refine the diagnostic questions used to identify outsourced workers, ensuring they aligned with JRF's initial definition and could be accurately answered by survey respondents. The diagnostic questions and feedback follow-ups were run on Opinium’s political omnibus, a nationally and politically representative sample of 2,055 UK adults between 30 August and 1 September 2023. The questions were filtered to those in work, resulting in a total of 1,200 respondents. Data from this pilot study is not reported here.

\[**POTENTIALLY ADD A TABLE HERE WITH CROSSTABS FOR THE TWO SAMPLES OR TABBED VISUALISATIONS**\]

# Measures

## Study 1- Nationally representative survey {#sec-study1}

The survey covered personal demographics, employment demographics (e.g. occupation, hours worked, pay), and the outsourced diagnostic questions. The main objectives were to ensure an accurate estimate of the size and demographic makeup of the outsourced population, and to analyse the data alongside the Labour Force Survey (LFS). \[MORGAN - **WHAT EXACTLY WAS INTENDED TO BE COMPARABLE? SPECIFICALLY WHICH QUESTIONS HAVE BEEN REPLICATED FROM TLFS**\]

Comparability to the LFS posed challenges, primarily because the LFS is conducted face-to-face, with interviewers playing a significant role in ensuring the accuracy of data and respondents' understanding of questions. However, as the Transformed Labour Force Survey (TLFS)– an online first version of the survey set to replace the LFS— was underway, where possible we used the TLFS versions. While question wording is still under review, this was deemed the best approach, as some TLFS waves had already taken place and findings on comparability to LFS \[MORGAN - **CITATION**\].

-   [x] I believe some questions were replicated from national survey's so lets explicate that
-   [x] Discuss the issue of pay calcs (e.g. basic overview and then refer to the section on it)
-   [ ] Discuss the issue of defining outsourcing ((e.g. basic overview and then refer to the section on it))
-   [ ] link to the data dictionary

### Income calculations (\[**perhaps more detailed than necessary in this section**\])

Respondents could choose how they provided information about their income. Firstly, they could choose the payment period for which to express their income from the following options:

-   Annually / per year
-   Monthly
-   Weekly
-   Hourly

Secondly, they could choose either an 'open' form of reporting or a 'closed' form. The open form required respondents to type in their pay for the payment period they chose. The closed form required respondents to select which income bracket their pay belonged to from a list of options.

The annual options were:

```{r}
ops <- levels(data$INCOME_CLOSED_ANNUAL_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The monthly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_MONTHLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The weekly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_WEEKLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The hourly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_HOURLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

```{r}
data_subset <- data %>%
  dplyr::select(c(ID, contains("INCOME", ignore.case = F))) %>%
  dplyr::select(!ends_with("labelled") & !ends_with("FREQ") & !ends_with("2"))

number_open <- data_subset %>%
  filter(!is.na(INCOME_OPEN_1)) %>%
  nrow()

number_closed <- data_subset %>%
  filter(is.na(INCOME_OPEN_1)) %>%
  dplyr::select(c(ID, contains("CLOSED"))) %>%
  nrow()

# but also check how many "prefer not to say"
closed_income <- data %>%
  filter(is.na(INCOME_OPEN_1)) %>%
  dplyr::select(c(ID, contains("INCOME", ignore.case = F))) %>%
  dplyr::select(ends_with("labelled"))

pref_not_say <- closed_income %>%
  rowwise() %>%
  summarise(
    sum = sum(c_across(everything()) == "Prefer not to say", na.rm=TRUE)
  ) %>%
  summarise(
    total_not_answered = sum(sum)
  )

closed_answered <- number_closed - pref_not_say$total_not_answered

```

`r number_open` respondents answered using the open method. `r closed_answered` respondents answered using the closed method. `r nrow(data) - sum(number_open,closed_answered)` did not answer either.

We equivalised respondents' income across the reporting options in two steps. Firstly, we converted closed income responses to continuous numeric values by taking the midpoint of the income brackets, or the value of the "less than" and "over" values. For example, a closed response of "£5,600 up to £11,200" would be converted to £8400; and a closed response of "Less than £5,600 a year" would be converted to £5600. These converted closed responses were combined with the open responses to produce a single continous income variable across payment periods.

```{r}
weeks_in_year <- 365 / 7 # if we're being pedantic (this is 52.14 weeks)
min_holiday_entitlement <- 28
non_working_weeks <- min_holiday_entitlement/5
working_weeks <- weeks_in_year - non_working_weeks
```

Next, we expressed all respondents' income in annual, weekly, and hourly periods. To do this we made an assumption about the number of working weeks in a year based on the minimum holiday entitlement of 28 days. We calculated the total number of weeks in a year as 365 / 7 = `r round(weeks_in_year,2)`, the total number of non-working weeks as 28 / 5 = `r round(non_working_weeks,2)`, and thus the total number of working weeks as `r round(weeks_in_year,2)` - `r round(non_working_weeks,2)` = `r round(working_weeks,2)`.

With this figure and the number of hours worked per week, we could convert incomes provided in one payment period to another. The table below shows how this was achieved.

\[ADD OUTLIER EXCLUSION CRITERIA\]

```{r}
conversion_table <- data.frame("Income provided..." = 
                                 c("... annually",
                                   "... monthly",
                                   "... weekly",
                                   "... hourly"),
                               "Formula to convert to annual" = 
                                 c("= income",
                                   "= income x 12",
                                   "= income x working weeks",
                                   "= income x hours per week x working weeks "),
                               "Formula to convert to weekly" = 
                                 c("= income / working weeks",
                                   "= (income x 12) / working weeks",
                                   "= income",
                                   "= income x hours per week"),
                               "Formula to convert to hourly" = 
                                 c("= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week"))

conversion_table %>%
  kable(col.names = c(
    "Income provided...", 
    "Formula to convert to annual",
    "Formula to convert to weekly",
    "Formula to convert to hourly")) %>%
  kable_styling(full_width = T)
```

## Study 2 - Outsourced workers survey {#sec-study2}

In the follow up survey of outsourced workers the data focuses on workers experiences and perceptions of outsourced work. The dataset is large containing 214 variables. Analysis of all the variables was beyond the scope of the report thus we focus on a subset of the data pertaining to outsourced workers experiences of rights violations, discrimination, job clarity, benefits and drawbacks of outsourced work and potential improvements to their work arrangements.

In the process of data cleaning we set hours per week to NA for participants who gave an impossible number of work hours per week (e.g. $\ge$ 168, *N*=11). Relatedly we construct variables to determine hourly, weekly, monthly and annual pay as in study 1 and flag outlier responses. Through this method 11.22% (183) participants were dropped from all subsequent analysis leaving a final sample of 1631 participants. We also determine whether the participant is low paid using the method from study 1.

A data dictionary is available from the [Github Repository](https://github.com/JustKnowledge-UK/jrf_nat_rep "Just Knowledge GitHub") associated with this project along with all code used to produce the analyses.

# Analysis - Study 1

-   [x] Determining if the worker is outsourced
-   [x] Calculating Low/Not Low pay
-   [x] Explain the analyses (e.g. any models that actually appear in the final output)

## Defining outsourcing

Workers were defined as outsourced based on responses to a set of diagnostic questions. Three questions asked respondents directly about whether they considered themselves outsourced and/or agency workers.

The first of these questions asked respondents to indicate directly whether they considered themselves outsourced by selecting one of the following options:

1.  I am sure I’m an outsourced worker
2.  I think I might be an outsourced worker
3.  I am not an outsourced worker

The second question asked respondents to indicate whether they considered themselves an agency worker by selecting from three options. For respondents who responded 1 or 2 to question 1, the options were:

1.  I am sure that I’m also an agency worker
2.  I think I might also be an agency worker
3.  I am not an agency worker

For respondents who responded 3 to question 1, the options were:

1.  I am sure that I’m an agency worker
2.  I think I might be an agency worker
3.  I am not an agency worker

Respondents were also asked whether the work they do was long- or short-term by selecting one of:

1.  I’m hired to do work which an organisation needs doing on a long-term or ongoing basis.
2.  I’m hired to do work which an organisation needs doing on a short-term or temporary basis.
3.  Other (please specify)

Finally, respondents were asked about aspects of their work that might indicate that the work they do is outsourced work. Respondents were asked: "Please read each of the following statements and tell us whether or not they are true for you and your work." The statements were:

1.  I am paid by one organisation but I do work for a different organisation.
2.  The organisation I’m paid by is a ‘third party’ organisation which other organisations hire to do work for them, rather than doing that w \[**FIND QUESTION IN DATA DICT**\]
3.  My employer / agency provides people to do work for other organisations (i.e. they might provide people to do cleaning, security, administratio \[**FIND QUESTION IN DATA DICT**\]
4.  On a day-to-day basis, I’m paid by one organisation but I get given tasks or instructions by people who are paid by a different organisation.
5.  I am paid by one organisation, but I work in a space which has the logo or branding of a different organisation.
6.  I wear a uniform which has the logo or branding of my employer / agency, and which marks me out as being paid by a different organisation to so \[**FIND QUESTION IN DATA DICT**\]

Workers were categorised into three mutually exclusive sub groups based on their responses to the above questions.

1.  A respondent was categorised as '**clearly outsourced**' if they responded 'I am sure I'm an outsourced worker' or 'I think I might be an outsourced worker' **and** 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis.'.

2.  A respondent was categorised as '**likely agency**' if they responded 'I am sure that I'm an agency worker' **and** 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis', **excluding** those people who are already defined as being 'clearly outsourced'.

3.  A respondent was categorised as belonging to the '**high indicators**' group if they responded TRUE to five or six \[CAN THIS BE EXPRESSED AS $\ge$ 5?\] of the outsourcing indicators, as well as responding 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis', **excluding** those people who were already defined as 'clearly outsourced' or 'likely agency'.

Together, these three sub groups form the classification of 'outsourced workers' considered in this report. Throughout the report, the term 'outsourced' refers to workers across the three sub groups. In places, analysis considers the three sub groups separately, in which case the groups will be referred to by name as 'clearly outsourced', 'likely agency', or 'high indicators'.

## Defining low pay

A 'low pay' binary variable was created by implementing an income threshold below which respondents were considered to be on a relatively low income. In line with with the [Organisation for Economic Co-operation and Development](https://www.oecd.org/en/data/indicators/incidence-of-low-and-high-pay.html), we set the threshold at two-thirds median weekly income. The two-thirds threshold was based on the weekly median income for respondents' region to account for regional variations in earnings.

Regional weekly median income values were drawn from the [Annual Survey of Hours and Earnings](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/earningsandhoursworkedukregionbyagegroup) (2023 provisional edition). Respondents whose reported weekly income was less than or equal to two-thirds of the median weekly income in their region were assigned to the 'low pay' group, while those whose reported weekly income was greater than two-thirds of the median weekly income in their region were assigned to the 'not low pay' group.

## Aggregating ethnicity

For reference, the table below provides a disambiguation of how ethnicities have been grouped in this analysis.

For analyses using the disaggregated (survey) categories with 21 levels, the reference category is "English / Welsh / Scottish / Northern Irish / British".

For analyses using the aggregated categories with 9 levels, the reference category is "White British"

For analyses using teh aggregated categories with 4 levels, the reference category is "White".

```{r}
ethnicity_cat <- data %>%
  dplyr::select(contains("ethnicity")) %>%
  distinct() %>%
  arrange(Ethnicity) %>%
  dplyr::select(-c(1:2,Ethnicity_collapsed_disaggregated))

ethn_colnames = c(
  "Ethnicity: Survey (21 levels)",
  "Ethnicity: Aggregated (9 levels)",
  "Ethnicity: Binary (4 levels)"
)
ethnicity_cat %>%
  kable(col.names = ethn_colnames) %>%
  kable_styling(full_width=FALSE)
```

## Models

In this section we describe the statistical models used in the report. In all models we applied survey weights so that the estimates can be considered representative of employees nationally.

### Outsourced pay gap

To investigate the pay gap been outsourced and non-outsourced workers we constructed a linear regression model predicting annual and weekly income (in separate models) from outsourcing membership. We included other variables in the model to account for their potential influence on income. The full regression model can be expressed as:

$$
Income = Age + Gender + Education + Ethnicity + Migration + Region + Outsourcing
$$ 

where

-   Income is a continuous numeric variable indicating a the respondent's income (weekly or annual, in different models)
-   Age is a continuous numeric variable indicating the respondent's age
-   Gender is a categorical variable with three levels:
    -   Male (reference category)
    -   Female
    -   Other
-   Education is a categorical variable indicating whether the respondent has a degree, with three levels:
    - Yes (reference category)
    -   No
    -   Don't know
-   Ethnicity is a categorical variable with eight levels:
    -   White British (reference category)
    -   Arab/British Arab
    -   Asian/Asian British
    -   Black/African/Caribbean/Black British
    -   Mixed/Multiple ethnic group
    -   Other ethnic group
    -   Prefer not to say
    -   White other
    - Don't think of myself as any of these
-   Migration is a categorical variable indicating when the respondent arrived in the UK, with 10 levels:
    -   I was born in the UK (reference category)
    -   Within the last year
    -   Within the last 3 years
    -   Within the last 5 years
    -   Within the last 10 years
    -   Within the last 15 years
    -   Within the last 20 years
    -   Within the last 30 years
    -   More than 30 years ago
    -   Prefer not to say
-   Region is a categorical variable indicating the respodent's region of residence, with 12 levels:
    -   London (reference category)
    -   East Midlands
    -   East of England
    -   North East
    -   North West
    -   Northern Ireland
    -   Scotland
    -   South East
    -   South West
    -   Wales
    -   West Midlands
    -   Yorkshire and the Humber
-   Outsourcing is a categorical variable indicating whether the respondent is outsourced, with two levels:
    -   Not outsourced (reference category)
    -   Outsourced

```{r}
#| output: false
#| warning: false
#| message: false

# Annual income
# Intercept only
mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

mod_base <- lm(income_annual_all ~ 1, mod_data, weights = NatRepemployees)
# H1
mod_annual <- lm(income_annual_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled, mod_data, weights = NatRepemployees)

summary(mod_annual)

# F and p
f_annual <- round(anova(mod_base, mod_annual)[2,"F"],2)
p_annual <- anova(mod_base, mod_annual)[2,"Pr(>F)"]
if(p_annual < .001){
  p_annual = "< .001"
} else{
  p_annual = paste0("= ",round(p_annual,3))
}

# Degrees of freedom
dfs_annual <- as.list(anova(mod_base, mod_annual)[2,c("Df","Res.Df")])
# R2
rsquare_annual <- round(summary(mod_annual)$r.squared,2)

# Weekly income
# Intercept only
mod_base <- lm(income_weekly_all ~ 1, mod_data, weights = NatRepemployees)
# H1
mod_weekly <- lm(income_weekly_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled, mod_data, weights = NatRepemployees)
summary(mod_weekly)

# F and p
f_weekly <- round(anova(mod_base, mod_weekly)[2,"F"],2)
p_weekly <- anova(mod_base, mod_weekly)[2,"Pr(>F)"]
if(p_weekly < .001){
  p_weekly = "< .001"
} else{
  p_weekly = paste0("= ",round(p_weekly,3))
}

# Degrees of freedom
dfs_weekly <- as.list(anova(mod_base, mod_weekly)[2,c("Df","Res.Df")])
# R2
rsquare_weekly <- round(summary(mod_weekly)$r.squared,2)

```

The annual income model was statistically significant (*R^2^* = `r rsquare_annual`, *F*(`r dfs_annual[[1]]`, `r dfs_annual[[2]]`) = `r f_annual`, *p* `r p_annual`). The table below shows the coefficients for the annual income model.

```{r}
labels <- c(
  'Intercept',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Outsourcing: Outsourced',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)
  
tab_model(mod_annual, pred.labels = labels, dv.labels = "Annual income")
```

As expected, the model statistics for weekly income model were identical to the those of the annual income model. The model was statistically significant (*R^2^* = `r rsquare_weekly`, *F*(`r dfs_weekly[[1]]`, `r dfs_weekly[[2]]`) = `r f_weekly`, *p* `r p_weekly`). The table below shows the coefficients for the weekly income model.

```{r}
tab_model(mod_weekly, pred.labels = labels, dv.labels = "Weekly income")
```

### Gender pay gap

```{r}
annual_gender_coef <- extract_lm_coefs(mod_annual, only_sig = T) %>%
  filter(variable == "GenderFemale")

weekly_gender_coef <- extract_lm_coefs(mod_weekly, only_sig = T) %>%
  filter(variable == "GenderFemale") 
```

The above model was also used to assess a possible gender pay gap. As shown in the preceding two tables, there is a significant difference in pay between men and women. Annually, women earn £`r annual_gender_coef$Estimate %>% round(2) %>% abs()` less than men. Per week, women earn £`r weekly_gender_coef$Estimate %>% round(2) %>% abs()` less than men.

We next explored whether outsourcing compounds this gender pay gap by adding an interaction term into the previous models so that

$$
Income = Age + Gender + Education + Ethnicity + Migration + Region + Outsourcing + Gender:Outsourcing
$$

```{r}
#| output: false
#| warning: false
#| message: false
#| 
mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

# Annual income
# H1
mod_annual_int <- lm(income_annual_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled + Gender:outsourcing_status, income_data, weights = NatRepemployees)

summary(mod_annual_int)

# F and p
anova_test <- anova(mod_annual, mod_annual_int)
f_annual <- anova_test[2,"F"] %>% round(2)
p_annual <- anova_test[2,"Pr(>F)"]
if(p_annual < .001){
  p_annual = "< .001"
} else{
  p_annual = paste0("= ",round(p_annual,3))
}

# Degrees of freedom
dfs_annual <- as.list(anova_test[2,c("Df","Res.Df")])
# R2
rsquare_annual <- round(summary(mod_annual_int)$r.squared,2)

# Weekly income

# H1
mod_weekly_int <- lm(income_weekly_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled + Gender:outsourcing_status, income_data, weights = NatRepemployees)
summary(mod_weekly_int)

# F and p
anova_test <- anova(mod_weekly, mod_weekly_int)

f_weekly <-  anova_test[2,"F"] %>% round(2)
p_weekly <- anova_test[2,"Pr(>F)"]
if(p_weekly < .001){
  p_weekly = "< .001"
} else{
  p_weekly = paste0("= ", round(p_weekly,3))
}

# Degrees of freedom
dfs_weekly <- as.list(anova_test[2,c("Df","Res.Df")])
# R2
rsquare_weekly <- round(summary(mod_weekly_int)$r.squared,2)

```

For both models, adding the interaction effect did not improve model fit (*R^2^* = `r rsquare_weekly`, *F*(`r dfs_weekly[[1]]`, `r dfs_weekly[[2]]`) = `r f_weekly`, *p* `r p_weekly`). The tables below show the coefficients for each model.

```{r}
labels <- c(
  'Intercept',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  'Education: Has degree',
  "Education: Don't know",
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Outsourcing: Outsourced',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say',
  'Interaction: Outsourcing x Gender Female',
  'Interaction: Outsourcing x Gender Other',
  'Interaction: Outsourcing x Gender Prefer not to say'
)
  
tab_model(mod_annual_int, pred.labels = labels, dv.labels = "Annual income")
tab_model(mod_weekly_int, pred.labels = labels, dv.labels = "Weekly income")

```

```{r}
ems <- emmeans(mod_annual_int, specs = "Gender", by = "outsourcing_status", nuisance = "BORNUK_labelled")
cons <- summary(contrast(ems, "pairwise",adjust="tukey"))
sig_cons <- cons %>% filter(p.value < .05)

```

```{r}
ems <- emmeans(mod_annual_int, specs = "outsourcing_status", by = "Gender", nuisance = "BORNUK_labelled")
cons <- summary(contrast(ems, "pairwise",adjust="tukey"))
sig_cons2 <- cons %>% filter(p.value < .05) 

```


The interaction term is non-significant. Estimated marginal means show that:

- Among not outsourced workers, men are paid £`r sig_cons %>% filter(outsourcing_status == "Not outsourced") %>% pull(estimate) %>% abs() %>% round(2)` more than women
- Among outsourced workers, men are paid £`r sig_cons %>% filter(outsourcing_status == "Outsourced") %>% pull(estimate) %>% abs() %>% round(2)` more than women
- Among men, not outsourced workers are paid £`r sig_cons2 %>% filter(Gender == "Male") %>% pull(estimate) %>% abs() %>% round(2)` more than outsourced workers.
- Among women, not outsourced workers are paid £`r sig_cons2 %>% filter(Gender == "Female") %>% pull(estimate) %>% abs() %>% round(2)` more than outsourced workers.


The plot below illustrates the main effects that men are paid more than women and that outsourced men and women are paid less than non-outsourced men and women. The lack of interaction indicates that the difference in pay between men and women does not significantly differ between outsourced and non-outsourced people.

```{r}
sjPlot::plot_model(mod_annual_int, type = "pred", legend.title="", terms = c("outsourcing_status","Gender"), dodge=0.5) +#
  
  coord_flip() +
  xlab("") + ylab("Likelihood of being outsourced") +
  theme_minimal() 
```

### Demographic models

#### Ethnicity

Several regressions were run to assess the likelihood of being outsourced from demographics. These models underlie the claims in the report in relation to ethnicity, migration, and gender.

The overall model was defined as:

$$
Outsourcing = Ethnicity + Age + Gender + Education + Region + Migration
$$

where

-   Outsourcing is a categorical variable indicating whether the respondent is outsourced, with two levels:
    -   Not outsourced (reference category)
    -   Outsourced
-   Age is a continuous numeric variable indicating the respondent's age
-   Gender is a categorical variable with three levels:
    -   Male (reference category)
    -   Female
    -   Other
-   Education is a categorical variable indicating whether the respondent has a degree, with three levels:
    -   Yes (reference category)
    -   No
    -   Don't know
-   Migration is a categorical variable indicating when the respondent arrived in the UK, with 10 levels:
    -   I was born in the UK (reference category)
    -   Within the last year
    -   Within the last 3 years
    -   Within the last 5 years
    -   Within the last 10 years
    -   Within the last 15 years
    -   Within the last 20 years
    -   Within the last 30 years
    -   More than 30 years ago
    -   Prefer not to say
-   Region is a categorical variable indicating the respodent's region of residence, with 12 levels:
    -   London (reference category)
    -   East Midlands
    -   East of England
    -   North East
    -   North West
    -   Northern Ireland
    -   Scotland
    -   South East
    -   South West
    -   Wales
    -   West Midlands
    -   Yorkshire and the Humber

For this exploration we modelled ethnicity in three ways.

1.  As a categorical variable with four levels:
    -   White (reference category)
    -   Not White 
    - Don't think of myself as any of these
    - Prefer not say
    
2.  As a categorical variable with eight levels:
    -   White British (reference category)
    -   Arab/British Arab
    -   Asian/Asian British
    -   Black/African/Caribbean/Black British
    -   Don't think of myself as any of these
    -   Mixed/Multiple ethnic group
    -   Other ethnic group
    -   Prefer not to say
    -   White other
3.  As a categorical variable with 21 levels:
    -   English/Welsh/Scottish/Northern Irish/British (reference category)
    -   Irish
    -   Gypsy or Irish Traveller
    -   Roma
    -   Any other White background
    -   White and Black Caribbean
    -   White and Black African
    -   White and Asian
    -   Any other Mixed/Multiple ethnic background
    -   Indian
    -   Pakistani
    -   Bangladeshi
    -   Chinese
    -   Any other Asian background
    -   African
    -   Caribbean
    -   Any other Black, Black British, or Caribbean background
    -   Arab
    -   Any other ethnic group
    -   Don't think of myself as any of these
    -   Prefer not to say

We used `svyglm()` from the `survey` package to construct survey-weighted generalised linear models. This approach allows us to take into account survey weights to produce design-based standard errors by assuming a 'quasibinomial' distribution to the data. Specifically, the survey-weighted data contains overdispersion; the variance is greater than expected by a binomial distribution (which assumes variance = mean(1 - mean)). The quasibinomial distribution estimates a dispersion parameter that allows the variance to be greater than expected by the true binomial distribution. For more information see Lumley, Thomas, and Alastair Scott. ‘Fitting Regression Models to Survey Data’. Statistical Science 32, no. 2 (2017): 265–780.

We used Rao–Scott adjusted Wald tests to compare nested survey-weighted models fit using a quasibinomial family. This method accounts for the survey design and is appropriate given that quasi-likelihood models do not support likelihood-ratio testing. For more information see Rao, J. N. K., and A. J. Scott. ‘On Chi-Squared Tests for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data’. The Annals of Statistics 12, no. 1 (March 1984): 46–60. https://doi.org/10.1214/aos/1176346391.


```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

# Step 1: Create a survey design object
design <- svydesign(
  ids = ~1,                                
  weights = ~NatRepemployees,          
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_binary + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 1, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Ethnicity: Not White',
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)


tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```



```{r ethnicity-aggregated}
#| output: false
#| warning: false
#| message: false


mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,            
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_collapsed + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 2, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

```{r ethnicity-disaggregated}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 3, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```



#### Migration

We next focus on predicting whether a person was outsourced based on wehther the person was born in the UK. This binary variable was constructed by collapsing the 10-level migration variable down into two levels, so that "I was born in the UK" becomes "Born in UK", and all levels apart from "I was born in the UK" and "Prefer not to say" become "Not born in UK".

```{r}
#| output: false
#| warning: false
#| message: false


mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))


design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

#### Gender

```{r}
gender_coefs <- coefs %>%
  filter(variable == "GenderFemale")
```

We used the same generalised linear model as in the previous section to estimate the effect of Gender on outsourcing, where Gender is a categorical variable with four levels:

-   Male (reference category)
-   Female
-   Prefer not to say
-   Other

The model indicates that women are `r gender_coefs$or %>% round(2)` times as likely (i.e. `r 100 * (1 - gender_coefs$or %>% round(2))`% less likely) to be outsourced than men.

#### Age

```{r}
age_coefs <- coefs %>%
  filter(variable == "Age")
  
```

Again using the same model, we found that age was a significant predictor of the likelihood of being outsourced. The model indicates that for each year older a worker is, they are `r age_coefs$or %>% round(2)` times as likely (i.e. `r (1-age_coefs$or %>% round(2))*100`% less likely) to be outsourced.

We also explored how age predicted whether a person was on low pay. The model formula is:

$$
Income Group =  Age + Outsourcing + Ethnicity + Gender + Education + Region + Migration
$$

```{r}
#| output: false
#| warning: false
#| message: false
# 
# mod_data <- income_data %>%
#   filter(!is.na(Ethnicity_collapsed))
#   
# design <- svydesign(
#   ids = ~1,                             
#   weights = ~NatRepemployees,             
#   data = mod_data
# )
# 
# # Step 2: Fit the model with quasibinomial family
# mod_svy1 <- svyglm(
#   income_group ~ 1,
#   design = design,
#   family = quasibinomial()
# )
# 
# # Step 2: Fit the model with quasibinomial family
# mod_svy2 <- svyglm(
#   income_group ~ Age + outsourcing_status + Ethnicity_collapsed_disaggregated + Gender + Has_Degree + Region + BORNUK_binary,
#   design = design,
#   family = quasibinomial()
# )
# 
# coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
# 
# wald <- anova(mod_svy1,mod_svy2, method = "Wald")
# 
# # F and p
# f <- round(wald[["Ftest"]] %>% as.numeric(),2)
# p <- wald[["p"]] %>% as.numeric()
# 
# if(p < .001){
#   p = "< .001"
# } else{
#   p = paste0("= ",round(p,3))
# }
# 
# # Degrees of freedom
# dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

```{r}
#| output: false
#| message: false
# Alternative for 3-level variable

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ Age + outsourcing_status + Ethnicity_collapsed_disaggregated + Gender + Has_Degree + Region + BORNUK_binary,
  design = design,
  family = multinomial(refLevel = "Low")  # Replace "Low" with your reference category
)

summary(mod_svy2)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)

# Remove intercepts
non_intercept_idx <- !grepl("(Intercept)", names(coefs))

# Subset coefficients and vcov accordingly
coefs_non_intercept <- coefs[non_intercept_idx]
vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]

# Perform Wald test
wald <- wald.test(
  Sigma = vcovs_non_intercept, 
  b = coefs_non_intercept, 
  L = diag(length(coefs_non_intercept))
)
wald_stats <- wald[["result"]][["chi2"]]
p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A saturated model including all variables was a significantly better fit to the data than an intercept-only model, *X^2*(`r wald_stats[2]`) = `r wald_stats[1]`, *p* `r p`. The table below shows the model coefficients.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

# HERE

```{r}
# labels <- c(
#   'Intercept',
#   'Age',
#   'Outsourcing: Outsourced',
#   "Ethnicity: Irish",
#   "Ethnicity: Gypsy or Irish Traveller",
#   "Ethnicity: Roma",
#   "Ethnicity: Any other White background",
#   "Ethnicity: White and Black Caribbean",
#   "Ethnicity: White and Black African",
#   "Ethnicity: White and Asian",
#   "Ethnicity: Any other Mixed/Multiple ethnic background",
#   "Ethnicity: Indian",
#   "Ethnicity: Pakistani",
#   "Ethnicity: Bangladeshi",
#   "Ethnicity: Chinese",
#   "Ethnicity: Any other Asian background",
#   "Ethnicity: African",
#   "Ethnicity: Caribbean",
#   "Ethnicity: Any other Black, Black British, or Caribbean background",
#   "Ethnicity: Arab",
#   "Ethnicity: Any other ethnic group",
#   "Ethnicity: Don't think of myself as any of these",
#   "Ethnicity: Prefer not to say",
#   'Gender: Female',
#   'Gender: Other',
#   'Gender: Prefer not to say',
#   "Education: Don't have degree",
#   "Education: Don't know",
#   'Region: East Midlands',
#   'Region: East of England',
#   'Region: North East',
#   'Region: North West',
#   'Region: Northern Ireland',
#   'Region: Scotland',
#   'Region: South East',
#   'Region: South West',
#   'Region: Wales',
#   'Region: West Midlands',
#   'Region: Yorkshire and the Humber',
#   'Migration: Not born in the UK',
#   'Migration: Prefer not to say'
# )
# 
# 
# tab_model(mod_svy2, 
#           pred.labels = labels, 
#           dv.labels = "Low income group membership",
#           show.r2 = FALSE)
```


<!-- #### Age-outsourcing interaction -->

<!-- ```{r} -->
<!-- mod <- glm(outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region + income_group, income_data %>% filter(!is.na(income_group)), weights = NatRepemployees, family="quasibinomial") -->
<!-- summary(mod) -->

<!-- tjur <- income_data %>% -->
<!--   filter(!is.na(Ethnicity_collapsed_disaggregated)) %>% -->
<!--   filter(!is.na(income_group)) %>% -->
<!--   mutate(pred = predict(mod, type = "response")) %>% -->
<!--   group_by(outsourcing_status) %>% -->
<!--   summarise(weighted_mean = weighted.mean(pred, NatRepemployees)) %>% -->
<!--   summarise(tjur_r2 = diff(weighted_mean)) %>% -->
<!--   pull() -->

<!-- coefs <- extract_glm_coefs(mod, only_sig=T) -->

<!-- mod2 <- update(mod, ~. + Age:income_group) -->
<!-- summary(mod2) -->

<!-- tjur2 <- income_data %>% -->
<!--   filter(!is.na(Ethnicity_collapsed_disaggregated)) %>% -->
<!--   filter(!is.na(income_group)) %>% -->
<!--   mutate(pred = predict(mod2, type = "response")) %>% -->
<!--   group_by(outsourcing_status) %>% -->
<!--   summarise(weighted_mean = weighted.mean(pred, NatRepemployees)) %>% -->
<!--   summarise(tjur_r2 = diff(weighted_mean)) %>% -->
<!--   pull() -->

<!-- coefs2 <- extract_glm_coefs(mod2, only_sig=T) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- ems <- emtrends(mod2, var = "Age", specs = "income_group", rg.limit=15000)#, nuisance = c("BORNUK_labelled")) -->
<!-- cons <- summary(contrast(ems, "pairwise",adjust="tukey")) -->
<!-- sig_cons <- cons %>% filter(p.value < .05) %>% -->
<!--   mutate( -->
<!--     or = 1 / exp(estimate), .after=estimate # 1 / or because we want to express comparison - white(ref) (contrast expresses white(ref) - comparison) -->
<!--   ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- sjPlot::plot_model(mod2, type="int", terms=c("Age","income_group")) -->
<!-- ``` -->

#### Ethnicity-migration interaction

We next explored whether there was an interaction between ethnicity and migration in predicting outsourcing using generalised linear models by adding an interaction effect to the model predicting outsourcing above so that the model formula is:

$$
Outsourcing = Ethnicity + Age + Gender + Educaton + Region + Migration + Ethnicity:Migration
$$

where Ethnicity:Migration represents the interaction term.

We did this twice: first for the aggregated eight-level ethnicity variable, and then for the disaggregated 21-level variable.

##### Ethnicity 9

```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))
  
design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

summary(mod_svy1)
# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary * Ethnicity_collapsed + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A model including the ethnicity:migration interaction term had significantly improved fit compared to a model without the interaction term, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.


```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Interaction: Not born in UK x Arab/Arab British',
  'Interaction: Not born in UK x Asian/Asian British',
  'Interaction: Prefer not to say x Asian/Asian British',
  'Interaction: Not born in UK x Black/African/Caribbean/Black British',
  'Interaction: Prefer not to say x Black/African/Caribbean/Black British',
  "Interaction: Not born in UK x Don't think of myself as any of these",
  'Interaction: Not born in UK x Mixed/Multiple ethnic group',
  'Interaction: Prefer not to say x Mixed/Multiple ethnic group',
  'Interaction: Not born in UK x Other ethnic group',
  'Interaction: Not born in UK x Prefer not to say',
  'Interaction: Prefer not to say x Prefer not to say',
  'Interaction: Not born in UK x White other',
  'Interaction: Prefer not to say x White other'
  
)

tab_model(mod_svy2, 
          pred.labels = labels,
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

###### Post-hoc

We explored the interaction effect using targeted contrasts comparing

1. The effect of each ethnicity versus "White British" within each level of migration.
2. The effect of "Not born in UK" versus "Born in UK" within each level of ethnicity

Contrasts were calculated using `survey::svycontrast()` and p values were adjusted for multiple comparisons using the FDR method (Benjamini and Hochberg, 1995). Results were only considered where the sample for the contrast was greater than 10.

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "White British"
ref_bor <- "Born in UK"

partA_results <- list()

for (bor in bor_levels) {
  for (eth in eth_levels) {
    if (eth == ref_eth) next  # skip comparing ref to itself
    if (!paste0("Ethnicity_collapsed", eth) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for ethnicity (if not ref)
    if (eth != ref_eth) {
      vec[paste0("Ethnicity_collapsed", eth)] <- 1
    }

    # Interaction term (only needed if BORNUK != ref)
    if (bor != ref_bor) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed", eth)
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partA_results[[paste0(bor, ": ", eth, " vs ", ref_eth)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}

# Make into df
partA_df <- bind_rows(
  lapply(names(partA_results), function(name) {
    res <- partA_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partA_df <- partA_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed) %>%
  rename(cell_n = n)

partA_df <- partA_df %>%
  separate(contrast, into = c("BORNUK_binary", "ethnicity"), sep = ": ", remove = FALSE) %>%
  separate(ethnicity, into = c("test_ethn","ref_ethn"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("BORNUK_binary", "test_ethn" = "Ethnicity_collapsed")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partA <- partA_df %>% filter(p_adj < 0.05)

```

Exploring the effect of each ethnicity versus "White British" within each level of migration, we found that, among people not born in the UK, White other workers were `r sig_partA[which(sig_partA$test_ethn == "White other"), "OR"] %>% round(2)` times as likely (i.e., `r 100 * (1-(sig_partA[which(sig_partA$test_ethn == "White other"), "OR"] %>% round(2)))`% less likely) to be outsourced than "White British" people.

No differences by ethnicity were observed among people born in the UK.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ Ethnicity_collapsed * BORNUK_binary,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

# ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
#                       "Pakistani",
#                       "White and Black African")
ems_df %>%
  # filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = BORNUK_binary, x = prob, colour = Ethnicity_collapsed)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Migration",
    colour = "Ethnicity"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "White British"
ref_bor <- "Born in UK"

partB_results <- list()

for (eth in eth_levels) {
  for (bor in bor_levels) {
    if (bor == ref_bor) next  # skip comparing ref to itself
    if (!paste0("BORNUK_binary", bor) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for BORNUK (if not ref)
    vec[paste0("BORNUK_binary", bor)] <- 1

    # Interaction term (only if ethnicity != ref)
    if (eth != ref_eth) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed", eth)
      # Catch flipped ordering, just in case
      if (!interaction_name %in% coefs) {
        alt_name <- paste0("Ethnicity_collapsed", eth, ":", "BORNUK_binary", bor)
        if (alt_name %in% coefs) interaction_name <- alt_name
      }
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partB_results[[paste0(eth, ": ", bor, " vs ", ref_bor)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}


# Make into df
partB_df <- bind_rows(
  lapply(names(partB_results), function(name) {
    res <- partB_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partB_df <- partB_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed) %>%
  rename(cell_n = n)

partB_df <- partB_df %>%
  separate(contrast, into = c("ethnicity","BORNUK_binary"), sep = ": ", remove = FALSE) %>%
  separate(BORNUK_binary, into = c("test_born","ref_born"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("ethnicity" = "Ethnicity_collapsed", "test_born" = "BORNUK_binary")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partB <- partB_df %>% filter(p_adj < 0.05)

```

Examining the effect of "Not born in UK" versus "Born in UK" within each ethnicity, we found  

- among "White British", workers not born in the UK are `r sig_partB[which(sig_partB$ethnicity == "White British" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.
- among people of Mixed/multiple ethnic groups, workers not born in UK are `r sig_partB[which(sig_partB$ethnicity == "Mixed/Multiple ethnic group" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.

No significant differences between people born and not born in the UK were observed for any other ethnicities. The figure below shows these effects.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ BORNUK_binary * Ethnicity_collapsed,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

# ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
#                       "Pakistani",
#                       "White and Black African")
ems_df %>%
  # filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = Ethnicity_collapsed, x = prob, colour = BORNUK_binary)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Ethnicity",
    colour = "Born in UK?"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

##### Ethnicity 21

```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))
  
design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary * Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A model including the ethnicity:migration interaction term had significantly improved fit compared to a model without the interaction term, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.


```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  "Interaction: Not born in UK x Irish",
  "Interaction: Prefer not to say x Irish",
  "Interaction: Not born in UK x Gypsy or Irish Traveller",
  # "Interaction: Not born in UK x Roma", # Roma not estimable because rank deficient
  "Interaction: Not born in UK x Any other White background",
  "Interaction: Prefer not to say x Any other White background",
  "Interaction: Not born in UK x White and Black Caribbean",
  "Interaction: Prefer not to say x White and Black Caribbean",
  "Interaction: Not born in UK x White and Black African",
  "Interaction: Prefer not to say x White and Black African",
  "Interaction: Not born in UK x White and Asian",
  "Interaction: Not born in UK x Any other Mixed/Multiple ethnic background",
  "Interaction: Prefer not to say x Any other Mixed/Multiple ethnic background",
  "Interaction: Not born in UK x Indian",
  "Interaction: Prefer not to say x Indian",
  "Interaction: Not born in UK x Pakistani",
  "Interaction: Prefer not to say x Pakistani",
  "Interaction: Not born in UK x Bangladeshi",
  "Interaction: Prefer not to say x Bangladeshi",
  "Interaction: Not born in UK x Chinese",
  "Interaction: Not born in UK x Any other Asian background",
  "Interaction: Prefer not to say x Any other Asian background",
  "Interaction: Not born in UK x African",
  "Interaction: Prefer not to say x African",
  "Interaction: Not born in UK x Caribbean",
  "Interaction: Prefer not to say x Caribbean",
  "Interaction: Not born in UK x Any other Black, Black British, or Caribbean background",
  "Interaction: Prefer not to say x Any other Black, Black British, or Caribbean background",
  
  "Interaction: Not born in UK x Arab",
  "Interaction: Not born in UK x Any other ethnic group",
  "Interaction: Not born in UK x Don't think of myself as any of these",
  "Interaction: Not born in UK x Prefer not to say",
  "Interaction: Prefer not to say x Prefer not to say"

  
)

tab_model(mod_svy2, 
          pred.labels = labels,
          dv.labels = "Outsourcing",
          show.r2 = FALSE,
          title = "Note: Migration x Roma not estimable as model matrix rank deficient")
```

###### Post-hoc

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_bor <- "Born in UK"

partA_results <- list()

for (bor in bor_levels) {
  for (eth in eth_levels) {
    if (eth == ref_eth) next  # skip comparing ref to itself
    if (!paste0("Ethnicity_collapsed_disaggregated", eth) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for ethnicity (if not ref)
    if (eth != ref_eth) {
      vec[paste0("Ethnicity_collapsed_disaggregated", eth)] <- 1
    }

    # Interaction term (only needed if BORNUK != ref)
    if (bor != ref_bor) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed_disaggregated", eth)
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partA_results[[paste0(bor, ": ", eth, " vs ", ref_eth)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}

# Make into df
partA_df <- bind_rows(
  lapply(names(partA_results), function(name) {
    res <- partA_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partA_df <- partA_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partA_df <- partA_df %>%
  separate(contrast, into = c("BORNUK_binary", "ethnicity"), sep = ": ", remove = FALSE) %>%
  separate(ethnicity, into = c("test_ethn","ref_ethn"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("BORNUK_binary", "test_ethn" = "Ethnicity_collapsed_disaggregated")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partA <- partA_df %>% filter(p_adj < 0.05)


```

We explored the interaction effect using targeted contrasts comparing

1. The effect of each ethnicity versus "English / Welsh / Scottish / Northern Irish / British" within each level of migration.
2. The effect of "Not born in UK" versus "Born in UK" within each level of ethnicity

Contrasts were calculated using survey::svycontrast() and p values were adjusted for multiple comparisons using the FDR method (Benjamini and Hochberg, 1995) and results were only considered where the sample for the contrast was greater than 10.

Exploring the effect of each ethnicity versus "English / Welsh / Scottish / Northern Irish / British" within each level of migration, we found that, among people born in the UK

- White and Black African people were `r sig_partA[which(sig_partA$BORNUK_binary == "Born in UK" & sig_partA$test_ethn == "White and Black African"), "OR"] %>% round(2)` times more likely to be outsourced than "English / Welsh / Scottish / Northern Irish / British" people.
- Pakistani people were `r sig_partA[which(sig_partA$BORNUK_binary == "Born in UK" & sig_partA$test_ethn == "Pakistani"), "OR"] %>% round(2)` times more likely to be outsourced than "English / Welsh / Scottish / Northern Irish / British" people.

Among people not born in the UK, no significant differences between ethnicities were observed. The figure below shows the effects for "English / Welsh / Scottish / Northern Irish / British", "White and Black African", and Pakistani respondents.


```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ Ethnicity_collapsed_disaggregated * BORNUK_binary,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
                      "Pakistani",
                      "White and Black African")
ems_df %>%
  filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = BORNUK_binary, x = prob, colour = Ethnicity_collapsed_disaggregated)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Migration",
    colour = "Ethnicity"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_bor <- "Born in UK"

partB_results <- list()

for (eth in eth_levels) {
  for (bor in bor_levels) {
    if (bor == ref_bor) next  # skip comparing ref to itself
    if (!paste0("BORNUK_binary", bor) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for BORNUK (if not ref)
    vec[paste0("BORNUK_binary", bor)] <- 1

    # Interaction term (only if ethnicity != ref)
    if (eth != ref_eth) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed_disaggregated", eth)
      # Catch flipped ordering, just in case
      if (!interaction_name %in% coefs) {
        alt_name <- paste0("Ethnicity_collapsed_disaggregated", eth, ":", "BORNUK_binary", bor)
        if (alt_name %in% coefs) interaction_name <- alt_name
      }
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partB_results[[paste0(eth, ": ", bor, " vs ", ref_bor)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}


# Make into df
partB_df <- bind_rows(
  lapply(names(partB_results), function(name) {
    res <- partB_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partB_df <- partB_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partB_df <- partB_df %>%
  separate(contrast, into = c("ethnicity","BORNUK_binary"), sep = ": ", remove = FALSE) %>%
  separate(BORNUK_binary, into = c("test_born","ref_born"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("ethnicity" = "Ethnicity_collapsed_disaggregated", "test_born" = "BORNUK_binary")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partB <- partB_df %>% filter(p_adj < 0.05)

```

Examining the effect of "Not born in UK" versus "Born in UK" within each level of ethnicity, we found that among "English / Welsh / Scottish / Northern Irish / British", workers not born in the UK are `r sig_partB[which(sig_partB$ethnicity == "English / Welsh / Scottish / Northern Irish / British" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.

No significant differences between people born and not born in the UK were observed for any other ethnicities. The figure below shows these effects.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ BORNUK_binary * Ethnicity_collapsed_disaggregated,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

ggplot(ems_df, aes(y = Ethnicity_collapsed_disaggregated, x = prob, colour = BORNUK_binary)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Ethnicity",
    colour = "Born in UK?"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```


#### Ethnicity-outsourced interaction

A generalised linear model was constructed to test whether the interaction between ethnicity and outsourcing predicted whether a person had a low income.

$$
Income Group = Outsourcing + Ethnicity + Age + Gender + Education + Region + Migration + Outsourcing:Ethnicity
$$ 

As in preceding sections, we constructed three models; one for the binary ethnicity variable, one for the eight-level ethnicity variable, and one for the 21-level ethnicity variable.

##### Ethnicity binary

```{r}
#| message: false
#| output: false

# Alternative for 3-level variable

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_binary)) %>%
  filter(Ethnicity_binary %in% c("White","Non-White")) %>%
  dplyr::mutate(
Ethnicity_binary = factor(Ethnicity_binary, levels = c("White","Non-White")))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_binary + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Low")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_binary + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_binary,
  design = design,
  family = multinomial(refLevel = "Low")
)

summary(mod_svy2)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_binary", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p

# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```
A saturated model including the interaction term was not a significantly better fit to the data than an intercept-only model, *X^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

##### Ethnicity 9

```{r}
# Alternative for 3-level variable

ethns_to_drop <- c("Don't think of myself as any of these", "Prefer not to say")

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed)) %>%
  filter(!(Ethnicity_collapsed %in% ethns_to_drop)) %>%
  mutate(Ethnicity_collapsed = droplevels(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Low")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_collapsed,
  design = design,
  family = multinomial(refLevel = "Low")
)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_collapsed", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p
# 
# # Extract coefficients and vcov
# coefs <- coef(mod_svy2)
# vcovs <- vcov(mod_svy2)
# 
# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```
A model including the ethnicity:outsourcing interaction term significantly improved model fit compared to a model without the interaction term, *X^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients.


```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

We explored the interaction effect using targeted contrasts comparing

1. The effect of outsourcing within each level of ethnicity
2. The effect of each ethnicity versus "White British" within each level of outsourcing

```{r}
cell_count_thresh <- 10
```

We do not consider contrasts for which any cell count is less than `r cell_count_thresh`.

###### Post-hoc: Outsourcing within ethnicity

```{r}
#| message: false
#| output: false
#| 
# Create prediction data 
pred_data <- expand.grid(
  outsourcing_status = levels(mod_data$outsourcing_status),
  Ethnicity_collapsed = levels(mod_data$Ethnicity_collapsed),
  Age = mean(mod_data$Age, na.rm = TRUE),
  Gender = levels(mod_data$Gender)[1],
  Has_Degree = levels(mod_data$Has_Degree)[1],
  Region = levels(mod_data$Region)[1],
  BORNUK_labelled = levels(mod_data$BORNUK_labelled)[1]
)

# Get predictions
predictions <- predict(mod_svy2$fit, newdata = pred_data, type = "response")

# Create results dataframe - much simpler!
pred_results <- data.frame(
  pred_data[, 1:2],
  predictions
)

# Add prob_ prefix to column names for clarity
income_levels <- levels(mod_svy2)
prob_cols <- paste0("prob_", colnames(predictions))
names(pred_results)[3:ncol(pred_results)] <- prob_cols

# print(pred_results)

# Bootstrap function for getting confidence intervals
bootstrap_predictions <- function(n_boot = 500) {
  
  boot_results <- replicate(n_boot, {
    # Resample with replacement, respecting weights
    n_obs <- nrow(mod_data)
    boot_indices <- sample(1:n_obs, size = n_obs, replace = TRUE, 
                          prob = mod_data$NatRepemployees/sum(mod_data$NatRepemployees))
    boot_data <- mod_data[boot_indices, ]
    
    # Create new survey design
    boot_design <- svydesign(
      ids = ~1,
      weights = ~NatRepemployees,
      data = boot_data
    ) 
    
    # Refit model
    tryCatch({
      boot_model <- svyVGAM::svy_vglm(
        income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + 
                       Has_Degree + Region + BORNUK_labelled + 
                       outsourcing_status:Ethnicity_collapsed,
        design = boot_design,
        family = multinomial(refLevel = "Mid")  # Mid is reference
      )
      
      # Get predictions
      boot_pred <- predict(boot_model$fit, newdata = pred_data, type = "response")
      
      boot_results_df <- data.frame(
        pred_data[, 1:2],
        boot_pred
      )

      prob_cols <- paste0("prob_", colnames(boot_pred))
      names(boot_results_df)[3:ncol(boot_results_df)] <- prob_cols

      return(boot_results_df)
    }, error = function(e) {
      return(NULL)
    })
  }, simplify = FALSE)
  
  # Remove failed bootstrap samples
  boot_results <- boot_results[!sapply(boot_results, is.null)]
  
  return(boot_results)
}

# t1 <- Sys.time()
# boot_samples <- bootstrap_predictions(n_boot = 2)
# t2 <- Sys.time()
# cat(paste0("Done in ", difftime(t2, t1, units = "secs"), " seconds"))

filepath <- here("Data","bootstrap1_1000.rds")
if(!file.exists(filepath)){
# Run bootstrap (this will take some time)
  cat("Running bootstrap... this may take a few minutes\n")
  t1 <- Sys.time()
  boot_samples <- bootstrap_predictions(n_boot = 1000)  
  t2 <- Sys.time()
  cat(paste0("Done in ", difftime(t2, t1, units = "secs"), " seconds"))
  saveRDS(boot_samples, filepath)
} else{
  cat("Loading previous bootstrap")
  boot_samples <- readRDS(filepath)
}


# Calculate confidence intervals
calculate_boot_ci <- function(boot_samples, prob_cols) {
  ci_results <- pred_results[, 1:2]  # Keep grouping variables
  
  for(col in prob_cols) {
    # Extract this probability across all bootstrap samples
    boot_probs <- sapply(boot_samples, function(x) {
      if(is.null(x) || !col %in% names(x)) return(NA)
      x[[col]]
    })
    
    # Calculate percentile confidence intervals
    ci_lower <- apply(boot_probs, 1, quantile, probs = 0.025, na.rm = TRUE)
    ci_upper <- apply(boot_probs, 1, quantile, probs = 0.975, na.rm = TRUE)
    
    ci_results[[paste0(col, "_ci_lower")]] <- ci_lower
    ci_results[[paste0(col, "_ci_upper")]] <- ci_upper
  }
  
  return(ci_results)
}

# Get confidence intervals
prob_cols <- names(pred_results)[grepl("^prob_", names(pred_results))]
ci_results <- calculate_boot_ci(boot_samples, prob_cols)
```

```{r}
#| message: false
#| output: false

# Function to calculate differences and their bootstrap CIs
calculate_differences_with_ci <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)
  # Get point estimates
  ethnicity_groups <- split(pred_data, pred_data$Ethnicity_collapsed)
  
  results <- list()
  
  for(eth in names(ethnicity_groups)) {
    group_data <- ethnicity_groups[[eth]]
    
    if(nrow(group_data) >= 2) {
      outsourcing_levels <- levels(group_data$outsourcing_status)
      
      if(length(outsourcing_levels) == 2) {
        # Point estimate of difference (level 2 - level 1)
        prob_ratio <- group_data[group_data$outsourcing_status == outsourcing_levels[2], prob_col] / 
              group_data[group_data$outsourcing_status == outsourcing_levels[1], prob_col]

        
        # Bootstrap differences
        boot_ratios <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          boot_group <- boot_data[boot_data$Ethnicity_collapsed == eth, ]
          if(nrow(boot_group) >= 2) {
            boot_group[boot_group$outsourcing_status == outsourcing_levels[2], prob_col] / 
            boot_group[boot_group$outsourcing_status == outsourcing_levels[1], prob_col]
          } else {
            NA
          }
        })
        
        # Remove NAs
        boot_ratios <- boot_ratios[!is.na(boot_ratios)]
        
        if(length(boot_ratios) > 2) {  # Need sufficient bootstrap samples
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_ratios)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[eth]] <- data.frame(
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(outsourcing_levels[2], "vs", outsourcing_levels[1])
          )
        }
      }
    }
  }
  
  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
# Calculate differences for each income level
all_differences <- list()
for(level in income_levels) {
  all_differences[[level]] <- calculate_differences_with_ci(pred_results, boot_samples, level)
}

difference_results <- do.call(rbind, all_differences)
rownames(difference_results) <- NULL

# Apply multiple comparison correction
if(nrow(difference_results) > 0) {
  difference_results$p_value_bonferroni <- p.adjust(difference_results$p_value, method = "bonferroni")
  difference_results$p_value_fdr <- p.adjust(difference_results$p_value, method = "fdr")
  difference_results$significant_bonferroni <- difference_results$p_value_bonferroni < 0.05
  difference_results$significant_fdr <- difference_results$p_value_fdr < 0.05
}

# print(difference_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed,
    income_level = income_group
  )

difference_results2 <- difference_results %>% 
  left_join(counts, by = c("ethnicity", "income_level"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("ethnicity","income_level")]

difference_results3 <- difference_results %>%
  anti_join(drop, by = c("ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 

difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

- `r difference_results_sig$ethnicity[1]` workers are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[2]` workers are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[3]` workers are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[4]` workers are `r difference_results_sig$prob_ratio[4]` times as likely to be in the `r difference_results_sig$income_level[4]` group if they are outsourced compared to not-outsourced (note large confidence interval for this effect - see plot)

```{r}
# Reshape data for plotting
# plot_data <- pred_results %>%
#   pivot_longer(cols = starts_with("prob_"), 
#                names_to = "income_level", 
#                values_to = "probability") %>%
#   mutate(income_level = gsub("prob_", "", income_level)) %>%
#   mutate(income_level = factor(income_level, levels = income_levels))  # Preserve order
# 
# # Plot predicted probabilities
# ggplot(plot_data, aes(x = Ethnicity_collapsed, y = probability,
#                       fill = outsourcing_status)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   facet_wrap(~income_level) +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
#        x = "Ethnicity", y = "Predicted Probability",
#        fill = "Outsourcing Status")

# Plot differences with confidence intervals

ggplot(difference_results3, aes(x = prob_ratio, y = ethnicity, colour = significant_bonferroni)) +
  geom_point() +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_wrap(~income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from not outsourced\nRed dots indicate significant effects"
) +
  scale_colour_manual(values = c("black","red"))

```

###### Post-hoc: Ethnicity within outsourcing

```{r}
calculate_ethnicity_differences_within_outsourcing <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)

  # Get point estimates
  outsourcing_groups <- split(pred_data, pred_data$outsourcing_status)
  
  results <- list()
  
  for(out_group in names(outsourcing_groups)) {
    group_data <- outsourcing_groups[[out_group]]
    
    # Reference group
    ref_data <- group_data[group_data$Ethnicity_collapsed == "White British", ]
    if(nrow(ref_data) == 0) next
    
    # Loop through other ethnicities
    other_ethnicities <- setdiff(unique(group_data$Ethnicity_collapsed), "White British")
    
    for(eth in other_ethnicities) {
      comp_data <- group_data[group_data$Ethnicity_collapsed == eth, ]
      
      if(nrow(comp_data) > 0) {
        # Point estimate of difference (ethnicity - White British)
        prob_ratio <- comp_data[[prob_col]] / ref_data[[prob_col]]

        
        # Bootstrap differences
        boot_diffs <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          
          boot_group <- boot_data[boot_data$outsourcing_status == out_group, ]
          boot_ref <- boot_group[boot_group$Ethnicity_collapsed == "White British", ]
          boot_eth <- boot_group[boot_group$Ethnicity_collapsed == eth, ]
          
          if(nrow(boot_ref) > 0 && nrow(boot_eth) > 0) {
            boot_eth[[prob_col]] / boot_ref[[prob_col]]

          } else {
            NA
          }
        })

        boot_diffs <- boot_diffs[!is.na(boot_diffs)]
        
        
        if(length(boot_diffs) > 2) {
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_diffs)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[paste(out_group, eth, sep = "_")]] <- data.frame(
            outsourcing_status = out_group,
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(eth, "vs White British")
          )
        }
      }
    }
  }

  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
all_ethnicity_differences <- list()
for(level in income_levels) {
  all_ethnicity_differences[[level]] <- calculate_ethnicity_differences_within_outsourcing(pred_results, boot_samples, level)
}

ethnicity_diff_results <- do.call(rbind, all_ethnicity_differences)
rownames(ethnicity_diff_results) <- NULL

# Apply multiple comparison correction
if(nrow(ethnicity_diff_results) > 0) {
  ethnicity_diff_results$p_value_bonferroni <- p.adjust(ethnicity_diff_results$p_value, method = "bonferroni")
  ethnicity_diff_results$p_value_fdr <- p.adjust(ethnicity_diff_results$p_value, method = "fdr")
  ethnicity_diff_results$significant_bonferroni <- ethnicity_diff_results$p_value_bonferroni < 0.05
  ethnicity_diff_results$significant_fdr <- ethnicity_diff_results$p_value_fdr < 0.05
}

# print(ethnicity_diff_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed,
    income_level = income_group
  )

difference_results2 <- ethnicity_diff_results %>%
  left_join(counts, by = c("ethnicity", "income_level","outsourcing_status"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("outsourcing_status","ethnicity","income_level")]

difference_results3 <- ethnicity_diff_results %>%
  anti_join(drop, by = c("outsourcing_status", "ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 


difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))
```

Comparing ethnicities within outsourcing status,

- Among `r difference_results_sig$outsourcing_status[1]` workers, people of `r difference_results_sig$ethnicity[1]` ethnicity are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group compared to White British people.
- Among `r difference_results_sig$outsourcing_status[2]` workers, people of `r difference_results_sig$ethnicity[2]` ethnicity are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group compared to White British people.
- Among `r difference_results_sig$outsourcing_status[3]` workers, people of `r difference_results_sig$ethnicity[3]` ethnicity are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group compared to White British people.


```{r}

ggplot(difference_results3, aes(x = prob_ratio, y = ethnicity, colour = significant_bonferroni)) +
  geom_point(size = 2) +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_grid(outsourcing_status ~ income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        strip.text = element_text(face = "bold"),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability (vs White British)",
    subtitle = "Shown within each outsourcing status and income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from White British\nRed dots indicate significant effects"

  ) +
  scale_colour_manual(values = c("black","red")) 


```

##### Ethnicity 21

```{r}
#| message: false
#| output: false
# Alternative for 3-level variable

ethns_to_drop <- c("Don't think of myself as any of these", "Prefer not to say")

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed_disaggregated)) %>%
  filter(!(Ethnicity_collapsed_disaggregated %in% ethns_to_drop)) %>%
  mutate(Ethnicity_collapsed_disaggregated = droplevels(Ethnicity_collapsed_disaggregated))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Low")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_collapsed_disaggregated,
  design = design,
  family = multinomial(refLevel = "Low")
)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_collapsed_disaggregated", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p
# 
# # Extract coefficients and vcov
# coefs <- coef(mod_svy2)
# vcovs <- vcov(mod_svy2)
# 
# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A model including the ethnicity:outsourcing interaction term significantly improved model fit compared to a model without the interaction term, *X^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients.


```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

###### Post-hoc: Outsourcing within ethnicity

```{r}
#| message: false
#| output: false
#| 
# Create prediction data 
pred_data <- expand.grid(
  outsourcing_status = levels(mod_data$outsourcing_status),
  Ethnicity_collapsed_disaggregated = levels(mod_data$Ethnicity_collapsed_disaggregated),
  Age = mean(mod_data$Age, na.rm = TRUE),
  Gender = levels(mod_data$Gender)[1],
  Has_Degree = levels(mod_data$Has_Degree)[1],
  Region = levels(mod_data$Region)[1],
  BORNUK_labelled = levels(mod_data$BORNUK_labelled)[1]
)

# Get predictions
predictions <- predict(mod_svy2$fit, newdata = pred_data, type = "response")

# Create results dataframe - much simpler!
pred_results <- data.frame(
  pred_data[, 1:2],
  predictions
)

# Add prob_ prefix to column names for clarity
income_levels <- levels(mod_svy2)
prob_cols <- paste0("prob_", colnames(predictions))
names(pred_results)[3:ncol(pred_results)] <- prob_cols
  
# Set up parallel backend (choose number of workers if needed)
plan(multisession)  # Or plan(multisession, workers = 4)

bootstrap_predictions <- function(n_boot = 500) {
  library(survey)
  library(svyVGAM)
  
  set.seed(1234)
  boot_results <- future_lapply(1:n_boot, function(i) {
    # Resample with replacement, respecting weights
    n_obs <- nrow(mod_data)
    boot_indices <- sample(
      1:n_obs,
      size = n_obs,
      replace = TRUE,
      prob = mod_data$NatRepemployees / sum(mod_data$NatRepemployees)
    )
    boot_data <- mod_data[boot_indices, ]
    
    # Create new survey design
    boot_design <- svydesign(
      ids = ~1,
      weights = ~NatRepemployees,
      data = boot_data
    )
    
    # Refit model and predict
    tryCatch({
      boot_model <- svyVGAM::svy_vglm(
        income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + 
          Has_Degree + Region + BORNUK_labelled + 
          outsourcing_status:Ethnicity_collapsed_disaggregated,
        design = boot_design,
        family = multinomial(refLevel = "Mid")
      )
      
      boot_pred <- predict(boot_model$fit, newdata = pred_data, type = "response")
      
      boot_results_df <- data.frame(
        pred_data[, 1:2],
        boot_pred
      )
      
      prob_cols <- paste0("prob_", colnames(boot_pred))
      names(boot_results_df)[3:ncol(boot_results_df)] <- prob_cols
      
      return(boot_results_df)
    }, error = function(e) {
      return(NULL)
    })
  }, future.seed = TRUE)
  
  # Remove failed bootstrap samples
  boot_results <- boot_results[!sapply(boot_results, is.null)]
  return(boot_results)
}

# Run or load
filepath <- here("Data", "bootstrap2.rds")
if (!file.exists(filepath)) {
  cat("Running bootstrap... this may take a few minutes\n")
  boot_samples <- bootstrap_predictions(n_boot = 500)
  saveRDS(boot_samples, filepath)
} else {
  cat("Loading previous bootstrap\n")
  boot_samples <- readRDS(filepath)
}

  
# Calculate confidence intervals
calculate_boot_ci <- function(boot_samples, prob_cols) {
  ci_results <- pred_results[, 1:2]  # Keep grouping variables
  
  for(col in prob_cols) {
    # Extract this probability across all bootstrap samples
    boot_probs <- sapply(boot_samples, function(x) {
      if(is.null(x) || !col %in% names(x)) return(NA)
      x[[col]]
    })
    
    # Calculate percentile confidence intervals
    ci_lower <- apply(boot_probs, 1, quantile, probs = 0.025, na.rm = TRUE)
    ci_upper <- apply(boot_probs, 1, quantile, probs = 0.975, na.rm = TRUE)
    
    ci_results[[paste0(col, "_ci_lower")]] <- ci_lower
    ci_results[[paste0(col, "_ci_upper")]] <- ci_upper
  }
  
  return(ci_results)
}

# Get confidence intervals
prob_cols <- names(pred_results)[grepl("^prob_", names(pred_results))]
ci_results <- calculate_boot_ci(boot_samples, prob_cols)
```

```{r}
#| message: false
#| output: false

# Function to calculate differences and their bootstrap CIs
calculate_differences_with_ci <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)
  # Get point estimates
  ethnicity_groups <- split(pred_data, pred_data$Ethnicity_collapsed_disaggregated)
  
  results <- list()
  
  for(eth in names(ethnicity_groups)) {
    group_data <- ethnicity_groups[[eth]]
    
    if(nrow(group_data) >= 2) {
      outsourcing_levels <- levels(group_data$outsourcing_status)
      
      if(length(outsourcing_levels) == 2) {
        # Point estimate of difference (level 2 - level 1)
        prob_ratio <- group_data[group_data$outsourcing_status == outsourcing_levels[2], prob_col] / 
              group_data[group_data$outsourcing_status == outsourcing_levels[1], prob_col]

        
        # Bootstrap differences
        boot_ratios <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          boot_group <- boot_data[boot_data$Ethnicity_collapsed_disaggregated == eth, ]
          if(nrow(boot_group) >= 2) {
            boot_group[boot_group$outsourcing_status == outsourcing_levels[2], prob_col] / 
            boot_group[boot_group$outsourcing_status == outsourcing_levels[1], prob_col]
          } else {
            NA
          }
        })
        
        # Remove NAs
        boot_ratios <- boot_ratios[!is.na(boot_ratios)]
        
        if(length(boot_ratios) > 2) {  # Need sufficient bootstrap samples
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_ratios)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[eth]] <- data.frame(
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(outsourcing_levels[2], "vs", outsourcing_levels[1])
          )
        }
      }
    }
  }
  
  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
# Calculate differences for each income level
all_differences <- list()
for(level in income_levels) {
  all_differences[[level]] <- calculate_differences_with_ci(pred_results, boot_samples, level)
}

difference_results <- do.call(rbind, all_differences)
rownames(difference_results) <- NULL

# Apply multiple comparison correction
if(nrow(difference_results) > 0) {
  difference_results$p_value_bonferroni <- p.adjust(difference_results$p_value, method = "bonferroni")
  difference_results$p_value_fdr <- p.adjust(difference_results$p_value, method = "fdr")
  difference_results$significant_bonferroni <- difference_results$p_value_bonferroni < 0.05
  difference_results$significant_fdr <- difference_results$p_value_fdr < 0.05
}

# print(difference_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed_disaggregated,
    income_level = income_group
  )

difference_results2 <- difference_results %>% 
  left_join(counts, by = c("ethnicity", "income_level"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("ethnicity","income_level")]

difference_results3 <- difference_results %>%
  anti_join(drop, by = c("ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 


difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

- `r difference_results_sig$ethnicity[1]` workers are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[2]` workers are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[3]` workers are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[4]` workers are `r difference_results_sig$prob_ratio[4]` times as likely to be in the `r difference_results_sig$income_level[4]` group if they are outsourced compared to not-outsourced
- `r difference_results_sig$ethnicity[5]` workers are `r difference_results_sig$prob_ratio[5]` times as likely to be in the `r difference_results_sig$income_level[5]` group if they are outsourced compared to not-outsourced

```{r}
# Reshape data for plotting
# plot_data <- pred_results %>%
#   pivot_longer(cols = starts_with("prob_"), 
#                names_to = "income_level", 
#                values_to = "probability") %>%
#   mutate(income_level = gsub("prob_", "", income_level)) %>%
#   mutate(income_level = factor(income_level, levels = income_levels))  # Preserve order
# 
# # Plot predicted probabilities
# ggplot(plot_data, aes(x = Ethnicity_collapsed_disaggregated, y = probability,
#                       fill = outsourcing_status)) +
#   geom_bar(stat = "identity", position = "dodge") +
#   facet_wrap(~income_level) +
#   theme_minimal() +
#   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
#   labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
#        x = "Ethnicity", y = "Predicted Probability",
#        fill = "Outsourcing Status")

# Plot differences with confidence intervals

ggplot(difference_results3, aes(x = prob_ratio , y = ethnicity, colour = significant_bonferroni)) +
  geom_point() +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_wrap(~income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from not outsourced\nRed dots show significant effects"
) +
  scale_colour_manual(values = c("black","red"))

```

###### Post-hoc: Ethnicity within outsourcing

```{r}
calculate_ethnicity_differences_within_outsourcing <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)

  # Get point estimates
  outsourcing_groups <- split(pred_data, pred_data$outsourcing_status)
  
  results <- list()
  
  for(out_group in names(outsourcing_groups)) {
    group_data <- outsourcing_groups[[out_group]]
    
    # Reference group
    ref_data <- group_data[group_data$Ethnicity_collapsed_disaggregated == "English / Welsh / Scottish / Northern Irish / British", ]
    if(nrow(ref_data) == 0) next
    
    # Loop through other ethnicities
    other_ethnicities <- setdiff(unique(group_data$Ethnicity_collapsed_disaggregated), "English / Welsh / Scottish / Northern Irish / British")
    
    for(eth in other_ethnicities) {
      comp_data <- group_data[group_data$Ethnicity_collapsed_disaggregated == eth, ]
      
      if(nrow(comp_data) > 0) {
        # Point estimate of difference (ethnicity - White British)
        prob_ratio <- comp_data[[prob_col]] / ref_data[[prob_col]]

        
        # Bootstrap differences
        boot_diffs <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          
          boot_group <- boot_data[boot_data$outsourcing_status == out_group, ]
          boot_ref <- boot_group[boot_group$Ethnicity_collapsed_disaggregated == "English / Welsh / Scottish / Northern Irish / British", ]
          boot_eth <- boot_group[boot_group$Ethnicity_collapsed_disaggregated == eth, ]
          
          if(nrow(boot_ref) > 0 && nrow(boot_eth) > 0) {
            boot_eth[[prob_col]] / boot_ref[[prob_col]]

          } else {
            NA
          }
        })

        boot_diffs <- boot_diffs[!is.na(boot_diffs)]
        
        if(length(boot_diffs) > 2) {
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_diffs)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[paste(out_group, eth, sep = "_")]] <- data.frame(
            outsourcing_status = out_group,
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(eth, "vs English / Welsh / Scottish / Northern Irish / British")
          )
        }
      }
    }
  }

  do.call(rbind, results)
}

all_ethnicity_differences <- list()
for(level in income_levels) {
  all_ethnicity_differences[[level]] <- calculate_ethnicity_differences_within_outsourcing(pred_results, boot_samples, level)
}

ethnicity_diff_results <- do.call(rbind, all_ethnicity_differences)
rownames(ethnicity_diff_results) <- NULL

# Apply multiple comparison correction
if(nrow(ethnicity_diff_results) > 0) {
  ethnicity_diff_results$p_value_bonferroni <- p.adjust(ethnicity_diff_results$p_value, method = "bonferroni")
  ethnicity_diff_results$p_value_fdr <- p.adjust(ethnicity_diff_results$p_value, method = "fdr")
  ethnicity_diff_results$significant_bonferroni <- ethnicity_diff_results$p_value_bonferroni < 0.05
  ethnicity_diff_results$significant_fdr <- ethnicity_diff_results$p_value_fdr < 0.05
}

# print(ethnicity_diff_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed_disaggregated,
    income_level = income_group
  )


difference_results2 <- ethnicity_diff_results %>%
  left_join(counts, by = c("ethnicity", "income_level","outsourcing_status"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("outsourcing_status","ethnicity","income_level")]

difference_results3 <- ethnicity_diff_results %>%
  anti_join(drop, by = c("outsourcing_status", "ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 

difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

Comparing ethnicities within outsourcing status,

- Among `r difference_results_sig$outsourcing_status[1]` workers, people of `r difference_results_sig$ethnicity[1]` ethnicity are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group compared to English / Welsh / Scottish / Northern Irish / British people.
- Among `r difference_results_sig$outsourcing_status[2]` workers, people of `r difference_results_sig$ethnicity[2]` ethnicity are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group compared to English / Welsh / Scottish / Northern Irish / British people.
- Among `r difference_results_sig$outsourcing_status[3]` workers, people of `r difference_results_sig$ethnicity[3]` ethnicity are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group compared to English / Welsh / Scottish / Northern Irish / British people.
- Among `r difference_results_sig$outsourcing_status[4]` workers, people of `r difference_results_sig$ethnicity[4]` ethnicity are `r difference_results_sig$prob_ratio[4]` times as likely to be in the `r difference_results_sig$income_level[4]` group compared to English / Welsh / Scottish / Northern Irish / British people.
- Among `r difference_results_sig$outsourcing_status[5]` workers, people of `r difference_results_sig$ethnicity[5]` ethnicity are `r difference_results_sig$prob_ratio[5]` times as likely to be in the `r difference_results_sig$income_level[5]` group compared to English / Welsh / Scottish / Northern Irish / British people.

```{r}
#| height: 10
ggplot(difference_results3, aes(x = prob_ratio , y = ethnicity, colour = significant_bonferroni)) +
  geom_point(size = 2) +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_grid(outsourcing_status ~ income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        strip.text = element_text(face = "bold"),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each outsourcing status and income level",
    y = "",
    x = "Ratio of Predicted Probabilities",
    caption = "Red line indicates no difference from White British\nRed dots indicate significant effects"
  ) +
  scale_colour_manual(values = c("black","red"))


```
We explored the interaction effect using targeted contrasts comparing

1. The effect of each ethnicity versus "White British" within each level of outsourcing
2. The effect of outsourcing within each level of ethnicity

Contrasts were calculated using `survey::svycontrast()` and p values were adjusted for multiple comparisons using the FDR method (Benjamini and Hochberg, 1995). Results were only considered where the sample for the contrast was greater than 10.

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
out_levels <- levels(mod_data$outsourcing_status)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_out <- "Not outsourced"

partA_results <- list()

for (out in out_levels) {
  for (eth in eth_levels) {
    if (eth == ref_eth) next  # skip comparing ref to itself
    if (!paste0("Ethnicity_collapsed_disaggregated", eth) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for ethnicity (if not ref)
    if (eth != ref_eth) {
      vec[paste0("Ethnicity_collapsed_disaggregated", eth)] <- 1
    }

    # Interaction term (only needed if BORNUK != ref)
    if (out != ref_out) {
      interaction_name <- paste0("outsourcing_status", out, ":", "Ethnicity_collapsed_disaggregated", eth)
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partA_results[[paste0(out, ": ", eth, " vs ", ref_eth)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}

# Make into df
partA_df <- bind_rows(
  lapply(names(partA_results), function(name) {
    res <- partA_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partA_df <- partA_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partA_df <- partA_df %>%
  separate(contrast, into = c("outsourcing_status", "ethnicity"), sep = ": ", remove = FALSE) %>%
  separate(ethnicity, into = c("test_ethn","ref_ethn"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("outsourcing_status", "test_ethn" = "Ethnicity_collapsed_disaggregated")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partA <- partA_df %>% filter(p_adj < 0.05)

```

Examining the effect of ethnicity within each level of outsourcing, we find that:

- Among people who are outsourced, "White and Asian" people are `r sig_partA[which(sig_partA$test_ethn == "White and Asian"), "OR"] %>% round(2)` times more likely to be in the low income group than White British people (**NB** sample is 12 for this cell).
-   Among people who are not outsourced, people of "Any other ethnic group" are `r sig_partA[which(sig_partA$test_ethn == "Any other ethnic group"), "OR"]` times as likely (i.e. `r 100 * (1-(sig_partA[which(sig_partA$test_ethn == "Any other ethnic group"), "OR"]))`% less likely) than White British people to be in the low income group (**NB** sample size for this cell is 11).

No other significant differences were observed. The plot below visualises this.

```{r}
# Explcitly specify the data that was used because something happens that drops the prior weights otherwise
data_used <- model.frame(mod_svy2)
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ outsourcing_status*Ethnicity_collapsed_disaggregated,
               type = "response", nuisance = c("BORNUK_labelled"),
               data = data_used)  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British",
                      "White and Asian",
                      "Any other ethnic group")
ems_df %>%
  filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = outsourcing_status, x = prob, colour = Ethnicity_collapsed_disaggregated)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of being in the low income group",
    y = "Outsourcing",
    colour = "Ethnicity"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
out_levels <- levels(mod_data$outsourcing_status)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_out <- "Not outsourced"

partB_results <- list()

for (eth in eth_levels) {
  for (out in out_levels) {
    if (out == ref_out) next  # skip comparing ref to itself
    if (!paste0("outsourcing_status", out) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for BORNUK (if not ref)
    vec[paste0("outsourcing_status", out)] <- 1

    # Interaction term (only if ethnicity != ref)
    if (eth != ref_eth) {
      interaction_name <- paste0("outsourcing_status", out, ":", "Ethnicity_collapsed_disaggregated", eth)
      # Catch flipped ordering, just in case
      if (!interaction_name %in% coefs) {
        alt_name <- paste0("Ethnicity_collapsed_disaggregated", eth, ":", "outsourcing_status", out)
        if (alt_name %in% coefs) interaction_name <- alt_name
      }
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partB_results[[paste0(eth, ": ", out, " vs ", ref_out)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}


# Make into df
partB_df <- bind_rows(
  lapply(names(partB_results), function(name) {
    res <- partB_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partB_df <- partB_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partB_df <- partB_df %>%
  separate(contrast, into = c("ethnicity","outsourcing_status"), sep = ": ", remove = FALSE) %>%
  separate(outsourcing_status, into = c("test_out","ref_out"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("ethnicity" = "Ethnicity_collapsed_disaggregated", "test_out" = "outsourcing_status")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partB <- partB_df %>% filter(p_adj < 0.05)

```

Examining the effect of outsourcing within each ethnicity, we find that:

1.  Among "English / Welsh / Scottish / Northern Irish / British", outsourced workers are `r sig_partB[which(sig_partB$ethnicity == "English / Welsh / Scottish / Northern Irish / British"), "OR"] %>% round(2)` times more likely to be in the low income group than non-outsourced workers.
2.  Among people of "White and Asian" ethnicity, outsourced workers are `r sig_partB[which(sig_partB$ethnicity == "White and Asian"), "OR"] %>% round(2)` times more likely to be in the low income group than non-outsourced workers (**NB** sample for this cell is 12).

For all other ethnicities, there is no significant difference between outsourced and non-outsourced people in the odds of being in the low income group.

The plot below visualises these effects.

```{r}
# Explcitly specify the data that was used because something happens that drops the prior weights otherwise
data_used <- model.frame(mod_svy2)
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ outsourcing_status*Ethnicity_collapsed_disaggregated,
               type = "response", nuisance = c("BORNUK_labelled"),
               data = data_used)  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

# ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British",
#                       "White and Asian",
#                       "Any other ethnic group")
ems_df %>%
  # filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y =Ethnicity_collapsed_disaggregated , x = prob, colour = outsourcing_status)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of being in the low income group",
    y = "Ethnicity",
    colour = "Outsourcing"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

# Analysis - Study 2

Analysis from Study 2 appearing in \[NAME OF REPORT\] primarily employs a descriptive approach to understand the data. We conducted several cross-tabulations focusing on key demographic variables including Migration Status, Low Pay, and Ethnicity.

Due to the extensive number of variables examined, these cross-tabulations are not reproduced in this document. However, researchers can easily recreate all analyses by running the "Crosstabulations.qmd" script available in the GitHub repository associated with this project (see @reproducibility). The repository contains all necessary data files and code to replicate our findings.

\[TO CHECK WITH MORGAN WHETHER ANY OF THE MODELLING IS USED IN THE REPORT\]

# Limitations and Future Research?

-   [ ] Discuss the limitations of the data and the analysis
-   [ ] If something is really burning we can suggest some further analysis that people can do

# Reproducibility {#reproducibility}

All analyses presented in this report can be fully reproduced using the code and data provided in the [Just Knowlegde GitHub repository.](https://github.com/JustKnowledge-UK/jrf_nat_rep/tree/main "GitHub")

------------------------------------------------------------------------

# Appendices

## Study 1 - Age

The table below shows weighted descriptive statistics of the sample, and the figure below shows the frequency of respondents at each single year of age.

```{r}
age_statistics %>%
  dplyr::select(contains('wtd')) %>%
  knitr::kable(
             digits = 2,
             col.names = c("Mean",
                           "Median",
                           "Min",
                           "Max",
                           "Standard dev.")) %>%
  kable_styling(full_width = F)

age_range <- max(data$Age) - min(data$Age)
interval <- 1
n_bins <- (age_range / interval) + 1

data %>%
  ggplot(.,aes(Age)) +
  geom_histogram(colour="black",alpha = .7, bins = n_bins) +
  geom_vline(data =age_statistics, aes(xintercept=median), colour="red") +
  scale_x_continuous(breaks = seq(16, 80, 4)) +
  theme_minimal() +
  scale_colour_manual(values=colours, name = "Outsourcing status") +
  scale_fill_manual(values=colours, name = "Outsourcing status") +
  ylab("Count")
  

```

## Study 1 - Gender

The table below shows the weighted gender breakdown of the sample

```{r}
gender_statistics %>%
  dplyr::select(-percentage) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum)) %>%
  kable(col.names = c(
    "Gender",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```

## Study 1 - Ethnicity {#sec-ethnicity}

The table below shows the weighted ethnicity breakdown using the full range of Census 2021 categories. Note that 'NA' indicates non-responses.

```{r}
ethnicity_statistics %>%
  dplyr::select(-percentage) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum)) %>%
  kable(col.names = c(
    "Ethnicity",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```

We also make use of an aggregated ethnicity variable that groups ethnicities into fewer categories. The table below shows how the Census categories map onto the aggregated categories.

```{r}
ethnicity_cat <- data %>%
  dplyr::select(contains("ethnicity")) %>%
  distinct() %>%
  arrange(Ethnicity) %>%
  dplyr::select(-c(1:2,Ethnicity_collapsed_disaggregated, Ethnicity_binary))

write_csv(ethnicity_cat, file="../outputs/methodology/data/ethnicity_aggregation_mapping.csv")

ethn_colnames = c(
  "Census categories",
  "Aggregated categories"
)
ethnicity_cat %>%
  kable(col.names = ethn_colnames) %>%
  kable_styling(full_width=FALSE)
```

The table below shows the weighted ethnicity breakdown using the aggregated set of categories

```{r}
ethnicity_statistics_collapsed <- data %>%
  group_by(Ethnicity_collapsed) %>%
  summarise(
    n = n(), # count cases
    Frequency = sum(NatRepemployees) # count weighted cases
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    Percentage = 100 * (Frequency / Sum),
    Ethnicity_short = Ethnicity_collapsed
  )

write_csv(ethnicity_statistics_collapsed, file="../outputs/methodology/data/ethnicity_statistics_aggregated.csv")

ethnicity_statistics_collapsed %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum, Ethnicity_short)) %>%
  kable(col.names = c(
    "Ethnicity",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```
