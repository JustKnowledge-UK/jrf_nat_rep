---
title: "Methodology"
author: 
  - Jolyon Miles-Wilson
  - Celestin Okoroji
date: "`r format(Sys.time(), '%e %B %Y')`"
always_allow_html: true
format: 
  html:
    page-layout: full
    self-contained: true
    code-fold: true
    code-tools: true
    code-summary: "Code for Nerds"
    toc: true
    toc-depth: 5
  docx:
    toc: true
    toc-depth: 5
execute: 
  echo: false
  warning: false
  message: false
  outwidth: "100%"
number-sections: true
---

```{r packages}
library(haven)
library(poLCA)
library(Hmisc)
library(dplyr)
library(ggplot2)
library(tidyr)
library(skimr)
library(kableExtra)
#library(MASS)
library(wesanderson)
library(ggrepel)
library(here)
library(emmeans)
#library(devtools)
#install_version("sjstats", version = "0.18.2")
library(sjstats)
library(readr)
library(sjPlot)
library(nnet)
library(apaTables)
library(survey)
library(svyVGAM)
library(aod)
library(stringr)
library(future)
library(future.apply)
```

```{r palette}
rm(list = ls())
options(scipen = 999)
colours <- wes_palette("GrandBudapest2",4,"discrete")
better_colours <- c('#8dd3c7','#bebada','#fb8072','#80b1d3','#fdb462')
many_colours <- c('#a6cee3','#1f78b4','#b2df8a','#33a02c','#fb9a99','#e31a1c','#fdbf6f','#ff7f00','#cab2d6','#6a3d9a','#ffff99','#b15928','#8dd3c7','#ffffb3','#bebada','#fb8072','#80b1d3','#fdb462','#b3de69','#fccde5','#d9d9d9','#bc80bd','#ccebc5','#ffed6f')
```

```{r functions}
extract_glm_coefs <- function(mod, only_sig=F, decimal_places = 3){
  coefs <- coef(summary(mod)) 
  if(only_sig==T){
    coefs <- coefs[which(coefs[,4] < .05),]
  }
  coefs <- as_tibble(coefs, rownames="variable") %>% # specify new variable to add rownames to 
    mutate(
    or = round(exp(Estimate), decimal_places), .after=Estimate
    )
}

extract_lm_coefs <- function(mod, only_sig = F){
  coefs <- coef(summary(mod)) 
  if(only_sig==T){
    coefs <- coefs[which(coefs[,4] < .05),]
  }
  coefs <- as_tibble(coefs, rownames="variable") # specify new variable to add rownames to 
}

get_pvalue <- function(model){
  f_value <- summary(model)$fstatistic
  p_value <- pf(f_value['value'], f_value['numdf'], f_value['dendf'], lower.tail = F)
  attributes(p_value) <- NULL
  return(p_value)
}


# Modified from https://tech.popdata.org/pma-data-hub/posts/2021-08-15-covid-analysis/

tidy.svyVGAM <- function(
  x, 
  conf.int = FALSE, 
  conf.level = 0.95,
  exponentiate = FALSE, 
  ...
){
  ret <- as_tibble(summary(x)$coeftable, rownames = "term")
  colnames(ret) <- c("term", "estimate", "std.error", "statistic", "p.value")
  coefs <- tibble::enframe(stats::coef(x), name = "term", value = "estimate")
  ret <- left_join(coefs, ret, by = c("term", "estimate"))
  
  if (conf.int){
    ci <- broom:::broom_confint_terms(x, level = conf.level, ...)
    ret <- dplyr::left_join(ret, ci, by = "term")
  }
  if (exponentiate){
    ret <- broom:::exponentiate(ret)
  }

  # Split on last colon
  ret <- ret %>%
    mutate(
      y.level = ifelse(str_detect(term, ":"), sub(".*:(.+)$", "\\1", term), NA),
      term = ifelse(str_detect(term, ":"), sub(":(?!.*:).*$", "", term, perl = TRUE), term)
    ) %>%
    arrange(y.level) %>%
    relocate(y.level, .before = term)
  
  ret
}



```

```{r data, output=FALSE}
data <- readRDS("../Data/2025-06-23 - Cleaned_data.rds")

# Specify data to be used in income analysis
income_data <- filter(data, income_drop_all==0)
```

```{r age_stats}
age_statistics <- data %>%
  summarise(
    mean = mean(Age, na.rm=T),
    median = median(Age, na.rm=T),
    min = min(Age,na.rm=T),
    max = max(Age,na.rm=T),
    stdev = sd(Age, na.rm=T),
    wtd_mean = weighted.mean(Age, w = NatRepemployees, na.rm = T),
    wtd_median = wtd.quantile(Age, w = NatRepemployees, probs = c(.5), na.rm = T),
    wtd_min = wtd.quantile(Age, w = NatRepemployees, probs = c(0), na.rm = T),
    wtd_max = wtd.quantile(Age, w = NatRepemployees, probs = c(1), na.rm = T),
    wtd_stdev = sqrt(wtd.var(Age, w = NatRepemployees, na.rm = T)),
    N = n()
  )

readr::write_csv(age_statistics, file = "../outputs/methodology/data/age_stats.csv")

```

```{r gender_stats}
gender_statistics <- data %>%
  group_by(Gender) %>%
  summarise(
    n = n(),
    Frequency = sum(NatRepemployees)
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    percentage = 100 * (n / N),
    wtd_percentage = 100 * (Frequency / Sum)
  )

readr::write_csv(gender_statistics, file="../outputs/methodology/data/gender_statistics.csv")
```

```{r ethnicity_stats}
ethnicity_statistics <- data %>%
  group_by(Ethnicity_labelled) %>%
  summarise(
    n = n(), # count cases
    Frequency = sum(NatRepemployees) # count weighted cases
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    percentage = 100 * (n / N),
    wtd_percentage = 100 * (Frequency / Sum)
  )

write_csv(ethnicity_statistics, file="../outputs/methodology/data/ethnicity_statistics_census.csv")
```

-   [ ] Add css file to improve styling?

# Participants and Design

\[**Insert Name of Report**\] contains data from two studies. The first of these studies was a nationally representative survey of `r nrow(data)` \[**Workers?**\] conducted by Opinium Research between 25th November 2023 and the 21st December 2023.

To achieve a robust estimate of outsourced workers, the sample was weighted by age, gender, and education, region, and ethnicity. The ethnic minority sub-sample (1,435 respondents) was also weighted separately by age, gender, and region to ensure that findings related to ethnic minority adults were fully representative. Targets were estimated using data from the Labour Force Survey, the 2021 Census for England and Wales, and the Northern Ireland Census.

This sample had median age `r age_statistics$median` (SD = `r round(age_statistics$stdev,2)`). `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Female")],0)`% of respondents identified as female, `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Male")],0)`% as male, `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Other")],2)`% as other, and `r round(gender_statistics$percentage[which(gender_statistics$Gender == "Prefer not to say")],2)`% preferred not to identify a gender. `r round(ethnicity_statistics$percentage[which(ethnicity_statistics$Ethnicity_labelled == "English / Welsh / Scottish / Northern Irish / British")],0)`% of respondents identified as 'English / Welsh / Scottish / Northern Irish / British' (see @sec-ethnicity for a detailed breakdown of ethnicity).

A follow-up survey of Outsourced workers (as defined in @sec-study1) was conducted by Opinium Research between 19th April to the 16th of May 2024 with a total sample of 1814. The purpose of this study was to further probe the experiences of outsourced workers and to understand the impact of outsourcing on their work and lives (see @sec-study2).

Soft quotas on age, gender, and region were implemented to ensure broad representativeness, and the final data was weighted to targets based on age, gender, education, region, and ethnicity. The targets were based on the weighted data from study 1. The survey population had a mean Age of 38.9 (SD = 13.0). 42.4% Female and 65.5% White British. A small proportion of respondents had previously participated in study 1 and met the outsourced criteria (5%).

Both surveys were administered online.

An initial pilot study aimed to refine the diagnostic questions used to identify outsourced workers, ensuring they aligned with JRF's initial definition and could be accurately answered by survey respondents. The diagnostic questions and feedback follow-ups were run on Opinium’s political omnibus, a nationally and politically representative sample of 2,055 UK adults between 30 August and 1 September 2023. The questions were filtered to those in work, resulting in a total of 1,200 respondents. Data from this pilot study is not reported here.

\[**POTENTIALLY ADD A TABLE HERE WITH CROSSTABS FOR THE TWO SAMPLES OR TABBED VISUALISATIONS**\]

# Measures

## Study 1- Nationally representative survey {#sec-study1}

The survey covered personal demographics, employment demographics (e.g. occupation, hours worked, pay), and the outsourced diagnostic questions. The main objectives were to ensure an accurate estimate of the size and demographic makeup of the outsourced population, and to analyse the data alongside the Labour Force Survey (LFS). \[MORGAN - **WHAT EXACTLY WAS INTENDED TO BE COMPARABLE? SPECIFICALLY WHICH QUESTIONS HAVE BEEN REPLICATED FROM TLFS**\]

Comparability to the LFS posed challenges, primarily because the LFS is conducted face-to-face, with interviewers playing a significant role in ensuring the accuracy of data and respondents' understanding of questions. However, as the Transformed Labour Force Survey (TLFS)– an online first version of the survey set to replace the LFS— was underway, where possible we used the TLFS versions. While question wording is still under review, this was deemed the best approach, as some TLFS waves had already taken place and findings on comparability to LFS \[MORGAN - **CITATION**\].

-   [x] I believe some questions were replicated from national survey's so lets explicate that
-   [x] Discuss the issue of pay calcs (e.g. basic overview and then refer to the section on it)
-   [ ] Discuss the issue of defining outsourcing ((e.g. basic overview and then refer to the section on it))
-   [ ] link to the data dictionary

### Income calculations (\[**perhaps more detailed than necessary in this section**\])

Respondents could choose how they provided information about their income. Firstly, they could choose the payment period for which to express their income from the following options:

-   Annually / per year
-   Monthly
-   Weekly
-   Hourly

Secondly, they could choose either an 'open' form of reporting or a 'closed' form. The open form required respondents to type in their pay for the payment period they chose. The closed form required respondents to select which income bracket their pay belonged to from a list of options.

The annual options were:

```{r}
ops <- levels(data$INCOME_CLOSED_ANNUAL_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The monthly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_MONTHLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The weekly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_WEEKLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

The hourly options were:

```{r}
ops <- levels(data$INCOME_CLOSED_HOURLY_labelled)
```

`r paste0("- ", ops, collapse = "\n")`

```{r}
data_subset <- data %>%
  dplyr::select(c(ID, contains("INCOME", ignore.case = F))) %>%
  dplyr::select(!ends_with("labelled") & !ends_with("FREQ") & !ends_with("2"))

number_open <- data_subset %>%
  filter(!is.na(INCOME_OPEN_1)) %>%
  nrow()

number_closed <- data_subset %>%
  filter(is.na(INCOME_OPEN_1)) %>%
  dplyr::select(c(ID, contains("CLOSED"))) %>%
  nrow()

# but also check how many "prefer not to say"
closed_income <- data %>%
  filter(is.na(INCOME_OPEN_1)) %>%
  dplyr::select(c(ID, contains("INCOME", ignore.case = F))) %>%
  dplyr::select(ends_with("labelled"))

pref_not_say <- closed_income %>%
  rowwise() %>%
  summarise(
    sum = sum(c_across(everything()) == "Prefer not to say", na.rm=TRUE)
  ) %>%
  summarise(
    total_not_answered = sum(sum)
  )

closed_answered <- number_closed - pref_not_say$total_not_answered

```

`r number_open` respondents answered using the open method. `r closed_answered` respondents answered using the closed method. `r nrow(data) - sum(number_open,closed_answered)` did not answer either.

We equivalised respondents' income across the reporting options in two steps. Firstly, we converted closed income responses to continuous numeric values by taking the midpoint of the income brackets, or the value of the "less than" and "over" values. For example, a closed response of "£5,600 up to £11,200" would be converted to £8400; and a closed response of "Less than £5,600 a year" would be converted to £5600. These converted closed responses were combined with the open responses to produce a single continous income variable across payment periods.

```{r}
weeks_in_year <- 365 / 7 # if we're being pedantic (this is 52.14 weeks)
min_holiday_entitlement <- 28
non_working_weeks <- min_holiday_entitlement/5
working_weeks <- weeks_in_year - non_working_weeks
```

Next, we expressed all respondents' income in annual, weekly, and hourly periods. To do this we made an assumption about the number of working weeks in a year based on the minimum holiday entitlement of 28 days. We calculated the total number of weeks in a year as 365 / 7 = `r round(weeks_in_year,2)`, the total number of non-working weeks as 28 / 5 = `r round(non_working_weeks,2)`, and thus the total number of working weeks as `r round(weeks_in_year,2)` - `r round(non_working_weeks,2)` = `r round(working_weeks,2)`.

With this figure and the number of hours worked per week, we could convert incomes provided in one payment period to another. The table below shows how this was achieved.

\[ADD OUTLIER EXCLUSION CRITERIA\]

```{r}
conversion_table <- data.frame("Income provided..." = 
                                 c("... annually",
                                   "... monthly",
                                   "... weekly",
                                   "... hourly"),
                               "Formula to convert to annual" = 
                                 c("= income",
                                   "= income x 12",
                                   "= income x working weeks",
                                   "= income x hours per week x working weeks "),
                               "Formula to convert to weekly" = 
                                 c("= income / working weeks",
                                   "= (income x 12) / working weeks",
                                   "= income",
                                   "= income x hours per week"),
                               "Formula to convert to hourly" = 
                                 c("= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week",
                                   "= weekly income / hours worked per week"))

conversion_table %>%
  kable(col.names = c(
    "Income provided...", 
    "Formula to convert to annual",
    "Formula to convert to weekly",
    "Formula to convert to hourly")) %>%
  kable_styling(full_width = T)
```

## Study 2 - Outsourced workers survey {#sec-study2}

In the follow up survey of outsourced workers the data focuses on workers experiences and perceptions of outsourced work. The dataset is large containing 214 variables. Analysis of all the variables was beyond the scope of the report thus we focus on a subset of the data pertaining to outsourced workers experiences of rights violations, discrimination, job clarity, benefits and drawbacks of outsourced work and potential improvements to their work arrangements.

In the process of data cleaning we set hours per week to NA for participants who gave an impossible number of work hours per week (e.g. $\ge$ 168, *N*=11). Relatedly we construct variables to determine hourly, weekly, monthly and annual pay as in study 1 and flag outlier responses. Through this method 11.22% (183) participants were dropped from all subsequent analysis leaving a final sample of 1631 participants. We also determine whether the participant is low paid using the method from study 1.

A data dictionary is available from the [Github Repository](https://github.com/JustKnowledge-UK/jrf_nat_rep "Just Knowledge GitHub") associated with this project along with all code used to produce the analyses.

# Analysis - Study 1

-   [x] Determining if the worker is outsourced
-   [x] Calculating Low/Not Low pay
-   [x] Explain the analyses (e.g. any models that actually appear in the final output)

## Defining outsourcing

Workers were defined as outsourced based on responses to a set of diagnostic questions. Three questions asked respondents directly about whether they considered themselves outsourced and/or agency workers.

The first of these questions asked respondents to indicate directly whether they considered themselves outsourced by selecting one of the following options:

1.  I am sure I’m an outsourced worker
2.  I think I might be an outsourced worker
3.  I am not an outsourced worker

The second question asked respondents to indicate whether they considered themselves an agency worker by selecting from three options. For respondents who responded 1 or 2 to question 1, the options were:

1.  I am sure that I’m also an agency worker
2.  I think I might also be an agency worker
3.  I am not an agency worker

For respondents who responded 3 to question 1, the options were:

1.  I am sure that I’m an agency worker
2.  I think I might be an agency worker
3.  I am not an agency worker

Respondents were also asked whether the work they do was long- or short-term by selecting one of:

1.  I’m hired to do work which an organisation needs doing on a long-term or ongoing basis.
2.  I’m hired to do work which an organisation needs doing on a short-term or temporary basis.
3.  Other (please specify)

Finally, respondents were asked about aspects of their work that might indicate that the work they do is outsourced work. Respondents were asked: "Please read each of the following statements and tell us whether or not they are true for you and your work." The statements were:

1.  I am paid by one organisation but I do work for a different organisation.
2.  The organisation I’m paid by is a ‘third party’ organisation which other organisations hire to do work for them, rather than doing that w \[**FIND QUESTION IN DATA DICT**\]
3.  My employer / agency provides people to do work for other organisations (i.e. they might provide people to do cleaning, security, administratio \[**FIND QUESTION IN DATA DICT**\]
4.  On a day-to-day basis, I’m paid by one organisation but I get given tasks or instructions by people who are paid by a different organisation.
5.  I am paid by one organisation, but I work in a space which has the logo or branding of a different organisation.
6.  I wear a uniform which has the logo or branding of my employer / agency, and which marks me out as being paid by a different organisation to so \[**FIND QUESTION IN DATA DICT**\]

Workers were categorised into three mutually exclusive sub groups based on their responses to the above questions.

1.  A respondent was categorised as '**clearly outsourced**' if they responded 'I am sure I'm an outsourced worker' or 'I think I might be an outsourced worker' **and** 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis.'.

2.  A respondent was categorised as '**likely agency**' if they responded 'I am sure that I'm an agency worker' **and** 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis', **excluding** those people who are already defined as being 'clearly outsourced'.

3.  A respondent was categorised as belonging to the '**high indicators**' group if they responded TRUE to five or six \[CAN THIS BE EXPRESSED AS $\ge$ 5?\] of the outsourcing indicators, as well as responding 'I’m hired to do work which an organisation needs doing on a long-term or ongoing basis', **excluding** those people who were already defined as 'clearly outsourced' or 'likely agency'.

Together, these three sub groups form the classification of 'outsourced workers' considered in this report. Throughout the report, the term 'outsourced' refers to workers across the three sub groups. In places, analysis considers the three sub groups separately, in which case the groups will be referred to by name as 'clearly outsourced', 'likely agency', or 'high indicators'.

## Defining low pay

A 'low pay' binary variable was created by implementing an income threshold below which respondents were considered to be on a relatively low income. In line with with the [Organisation for Economic Co-operation and Development](https://www.oecd.org/en/data/indicators/incidence-of-low-and-high-pay.html), we set the threshold at two-thirds median weekly income. The two-thirds threshold was based on the weekly median income for respondents' region to account for regional variations in earnings.

Regional weekly median income values were drawn from the [Annual Survey of Hours and Earnings](https://www.ons.gov.uk/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/earningsandhoursworkedukregionbyagegroup) (2023 provisional edition). Respondents whose reported weekly income was less than or equal to two-thirds of the median weekly income in their region were assigned to the 'low pay' group, while those whose reported weekly income was greater than two-thirds of the median weekly income in their region were assigned to the 'not low pay' group.

## Aggregating ethnicity

For reference, the table below provides a disambiguation of how ethnicities have been grouped in this analysis.

For analyses using the disaggregated (survey) categories with 21 levels, the reference category is "English / Welsh / Scottish / Northern Irish / British".

For analyses using the aggregated categories with 9 levels, the reference category is "White British"

For analyses using teh aggregated categories with 4 levels, the reference category is "White".

```{r}
ethnicity_cat <- data %>%
  dplyr::select(contains("ethnicity")) %>%
  distinct() %>%
  arrange(Ethnicity) %>%
  dplyr::select(-c(1:2,Ethnicity_collapsed_disaggregated))

ethn_colnames = c(
  "Ethnicity: Survey (21 levels)",
  "Ethnicity: Aggregated (9 levels)",
  "Ethnicity: Binary (4 levels)"
)
ethnicity_cat %>%
  kable(col.names = ethn_colnames) %>%
  kable_styling(full_width=FALSE)
```

## Models

In this section we describe the statistical models used in the report. In all models we applied survey weights so that the estimates can be considered representative of employees nationally.

### Outsourced pay gap

To investigate the pay gap been outsourced and non-outsourced workers we constructed a linear regression model predicting annual and weekly income (in separate models) from outsourcing membership. We included other variables in the model to account for their potential influence on income. The full regression model can be expressed as:

$$
Income = Age + Gender + Education + Ethnicity + Migration + Region + Outsourcing
$$

where

-   Income is a continuous numeric variable indicating a the respondent's income (weekly or annual, in different models)
-   Age is a continuous numeric variable indicating the respondent's age
-   Gender is a categorical variable with three levels:
    -   Male (reference category)
    -   Female
    -   Other
-   Education is a categorical variable indicating whether the respondent has a degree, with three levels:
    -   Yes (reference category)
    -   No
    -   Don't know
-   Ethnicity is a categorical variable with eight levels:
    -   White British (reference category)
    -   Arab/British Arab
    -   Asian/Asian British
    -   Black/African/Caribbean/Black British
    -   Mixed/Multiple ethnic group
    -   Other ethnic group
    -   Prefer not to say
    -   White other
    -   Don't think of myself as any of these
-   Migration is a categorical variable indicating when the respondent arrived in the UK, with 10 levels:
    -   I was born in the UK (reference category)
    -   Within the last year
    -   Within the last 3 years
    -   Within the last 5 years
    -   Within the last 10 years
    -   Within the last 15 years
    -   Within the last 20 years
    -   Within the last 30 years
    -   More than 30 years ago
    -   Prefer not to say
-   Region is a categorical variable indicating the respodent's region of residence, with 12 levels:
    -   London (reference category)
    -   East Midlands
    -   East of England
    -   North East
    -   North West
    -   Northern Ireland
    -   Scotland
    -   South East
    -   South West
    -   Wales
    -   West Midlands
    -   Yorkshire and the Humber
-   Outsourcing is a categorical variable indicating whether the respondent is outsourced, with two levels:
    -   Not outsourced (reference category)
    -   Outsourced

```{r}
#| output: false
#| warning: false
#| message: false

# Annual income
# Intercept only
mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

mod_base <- lm(income_annual_all ~ 1, mod_data, weights = NatRepemployees)
# H1
mod_annual <- lm(income_annual_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled, mod_data, weights = NatRepemployees)

summary(mod_annual)

# F and p
f_annual <- round(anova(mod_base, mod_annual)[2,"F"],2)
p_annual <- anova(mod_base, mod_annual)[2,"Pr(>F)"]
if(p_annual < .001){
  p_annual = "< .001"
} else{
  p_annual = paste0("= ",round(p_annual,3))
}

# Degrees of freedom
dfs_annual <- as.list(anova(mod_base, mod_annual)[2,c("Df","Res.Df")])
# R2
rsquare_annual <- round(summary(mod_annual)$r.squared,2)

# Weekly income
# Intercept only
mod_base <- lm(income_weekly_all ~ 1, mod_data, weights = NatRepemployees)
# H1
mod_weekly <- lm(income_weekly_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled, mod_data, weights = NatRepemployees)
summary(mod_weekly)

# F and p
f_weekly <- round(anova(mod_base, mod_weekly)[2,"F"],2)
p_weekly <- anova(mod_base, mod_weekly)[2,"Pr(>F)"]
if(p_weekly < .001){
  p_weekly = "< .001"
} else{
  p_weekly = paste0("= ",round(p_weekly,3))
}

# Degrees of freedom
dfs_weekly <- as.list(anova(mod_base, mod_weekly)[2,c("Df","Res.Df")])
# R2
rsquare_weekly <- round(summary(mod_weekly)$r.squared,2)

```

The annual income model was statistically significant (*R^2^* = `r rsquare_annual`, *F*(`r dfs_annual[[1]]`, `r dfs_annual[[2]]`) = `r f_annual`, *p* `r p_annual`). The table below shows the coefficients for the annual income model.

```{r}
labels <- c(
  'Intercept',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Outsourcing: Outsourced',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)
  
tab_model(mod_annual, pred.labels = labels, dv.labels = "Annual income")
```

As expected, the model statistics for weekly income model were identical to the those of the annual income model. The model was statistically significant (*R^2^* = `r rsquare_weekly`, *F*(`r dfs_weekly[[1]]`, `r dfs_weekly[[2]]`) = `r f_weekly`, *p* `r p_weekly`). The table below shows the coefficients for the weekly income model.

```{r}
tab_model(mod_weekly, pred.labels = labels, dv.labels = "Weekly income")
```

### Gender pay gap

```{r}
annual_gender_coef <- extract_lm_coefs(mod_annual, only_sig = T) %>%
  filter(variable == "GenderFemale")

weekly_gender_coef <- extract_lm_coefs(mod_weekly, only_sig = T) %>%
  filter(variable == "GenderFemale") 
```

The above model was also used to assess a possible gender pay gap. As shown in the preceding two tables, there is a significant difference in pay between men and women. Annually, women earn £`r annual_gender_coef$Estimate %>% round(2) %>% abs()` less than men. Per week, women earn £`r weekly_gender_coef$Estimate %>% round(2) %>% abs()` less than men.

We next explored whether outsourcing compounds this gender pay gap by adding an interaction term into the previous models so that

$$
Income = Age + Gender + Education + Ethnicity + Migration + Region + Outsourcing + Gender:Outsourcing
$$

```{r}
#| output: false
#| warning: false
#| message: false
#| 
mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

# Annual income
# H1
mod_annual_int <- lm(income_annual_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled + Gender:outsourcing_status, income_data, weights = NatRepemployees)

summary(mod_annual_int)

# F and p
anova_test <- anova(mod_annual, mod_annual_int)
f_annual <- anova_test[2,"F"] %>% round(2)
p_annual <- anova_test[2,"Pr(>F)"]
if(p_annual < .001){
  p_annual = "< .001"
} else{
  p_annual = paste0("= ",round(p_annual,3))
}

# Degrees of freedom
dfs_annual <- as.list(anova_test[2,c("Df","Res.Df")])
# R2
rsquare_annual <- round(summary(mod_annual_int)$r.squared,2)

# Weekly income

# H1
mod_weekly_int <- lm(income_weekly_all ~ Age + Gender + Has_Degree + Ethnicity_collapsed + Region + outsourcing_status + BORNUK_labelled + Gender:outsourcing_status, income_data, weights = NatRepemployees)
summary(mod_weekly_int)

# F and p
anova_test <- anova(mod_weekly, mod_weekly_int)

f_weekly <-  anova_test[2,"F"] %>% round(2)
p_weekly <- anova_test[2,"Pr(>F)"]
if(p_weekly < .001){
  p_weekly = "< .001"
} else{
  p_weekly = paste0("= ", round(p_weekly,3))
}

# Degrees of freedom
dfs_weekly <- as.list(anova_test[2,c("Df","Res.Df")])
# R2
rsquare_weekly <- round(summary(mod_weekly_int)$r.squared,2)

```

For both models, adding the interaction effect did not improve model fit (*R^2^* = `r rsquare_weekly`, *F*(`r dfs_weekly[[1]]`, `r dfs_weekly[[2]]`) = `r f_weekly`, *p* `r p_weekly`). The tables below show the coefficients for each model.

```{r}
labels <- c(
  'Intercept',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  'Education: Has degree',
  "Education: Don't know",
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Outsourcing: Outsourced',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say',
  'Interaction: Outsourcing x Gender Female',
  'Interaction: Outsourcing x Gender Other',
  'Interaction: Outsourcing x Gender Prefer not to say'
)
  
tab_model(mod_annual_int, pred.labels = labels, dv.labels = "Annual income")
tab_model(mod_weekly_int, pred.labels = labels, dv.labels = "Weekly income")

```

```{r}
ems <- emmeans(mod_annual_int, specs = "Gender", by = "outsourcing_status", nuisance = "BORNUK_labelled")
cons <- summary(contrast(ems, "pairwise",adjust="tukey"))
sig_cons <- cons %>% filter(p.value < .05)

```

```{r}
ems <- emmeans(mod_annual_int, specs = "outsourcing_status", by = "Gender", nuisance = "BORNUK_labelled")
cons <- summary(contrast(ems, "pairwise",adjust="tukey"))
sig_cons2 <- cons %>% filter(p.value < .05) 

```

The interaction term is non-significant. Estimated marginal means show that:

-   Among not outsourced workers, men are paid £`r sig_cons %>% filter(outsourcing_status == "Not outsourced") %>% pull(estimate) %>% abs() %>% round(2)` more than women
-   Among outsourced workers, men are paid £`r sig_cons %>% filter(outsourcing_status == "Outsourced") %>% pull(estimate) %>% abs() %>% round(2)` more than women
-   Among men, not outsourced workers are paid £`r sig_cons2 %>% filter(Gender == "Male") %>% pull(estimate) %>% abs() %>% round(2)` more than outsourced workers.
-   Among women, not outsourced workers are paid £`r sig_cons2 %>% filter(Gender == "Female") %>% pull(estimate) %>% abs() %>% round(2)` more than outsourced workers.

The plot below illustrates the main effects that men are paid more than women and that outsourced men and women are paid less than non-outsourced men and women. The lack of interaction indicates that the difference in pay between men and women does not significantly differ between outsourced and non-outsourced people.

```{r}
sjPlot::plot_model(mod_annual_int, type = "pred", legend.title="", terms = c("outsourcing_status","Gender"), dodge=0.5) +#
  
  coord_flip() +
  xlab("") + ylab("Likelihood of being outsourced") +
  theme_minimal() 
```

### Demographic models

#### Ethnicity

Several regressions were run to assess the likelihood of being outsourced from demographics. These models underlie the claims in the report in relation to ethnicity, migration, and gender.

The overall model was defined as:

$$
Outsourcing = Ethnicity + Age + Gender + Education + Region + Migration
$$

where

-   Outsourcing is a categorical variable indicating whether the respondent is outsourced, with two levels:
    -   Not outsourced (reference category)
    -   Outsourced
-   Age is a continuous numeric variable indicating the respondent's age
-   Gender is a categorical variable with three levels:
    -   Male (reference category)
    -   Female
    -   Other
-   Education is a categorical variable indicating whether the respondent has a degree, with three levels:
    -   Yes (reference category)
    -   No
    -   Don't know
-   Migration is a categorical variable indicating when the respondent arrived in the UK, with 10 levels:
    -   I was born in the UK (reference category)
    -   Within the last year
    -   Within the last 3 years
    -   Within the last 5 years
    -   Within the last 10 years
    -   Within the last 15 years
    -   Within the last 20 years
    -   Within the last 30 years
    -   More than 30 years ago
    -   Prefer not to say
-   Region is a categorical variable indicating the respodent's region of residence, with 12 levels:
    -   London (reference category)
    -   East Midlands
    -   East of England
    -   North East
    -   North West
    -   Northern Ireland
    -   Scotland
    -   South East
    -   South West
    -   Wales
    -   West Midlands
    -   Yorkshire and the Humber

For this exploration we modelled ethnicity in three ways.

1.  As a categorical variable with four levels:
    -   White (reference category)
    -   Not White
    -   Don't think of myself as any of these
    -   Prefer not say
2.  As a categorical variable with eight levels:
    -   White British (reference category)
    -   Arab/British Arab
    -   Asian/Asian British
    -   Black/African/Caribbean/Black British
    -   Don't think of myself as any of these
    -   Mixed/Multiple ethnic group
    -   Other ethnic group
    -   Prefer not to say
    -   White other
3.  As a categorical variable with 21 levels:
    -   English/Welsh/Scottish/Northern Irish/British (reference category)
    -   Irish
    -   Gypsy or Irish Traveller
    -   Roma
    -   Any other White background
    -   White and Black Caribbean
    -   White and Black African
    -   White and Asian
    -   Any other Mixed/Multiple ethnic background
    -   Indian
    -   Pakistani
    -   Bangladeshi
    -   Chinese
    -   Any other Asian background
    -   African
    -   Caribbean
    -   Any other Black, Black British, or Caribbean background
    -   Arab
    -   Any other ethnic group
    -   Don't think of myself as any of these
    -   Prefer not to say

We used `svyglm()` from the `survey` package to construct survey-weighted generalised linear models. This approach allows us to take into account survey weights to produce design-based standard errors by assuming a 'quasibinomial' distribution to the data. Specifically, the survey-weighted data contains overdispersion; the variance is greater than expected by a binomial distribution (which assumes variance = mean(1 - mean)). The quasibinomial distribution estimates a dispersion parameter that allows the variance to be greater than expected by the true binomial distribution. For more information see Lumley, Thomas, and Alastair Scott. ‘Fitting Regression Models to Survey Data’. Statistical Science 32, no. 2 (2017): 265–780.

We used Rao–Scott adjusted Wald tests to compare nested survey-weighted models fit using a quasibinomial family. This method accounts for the survey design and is appropriate given that quasi-likelihood models do not support likelihood-ratio testing. For more information see Rao, J. N. K., and A. J. Scott. ‘On Chi-Squared Tests for Multiway Contingency Tables with Cell Proportions Estimated from Survey Data’. The Annals of Statistics 12, no. 1 (March 1984): 46–60. https://doi.org/10.1214/aos/1176346391.

```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

# Step 1: Create a survey design object
design <- svydesign(
  ids = ~1,                                
  weights = ~NatRepemployees,          
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_binary + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 1, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Ethnicity: Not White',
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)


tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

```{r ethnicity-aggregated}
#| output: false
#| warning: false
#| message: false


mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,            
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_collapsed + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 2, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

```{r ethnicity-disaggregated}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree +  Region + BORNUK_labelled,
  design = design,
  family = quasibinomial()
)

# summary(mod_svy2)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
ethn_coef <- coefs %>% filter(stringr::str_detect(variable, "Ethnicity"))


wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])

```

For model 3, a saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Migration: Arrived within the last year',
  'Migration: Arrived within the last 3 years',
  'Migration: Arrived within the last 5 years',
  'Migration: Arrived within the last 10 years',
  'Migration: Arrived within the last 15 years',
  'Migration: Arrived within the last 20 years',
  'Migration: Arrived within the last 30 years',
  'Migration: Arrived more than 30 years ago',
  'Migration: Prefer not to say'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

#### Migration

We next focus on predicting whether a person was outsourced based on wehther the person was born in the UK. This binary variable was constructed by collapsing the 10-level migration variable down into two levels, so that "I was born in the UK" becomes "Born in UK", and all levels apart from "I was born in the UK" and "Prefer not to say" become "Not born in UK".

```{r}
#| output: false
#| warning: false
#| message: false


mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))


design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ 1,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A saturated model including all variables was a significantly better fit to the data than an intercept-only model, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber'
)

tab_model(mod_svy2, 
          pred.labels = labels, 
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

#### Gender

```{r}
gender_coefs <- coefs %>%
  filter(variable == "GenderFemale")
```

We used the same generalised linear model as in the previous section to estimate the effect of Gender on outsourcing, where Gender is a categorical variable with four levels:

-   Male (reference category)
-   Female
-   Prefer not to say
-   Other

The model indicates that women are `r gender_coefs$or %>% round(2)` times as likely (i.e. `r 100 * (1 - gender_coefs$or %>% round(2))`% less likely) to be outsourced than men.

#### Age

```{r}
age_coefs <- coefs %>%
  filter(variable == "Age")
  
```

Again using the same model, we found that age was a significant predictor of the likelihood of being outsourced. The model indicates that for each year older a worker is, they are `r age_coefs$or %>% round(2)` times as likely (i.e. `r (1-age_coefs$or %>% round(2))*100`% less likely) to be outsourced.

We also explored how age predicted whether a person was on low pay. The model formula is:

$$
Income Group =  Age + Outsourcing + Ethnicity + Gender + Education + Region + Migration
$$

```{r}
#| output: false
#| warning: false
#| message: false
# 
# mod_data <- income_data %>%
#   filter(!is.na(Ethnicity_collapsed))
#   
# design <- svydesign(
#   ids = ~1,                             
#   weights = ~NatRepemployees,             
#   data = mod_data
# )
# 
# # Step 2: Fit the model with quasibinomial family
# mod_svy1 <- svyglm(
#   income_group ~ 1,
#   design = design,
#   family = quasibinomial()
# )
# 
# # Step 2: Fit the model with quasibinomial family
# mod_svy2 <- svyglm(
#   income_group ~ Age + outsourcing_status + Ethnicity_collapsed_disaggregated + Gender + Has_Degree + Region + BORNUK_binary,
#   design = design,
#   family = quasibinomial()
# )
# 
# coefs <- extract_glm_coefs(mod_svy2, only_sig=T)
# 
# wald <- anova(mod_svy1,mod_svy2, method = "Wald")
# 
# # F and p
# f <- round(wald[["Ftest"]] %>% as.numeric(),2)
# p <- wald[["p"]] %>% as.numeric()
# 
# if(p < .001){
#   p = "< .001"
# } else{
#   p = paste0("= ",round(p,3))
# }
# 
# # Degrees of freedom
# dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

```{r}
#| output: false
#| message: false
# Alternative for 3-level variable

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ Age + outsourcing_status + Ethnicity_collapsed_disaggregated + Gender + Has_Degree + Region + BORNUK_binary,
  design = design,
  family = multinomial(refLevel = "Mid")  # Replace "Low" with your reference category
)

# summary(mod_svy2)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)

# Remove intercepts
non_intercept_idx <- !grepl("(Intercept)", names(coefs))

# Subset coefficients and vcov accordingly
coefs_non_intercept <- coefs[non_intercept_idx]
vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]

# Perform Wald test
wald <- wald.test(
  Sigma = vcovs_non_intercept, 
  b = coefs_non_intercept, 
  L = diag(length(coefs_non_intercept))
)
wald_stats <- wald[["result"]][["chi2"]]
p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A saturated model including all variables was a significantly better fit to the data than an intercept-only model, *X\^2*(`r wald_stats[2]`) = `r wald_stats[1]`, *p* `r p`. The table below shows the model coefficients.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

#### Ethnicity-migration interaction

We next explored whether there was an interaction between ethnicity and migration in predicting outsourcing using generalised linear models by adding an interaction effect to the model predicting outsourcing above so that the model formula is:

$$
Outsourcing = Ethnicity + Age + Gender + Educaton + Region + Migration + Ethnicity:Migration
$$

where Ethnicity:Migration represents the interaction term.

We did this twice: first for the aggregated eight-level ethnicity variable, and then for the disaggregated 21-level variable.

##### Ethnicity 9

```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))
  
design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

summary(mod_svy1)
# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary * Ethnicity_collapsed + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A model including the ethnicity:migration interaction term had significantly improved fit compared to a model without the interaction term, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  'Ethnicity: Arab/British Arab',
  'Ethnicity: Asian/Asian British',
  'Ethnicity: Black/African/Caribbean/Black British',
  "Ethnicity: Don't think of myself as any of these",
  'Ethnicity: Mixed/Multiple ethnic group',
  'Ethnicity: Other ethnic group',
  'Ethnicity: Prefer not to say',
  'Ethnicity: White other',
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  'Interaction: Not born in UK x Arab/Arab British',
  'Interaction: Not born in UK x Asian/Asian British',
  'Interaction: Prefer not to say x Asian/Asian British',
  'Interaction: Not born in UK x Black/African/Caribbean/Black British',
  'Interaction: Prefer not to say x Black/African/Caribbean/Black British',
  "Interaction: Not born in UK x Don't think of myself as any of these",
  'Interaction: Not born in UK x Mixed/Multiple ethnic group',
  'Interaction: Prefer not to say x Mixed/Multiple ethnic group',
  'Interaction: Not born in UK x Other ethnic group',
  'Interaction: Not born in UK x Prefer not to say',
  'Interaction: Prefer not to say x Prefer not to say',
  'Interaction: Not born in UK x White other',
  'Interaction: Prefer not to say x White other'
  
)

tab_model(mod_svy2, 
          pred.labels = labels,
          dv.labels = "Outsourcing",
          show.r2 = FALSE)
```

###### Post-hoc

We explored the interaction effect using targeted contrasts comparing

1.  The effect of each ethnicity versus "White British" within each level of migration.
2.  The effect of "Not born in UK" versus "Born in UK" within each level of ethnicity

Contrasts were calculated using `survey::svycontrast()` and p values were adjusted for multiple comparisons using the FDR method (Benjamini and Hochberg, 1995). Results were only considered where the sample for the contrast was greater than 10.

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "White British"
ref_bor <- "Born in UK"

partA_results <- list()

for (bor in bor_levels) {
  for (eth in eth_levels) {
    if (eth == ref_eth) next  # skip comparing ref to itself
    if (!paste0("Ethnicity_collapsed", eth) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for ethnicity (if not ref)
    if (eth != ref_eth) {
      vec[paste0("Ethnicity_collapsed", eth)] <- 1
    }

    # Interaction term (only needed if BORNUK != ref)
    if (bor != ref_bor) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed", eth)
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partA_results[[paste0(bor, ": ", eth, " vs ", ref_eth)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}

# Make into df
partA_df <- bind_rows(
  lapply(names(partA_results), function(name) {
    res <- partA_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partA_df <- partA_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed) %>%
  rename(cell_n = n)

partA_df <- partA_df %>%
  separate(contrast, into = c("BORNUK_binary", "ethnicity"), sep = ": ", remove = FALSE) %>%
  separate(ethnicity, into = c("test_ethn","ref_ethn"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("BORNUK_binary", "test_ethn" = "Ethnicity_collapsed")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partA <- partA_df %>% filter(p_adj < 0.05)

```

Exploring the effect of each ethnicity versus "White British" within each level of migration, we found that, among people not born in the UK, White other workers were `r sig_partA[which(sig_partA$test_ethn == "White other"), "OR"] %>% round(2)` times as likely (i.e., `r 100 * (1-(sig_partA[which(sig_partA$test_ethn == "White other"), "OR"] %>% round(2)))`% less likely) to be outsourced than "White British" people.

No differences by ethnicity were observed among people born in the UK.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ Ethnicity_collapsed * BORNUK_binary,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

# ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
#                       "Pakistani",
#                       "White and Black African")
ems_df %>%
  # filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = BORNUK_binary, x = prob, colour = Ethnicity_collapsed)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Migration",
    colour = "Ethnicity"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "White British"
ref_bor <- "Born in UK"

partB_results <- list()

for (eth in eth_levels) {
  for (bor in bor_levels) {
    if (bor == ref_bor) next  # skip comparing ref to itself
    if (!paste0("BORNUK_binary", bor) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for BORNUK (if not ref)
    vec[paste0("BORNUK_binary", bor)] <- 1

    # Interaction term (only if ethnicity != ref)
    if (eth != ref_eth) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed", eth)
      # Catch flipped ordering, just in case
      if (!interaction_name %in% coefs) {
        alt_name <- paste0("Ethnicity_collapsed", eth, ":", "BORNUK_binary", bor)
        if (alt_name %in% coefs) interaction_name <- alt_name
      }
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partB_results[[paste0(eth, ": ", bor, " vs ", ref_bor)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}


# Make into df
partB_df <- bind_rows(
  lapply(names(partB_results), function(name) {
    res <- partB_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partB_df <- partB_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed) %>%
  rename(cell_n = n)

partB_df <- partB_df %>%
  separate(contrast, into = c("ethnicity","BORNUK_binary"), sep = ": ", remove = FALSE) %>%
  separate(BORNUK_binary, into = c("test_born","ref_born"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("ethnicity" = "Ethnicity_collapsed", "test_born" = "BORNUK_binary")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partB <- partB_df %>% filter(p_adj < 0.05)

```

Examining the effect of "Not born in UK" versus "Born in UK" within each ethnicity, we found

-   among "White British", workers not born in the UK are `r sig_partB[which(sig_partB$ethnicity == "White British" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.
-   among people of Mixed/multiple ethnic groups, workers not born in UK are `r sig_partB[which(sig_partB$ethnicity == "Mixed/Multiple ethnic group" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.

No significant differences between people born and not born in the UK were observed for any other ethnicities. The figure below shows these effects.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ BORNUK_binary * Ethnicity_collapsed,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

# ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
#                       "Pakistani",
#                       "White and Black African")
ems_df %>%
  # filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = Ethnicity_collapsed, x = prob, colour = BORNUK_binary)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Ethnicity",
    colour = "Born in UK?"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

##### Ethnicity 21

```{r}
#| output: false
#| warning: false
#| message: false

mod_data <- data %>%
  filter(!is.na(Ethnicity_collapsed))
  
design <- svydesign(
  ids = ~1,                             
  weights = ~NatRepemployees,             
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyglm(
  outsourcing_status ~ BORNUK_binary + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyglm(
  outsourcing_status ~ BORNUK_binary * Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region,
  design = design,
  family = quasibinomial()
)

coefs <- extract_glm_coefs(mod_svy2, only_sig=T)

wald <- anova(mod_svy1,mod_svy2, method = "Wald")

# F and p
f <- round(wald[["Ftest"]] %>% as.numeric(),2)
p <- wald[["p"]] %>% as.numeric()

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}

# Degrees of freedom
dfs <- list("df" = wald[["df"]], "ddf" = wald[["ddf"]])
```

A model including the ethnicity:migration interaction term had significantly improved fit compared to a model without the interaction term, *F*(`r dfs[[1]]`, `r dfs[[2]]`) = `r f`, *p* `r p`. The table below shows the model coefficients.

```{r}
labels <- c(
  'Intercept',
  'Migration: Not born in the UK',
  'Migration: Prefer not to say',
  "Ethnicity: Irish",
  "Ethnicity: Gypsy or Irish Traveller",
  "Ethnicity: Roma",
  "Ethnicity: Any other White background",
  "Ethnicity: White and Black Caribbean",
  "Ethnicity: White and Black African",
  "Ethnicity: White and Asian",
  "Ethnicity: Any other Mixed/Multiple ethnic background",
  "Ethnicity: Indian",
  "Ethnicity: Pakistani",
  "Ethnicity: Bangladeshi",
  "Ethnicity: Chinese",
  "Ethnicity: Any other Asian background",
  "Ethnicity: African",
  "Ethnicity: Caribbean",
  "Ethnicity: Any other Black, Black British, or Caribbean background",
  "Ethnicity: Arab",
  "Ethnicity: Any other ethnic group",
  "Ethnicity: Don't think of myself as any of these",
  "Ethnicity: Prefer not to say",
  'Age',
  'Gender: Female',
  'Gender: Other',
  'Gender: Prefer not to say',
  "Education: Don't have degree",
  "Education: Don't know",
  'Region: East Midlands',
  'Region: East of England',
  'Region: North East',
  'Region: North West',
  'Region: Northern Ireland',
  'Region: Scotland',
  'Region: South East',
  'Region: South West',
  'Region: Wales',
  'Region: West Midlands',
  'Region: Yorkshire and the Humber',
  "Interaction: Not born in UK x Irish",
  "Interaction: Prefer not to say x Irish",
  "Interaction: Not born in UK x Gypsy or Irish Traveller",
  # "Interaction: Not born in UK x Roma", # Roma not estimable because rank deficient
  "Interaction: Not born in UK x Any other White background",
  "Interaction: Prefer not to say x Any other White background",
  "Interaction: Not born in UK x White and Black Caribbean",
  "Interaction: Prefer not to say x White and Black Caribbean",
  "Interaction: Not born in UK x White and Black African",
  "Interaction: Prefer not to say x White and Black African",
  "Interaction: Not born in UK x White and Asian",
  "Interaction: Not born in UK x Any other Mixed/Multiple ethnic background",
  "Interaction: Prefer not to say x Any other Mixed/Multiple ethnic background",
  "Interaction: Not born in UK x Indian",
  "Interaction: Prefer not to say x Indian",
  "Interaction: Not born in UK x Pakistani",
  "Interaction: Prefer not to say x Pakistani",
  "Interaction: Not born in UK x Bangladeshi",
  "Interaction: Prefer not to say x Bangladeshi",
  "Interaction: Not born in UK x Chinese",
  "Interaction: Not born in UK x Any other Asian background",
  "Interaction: Prefer not to say x Any other Asian background",
  "Interaction: Not born in UK x African",
  "Interaction: Prefer not to say x African",
  "Interaction: Not born in UK x Caribbean",
  "Interaction: Prefer not to say x Caribbean",
  "Interaction: Not born in UK x Any other Black, Black British, or Caribbean background",
  "Interaction: Prefer not to say x Any other Black, Black British, or Caribbean background",
  
  "Interaction: Not born in UK x Arab",
  "Interaction: Not born in UK x Any other ethnic group",
  "Interaction: Not born in UK x Don't think of myself as any of these",
  "Interaction: Not born in UK x Prefer not to say",
  "Interaction: Prefer not to say x Prefer not to say"

  
)

tab_model(mod_svy2, 
          pred.labels = labels,
          dv.labels = "Outsourcing",
          show.r2 = FALSE,
          title = "Note: Migration x Roma not estimable as model matrix rank deficient")
```

###### Post-hoc

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_bor <- "Born in UK"

partA_results <- list()

for (bor in bor_levels) {
  for (eth in eth_levels) {
    if (eth == ref_eth) next  # skip comparing ref to itself
    if (!paste0("Ethnicity_collapsed_disaggregated", eth) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for ethnicity (if not ref)
    if (eth != ref_eth) {
      vec[paste0("Ethnicity_collapsed_disaggregated", eth)] <- 1
    }

    # Interaction term (only needed if BORNUK != ref)
    if (bor != ref_bor) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed_disaggregated", eth)
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partA_results[[paste0(bor, ": ", eth, " vs ", ref_eth)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}

# Make into df
partA_df <- bind_rows(
  lapply(names(partA_results), function(name) {
    res <- partA_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partA_df <- partA_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partA_df <- partA_df %>%
  separate(contrast, into = c("BORNUK_binary", "ethnicity"), sep = ": ", remove = FALSE) %>%
  separate(ethnicity, into = c("test_ethn","ref_ethn"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("BORNUK_binary", "test_ethn" = "Ethnicity_collapsed_disaggregated")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partA <- partA_df %>% filter(p_adj < 0.05)


```

We explored the interaction effect using targeted contrasts comparing

1.  The effect of each ethnicity versus "English / Welsh / Scottish / Northern Irish / British" within each level of migration.
2.  The effect of "Not born in UK" versus "Born in UK" within each level of ethnicity

Contrasts were calculated using survey::svycontrast() and p values were adjusted for multiple comparisons using the FDR method (Benjamini and Hochberg, 1995) and results were only considered where the sample for the contrast was greater than 10.

Exploring the effect of each ethnicity versus "English / Welsh / Scottish / Northern Irish / British" within each level of migration, we found that, among people born in the UK

-   White and Black African people were `r sig_partA[which(sig_partA$BORNUK_binary == "Born in UK" & sig_partA$test_ethn == "White and Black African"), "OR"] %>% round(2)` times more likely to be outsourced than "English / Welsh / Scottish / Northern Irish / British" people.
-   Pakistani people were `r sig_partA[which(sig_partA$BORNUK_binary == "Born in UK" & sig_partA$test_ethn == "Pakistani"), "OR"] %>% round(2)` times more likely to be outsourced than "English / Welsh / Scottish / Northern Irish / British" people.

Among people not born in the UK, no significant differences between ethnicities were observed. The figure below shows the effects for "English / Welsh / Scottish / Northern Irish / British", "White and Black African", and Pakistani respondents.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ Ethnicity_collapsed_disaggregated * BORNUK_binary,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

ethn_of_interest <- c("English / Welsh / Scottish / Northern Irish / British", 
                      "Pakistani",
                      "White and Black African")
ems_df %>%
  filter(Ethnicity_collapsed_disaggregated %in% ethn_of_interest) %>%
  ggplot(aes(y = BORNUK_binary, x = prob, colour = Ethnicity_collapsed_disaggregated)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Migration",
    colour = "Ethnicity"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

```{r}
# Here we manually calculate contrasts of interest
# i.e. comparing against white british and born uk
coefs <- names(coef(mod_svy2))
eth_levels <- levels(mod_data$Ethnicity_collapsed_disaggregated)
bor_levels <- levels(mod_data$BORNUK_binary)

# Set reference levels for clarity:
ref_eth <- "English / Welsh / Scottish / Northern Irish / British"
ref_bor <- "Born in UK"

partB_results <- list()

for (eth in eth_levels) {
  for (bor in bor_levels) {
    if (bor == ref_bor) next  # skip comparing ref to itself
    if (!paste0("BORNUK_binary", bor) %in% coefs) next  # skip if coef not estimated

    vec <- setNames(rep(0, length(coefs)), coefs)

    # Main effect for BORNUK (if not ref)
    vec[paste0("BORNUK_binary", bor)] <- 1

    # Interaction term (only if ethnicity != ref)
    if (eth != ref_eth) {
      interaction_name <- paste0("BORNUK_binary", bor, ":", "Ethnicity_collapsed_disaggregated", eth)
      # Catch flipped ordering, just in case
      if (!interaction_name %in% coefs) {
        alt_name <- paste0("Ethnicity_collapsed_disaggregated", eth, ":", "BORNUK_binary", bor)
        if (alt_name %in% coefs) interaction_name <- alt_name
      }
      if (interaction_name %in% coefs) {
        vec[interaction_name] <- 1
      }
    }

    res <- as.data.frame(svycontrast(mod_svy2, list("contrast" = vec)))
    colnames(res) <- c("contrast", "SE")
    zval <- res$contrast / res$SE
    pval <- 2 * pnorm(-abs(zval))

    partB_results[[paste0(eth, ": ", bor, " vs ", ref_bor)]] <- list(
      estimate = res$contrast,
      SE = res$SE,
      z = zval,
      p = pval
    )
  }
}


# Make into df
partB_df <- bind_rows(
  lapply(names(partB_results), function(name) {
    res <- partB_results[[name]]
    data.frame(
      contrast = name,
      estimate = res$estimate,
      SE = res$SE,
      z = res$z,
      p = res$p
    )
  }),
  .id = "id"
)

# Calculate OR and CIs and adjust p for multiple comparisons using FDR (Benjamini-Hochberg)
partB_df <- partB_df %>%
  mutate(p_adj = p.adjust(p, method = "fdr")) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * SE),
    CI_upper = exp(estimate + 1.96 * SE)
  )

cell_sizes <- mod_data %>%
  count(BORNUK_binary, Ethnicity_collapsed_disaggregated) %>%
  rename(cell_n = n)

partB_df <- partB_df %>%
  separate(contrast, into = c("ethnicity","BORNUK_binary"), sep = ": ", remove = FALSE) %>%
  separate(BORNUK_binary, into = c("test_born","ref_born"), sep = " vs ", remove = FALSE) %>%
  left_join(cell_sizes, by = c("ethnicity" = "Ethnicity_collapsed_disaggregated", "test_born" = "BORNUK_binary")) %>%
  mutate(small_cell_flag = cell_n <= 10)


sig_partB <- partB_df %>% filter(p_adj < 0.05)

```

Examining the effect of "Not born in UK" versus "Born in UK" within each level of ethnicity, we found that among "English / Welsh / Scottish / Northern Irish / British", workers not born in the UK are `r sig_partB[which(sig_partB$ethnicity == "English / Welsh / Scottish / Northern Irish / British" & sig_partB$test_born == "Not born in UK"), "OR"] %>% round(2)` times more likely to be outsourced than workers born in the UK.

No significant differences between people born and not born in the UK were observed for any other ethnicities. The figure below shows these effects.

```{r}
# Get estimated marginal means on the response (probability) scale
ems <- emmeans(mod_svy2,
               ~ BORNUK_binary * Ethnicity_collapsed_disaggregated,
               type = "response")  # response scale = predicted probabilities

ems_df <- as.data.frame(ems)


pd <- position_dodge(width = 0.5)  # Define dodge position once

ggplot(ems_df, aes(y = Ethnicity_collapsed_disaggregated, x = prob, colour = BORNUK_binary)) +
  geom_point(position = pd, size = 2) +
  geom_errorbar(
    aes(xmin = asymp.LCL, xmax = asymp.UCL),
    width = 0.2,
    position = pd
  ) +
  labs(
    x = "Predicted probability of outsourcing",
    y = "Ethnicity",
    colour = "Born in UK?"
  ) +
  theme_minimal() +
  theme(axis.text.y = element_text(size = 10))

```

#### Ethnicity-outsourced interaction

A generalised linear model was constructed to test whether the interaction between ethnicity and outsourcing predicted whether a person had a low income.

$$
Income Group = Outsourcing + Ethnicity + Age + Gender + Education + Region + Migration + Outsourcing:Ethnicity
$$

As in preceding sections, we constructed three models; one for the binary ethnicity variable, one for the eight-level ethnicity variable, and one for the 21-level ethnicity variable.

##### Ethnicity binary

```{r}
#| message: false
#| output: false

# Alternative for 3-level variable

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_binary)) %>%
  filter(Ethnicity_binary %in% c("White","Non-White")) %>%
  dplyr::mutate(
Ethnicity_binary = factor(Ethnicity_binary, levels = c("White","Non-White")))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

# Step 2: Fit the model with quasibinomial family
mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_binary + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Mid")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_binary + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_binary,
  design = design,
  family = multinomial(refLevel = "Mid")
)

summary(mod_svy2)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_binary", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p

# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A saturated model including the interaction term was not a significantly better fit to the data than an intercept-only model, *X\^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients of the simpler model without the interaction term.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy1, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Low", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

##### Ethnicity 9

```{r}
#| message: false
#| output: false
# Alternative for 3-level variable

ethns_to_drop <- c("Don't think of myself as any of these", "Prefer not to say")

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed)) %>%
  filter(!(Ethnicity_collapsed %in% ethns_to_drop)) %>%
  mutate(Ethnicity_collapsed = droplevels(Ethnicity_collapsed))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Mid")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_collapsed,
  design = design,
  family = multinomial(refLevel = "Mid")
)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_collapsed", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p
# 
# # Extract coefficients and vcov
# coefs <- coef(mod_svy2)
# vcovs <- vcov(mod_svy2)
# 
# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A model including the ethnicity:outsourcing interaction term significantly improved model fit compared to a model without the interaction term, *X^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

We explored the interaction effect using targeted contrasts comparing

1.  The effect of outsourcing within each level of ethnicity
2.  The effect of each ethnicity versus "White British" within each level of outsourcing

```{r}
cell_count_thresh <- 10
```

We do not consider contrasts for which any cell count is less than `r cell_count_thresh`.

###### Post-hoc: Outsourcing within ethnicity



```{r}
#| message: false
#| output: false
#| 
# Create prediction data 
pred_data <- expand.grid(
  outsourcing_status = levels(mod_data$outsourcing_status),
  Ethnicity_collapsed = levels(mod_data$Ethnicity_collapsed),
  Age = mean(mod_data$Age, na.rm = TRUE),
  Gender = levels(mod_data$Gender)[1],
  Has_Degree = levels(mod_data$Has_Degree)[1],
  Region = levels(mod_data$Region)[1],
  BORNUK_labelled = levels(mod_data$BORNUK_labelled)[1]
)

# Get predictions
predictions <- predict(mod_svy2$fit, newdata = pred_data, type = "response")

# Create results dataframe - much simpler!
pred_results <- data.frame(
  pred_data[, 1:2],
  predictions
)

# Add prob_ prefix to column names for clarity
income_levels <- levels(mod_svy2)
prob_cols <- paste0("prob_", colnames(predictions))
names(pred_results)[3:ncol(pred_results)] <- prob_cols

# print(pred_results)

# Bootstrap function for getting confidence intervals
# Set up parallel backend (choose number of workers if needed)
plan(multisession, workers = 12)  # Or plan(multisession, workers = 4)

bootstrap_predictions <- function(n_boot = 500) {
  library(survey)
  library(svyVGAM)
  
  set.seed(1234)
  boot_results <- future_lapply(1:n_boot, function(i) {
    # Resample with replacement, respecting weights
    n_obs <- nrow(mod_data)
    boot_indices <- sample(
      1:n_obs,
      size = n_obs,
      replace = TRUE,
      prob = mod_data$NatRepemployees / sum(mod_data$NatRepemployees)
    )
    boot_data <- mod_data[boot_indices, ]
    
    # Create new survey design
    boot_design <- svydesign(
      ids = ~1,
      weights = ~NatRepemployees,
      data = boot_data
    )
    
    # Refit model and predict
    tryCatch({
      boot_model <- svyVGAM::svy_vglm(
        income_group ~ outsourcing_status + Ethnicity_collapsed + Age + Gender + 
          Has_Degree + Region + BORNUK_labelled + 
          outsourcing_status:Ethnicity_collapsed,
        design = boot_design,
        family = multinomial(refLevel = "Mid")
      )
      
      boot_pred <- predict(boot_model$fit, newdata = pred_data, type = "response")
      
      boot_results_df <- data.frame(
        pred_data[, 1:2],
        boot_pred
      )
      
      prob_cols <- paste0("prob_", colnames(boot_pred))
      names(boot_results_df)[3:ncol(boot_results_df)] <- prob_cols
      
      return(boot_results_df)
    }, error = function(e) {
      return(NULL)
    })
  }, future.seed = TRUE)
  
  # Remove failed bootstrap samples
  boot_results <- boot_results[!sapply(boot_results, is.null)]
  return(boot_results)
}

# t1 <- Sys.time()
# boot_samples <- bootstrap_predictions(n_boot = 2)
# t2 <- Sys.time()
# cat(paste0("Done in ", difftime(t2, t1, units = "secs"), " seconds"))

filepath <- here("Data","bootstrap1_1000_3.rds")
if(!file.exists(filepath)){
# Run bootstrap (this will take some time)
  cat("Running bootstrap... this may take a few minutes\n")
  t1 <- Sys.time()
  boot_samples <- bootstrap_predictions(n_boot = 2000)  
  t2 <- Sys.time()
  cat(paste0("Done in ", difftime(t2, t1, units = "secs"), " seconds"))
  saveRDS(boot_samples, filepath)
} else{
  cat("Loading previous bootstrap")
  boot_samples <- readRDS(filepath)
}


# Calculate confidence intervals
calculate_boot_ci <- function(boot_samples, prob_cols) {
  ci_results <- pred_results[, 1:2]  # Keep grouping variables
  
  for(col in prob_cols) {
    # Extract this probability across all bootstrap samples
    boot_probs <- sapply(boot_samples, function(x) {
      if(is.null(x) || !col %in% names(x)) return(NA)
      x[[col]]
    })
  
    # Point estimate from bootstrap (mean)
    ci_results[[paste0(col, "_boot_mean")]] <- rowMeans(boot_probs, na.rm = TRUE)
    
    # Calculate percentile confidence intervals
    ci_lower <- apply(boot_probs, 1, quantile, probs = 0.025, na.rm = TRUE)
    ci_upper <- apply(boot_probs, 1, quantile, probs = 0.975, na.rm = TRUE)
    
    ci_results[[paste0(col, "_ci_lower")]] <- ci_lower
    ci_results[[paste0(col, "_ci_upper")]] <- ci_upper
  }
  
  return(ci_results)
}

# Get confidence intervals
prob_cols <- names(pred_results)[grepl("^prob_", names(pred_results))]
ci_results <- calculate_boot_ci(boot_samples, prob_cols)
  
boot_mean_results <- ci_results[, 1:2]  # Keep grouping vars
for (col in prob_cols) {
  boot_mean_results[[col]] <- ci_results[[paste0(col, "_boot_mean")]]
}

```

```{r}
#| message: false
#| output: false



# Function to calculate differences and their bootstrap CIs
calculate_differences_with_ci <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)
  # Get point estimates
  ethnicity_groups <- split(pred_data, pred_data$Ethnicity_collapsed)
  
  results <- list()
  
  for(eth in names(ethnicity_groups)) {
    group_data <- ethnicity_groups[[eth]]
    
    if(nrow(group_data) >= 2) {
      outsourcing_levels <- levels(group_data$outsourcing_status)
      
      if(length(outsourcing_levels) == 2) {
        # Point estimate of difference (level 2 - level 1)
        prob_ratio <- group_data[group_data$outsourcing_status == outsourcing_levels[2], prob_col] / 
              group_data[group_data$outsourcing_status == outsourcing_levels[1], prob_col]

        
        # Bootstrap differences
        boot_ratios <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          boot_group <- boot_data[boot_data$Ethnicity_collapsed == eth, ]
          if(nrow(boot_group) >= 2) {
            boot_group[boot_group$outsourcing_status == outsourcing_levels[2], prob_col] / 
            boot_group[boot_group$outsourcing_status == outsourcing_levels[1], prob_col]
          } else {
            NA
          }
        })
        
        # Remove NAs
        boot_ratios <- boot_ratios[!is.na(boot_ratios)]
        
        if(length(boot_ratios) > 2) {  # Need sufficient bootstrap samples
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_ratios)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[eth]] <- data.frame(
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(outsourcing_levels[2], "vs", outsourcing_levels[1])
          )
        }
      }
    }
  }
  
  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
# Calculate differences for each income level
all_differences <- list()
for(level in income_levels) {
  all_differences[[level]] <- calculate_differences_with_ci(boot_mean_results, boot_samples, level)
}

difference_results <- do.call(rbind, all_differences)
rownames(difference_results) <- NULL

# Apply multiple comparison correction
if(nrow(difference_results) > 0) {
  difference_results$p_value_bonferroni <- p.adjust(difference_results$p_value, method = "bonferroni")
  difference_results$p_value_fdr <- p.adjust(difference_results$p_value, method = "fdr")
  difference_results$significant_bonferroni <- difference_results$p_value_bonferroni < 0.05
  difference_results$significant_fdr <- difference_results$p_value_fdr < 0.05
}

# print(difference_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed,
    income_level = income_group
  )

difference_results2 <- difference_results %>% 
  left_join(counts, by = c("ethnicity", "income_level"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("ethnicity","income_level")]

difference_results3 <- difference_results %>%
  anti_join(drop, by = c("ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 

difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

-   `r difference_results_sig$ethnicity[1]` workers are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[2]` workers are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[3]` workers are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[4]` workers are `r difference_results_sig$prob_ratio[4]` times as likely to be in the `r difference_results_sig$income_level[4]` group if they are outsourced compared to not-outsourced (note large confidence interval for this effect - see plot)

In essence, a White British person is more likely to be in the low or mid income group, and less likely to be in the high income group, if they are outsourced compared to not-outsourced.

```{r}
ci_results2 <- ci_results %>%
  pivot_longer(
    cols = starts_with("prob_"),
    names_to = c("income_level", "metric"),
    names_pattern = "prob_(.*)_(ci_.*|boot_mean)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = metric,
    values_from = value
  )
	      
plot_data <- ci_results2 %>%
  # pivot_longer(cols = starts_with("prob_"),
  #              names_to = "income_level",
  #              values_to = "probability") %>%
  # mutate(income_level = gsub("prob_", "", income_level)) %>%
  # left_join(ci_results2, by = c("outsourcing_status","Ethnicity_collapsed","income_level")) %>% 

  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))) %>%
  mutate(
    nudge = ifelse(outsourcing_status == "Outsourced", 0.1, -0.1)
  )
  # Preserve order

# Plot predicted probabilities
ggplot(plot_data, aes(y = Ethnicity_collapsed, x = boot_mean,
                      colour = outsourcing_status)) +
  geom_point(position = position_nudge(y = plot_data$nudge)) +
  geom_errorbar(position = position_nudge(y = plot_data$nudge), aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  facet_grid(rows = vars(income_level)) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1)) +
  labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
       y = "", x = "Predicted Probability",
       colour = "Outsourcing Status") +
  scale_x_continuous(breaks = seq(0,1,0.2))

# Plot differences with confidence intervals

ggplot(difference_results3, aes(x = prob_ratio, y = ethnicity, colour = significant_bonferroni)) +
  geom_point() +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_wrap(~income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from not outsourced\nRed dots indicate significant effects"
) +
  scale_colour_manual(values = c("black","red"))




```

```{r}
#| include: false
#| message: false
#| output: false
test <- plot_data %>% 
  mutate(
    wrong = ifelse(boot_mean < ci_lower | boot_mean > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

test2 <- difference_results3 %>% 
  mutate(
    wrong = ifelse(prob_ratio < ci_lower | prob_ratio > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

```

###### Post-hoc: Ethnicity within outsourcing

```{r}
calculate_ethnicity_differences_within_outsourcing <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)

  # Get point estimates
  outsourcing_groups <- split(pred_data, pred_data$outsourcing_status)
  
  results <- list()
  
  for(out_group in names(outsourcing_groups)) {
    group_data <- outsourcing_groups[[out_group]]
    
    # Reference group
    ref_data <- group_data[group_data$Ethnicity_collapsed == "White British", ]
    if(nrow(ref_data) == 0) next
    
    # Loop through other ethnicities
    other_ethnicities <- setdiff(unique(group_data$Ethnicity_collapsed), "White British")
    
    for(eth in other_ethnicities) {
      comp_data <- group_data[group_data$Ethnicity_collapsed == eth, ]
      
      if(nrow(comp_data) > 0) {
        # Point estimate of difference (ethnicity - White British)
        prob_ratio <- comp_data[[prob_col]] / ref_data[[prob_col]]

        
        # Bootstrap differences
        boot_diffs <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          
          boot_group <- boot_data[boot_data$outsourcing_status == out_group, ]
          boot_ref <- boot_group[boot_group$Ethnicity_collapsed == "White British", ]
          boot_eth <- boot_group[boot_group$Ethnicity_collapsed == eth, ]
          
          if(nrow(boot_ref) > 0 && nrow(boot_eth) > 0) {
            boot_eth[[prob_col]] / boot_ref[[prob_col]]

          } else {
            NA
          }
        })

        boot_diffs <- boot_diffs[!is.na(boot_diffs)]
        
        
        if(length(boot_diffs) > 2) {
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_diffs)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[paste(out_group, eth, sep = "_")]] <- data.frame(
            outsourcing_status = out_group,
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(eth, "vs White British")
          )
        }
      }
    }
  }

  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
all_ethnicity_differences <- list()
for(level in income_levels) {
  all_ethnicity_differences[[level]] <- calculate_ethnicity_differences_within_outsourcing(boot_mean_results, boot_samples, level)
}

ethnicity_diff_results <- do.call(rbind, all_ethnicity_differences)
rownames(ethnicity_diff_results) <- NULL

# Apply multiple comparison correction
if(nrow(ethnicity_diff_results) > 0) {
  ethnicity_diff_results$p_value_bonferroni <- p.adjust(ethnicity_diff_results$p_value, method = "bonferroni")
  ethnicity_diff_results$p_value_fdr <- p.adjust(ethnicity_diff_results$p_value, method = "fdr")
  ethnicity_diff_results$significant_bonferroni <- ethnicity_diff_results$p_value_bonferroni < 0.05
  ethnicity_diff_results$significant_fdr <- ethnicity_diff_results$p_value_fdr < 0.05
}

# print(ethnicity_diff_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed,
    income_level = income_group
  )

difference_results2 <- ethnicity_diff_results %>%
  left_join(counts, by = c("ethnicity", "income_level","outsourcing_status"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("outsourcing_status","ethnicity","income_level")]

difference_results3 <- ethnicity_diff_results %>%
  anti_join(drop, by = c("outsourcing_status", "ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 


difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))
```

Comparing ethnicities within outsourcing status revealed no significant contrasts.


```{r}
# levs <- levels(plot_data$Ethnicity_collapsed)
# levs_nudge <- as.list(seq(0,1, (1/(length(levs_nudge)-1))) - 0.5)
# names(levs_nudge) <- levs
# 
# 
# plot_data <- plot_data %>%
#   mutate(
#     nudge = purrr::map_dbl(Ethnicity_collapsed, ~ levs_nudge[[.x]])
#   )

dodge_val <- 0.8
# Plot predicted probabilities
# ggplot(plot_data, aes(y = outsourcing_status , x = probability,
#                       colour = Ethnicity_collapsed )) +
#   geom_point(position = position_dodge(dodge_val)) +
#   geom_errorbar(position = position_dodge(dodge_val), aes(xmin = ci_lower, xmax = ci_upper), width = 0.1) +
#   facet_grid(rows = vars(income_level)) +
#   theme_minimal() +
#   theme(axis.text.x = element_text(hjust = 1)) +
#   labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
#        y = "", x = "Predicted Probability",
#        colour = "Outsourcing Status") +
#   scale_x_continuous(breaks = seq(0,1,0.2))



ggplot(difference_results3, aes(x = prob_ratio, y = ethnicity, colour = significant_bonferroni)) +
  geom_point(size = 2) +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_grid(outsourcing_status ~ income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        strip.text = element_text(face = "bold"),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability (vs White British)",
    subtitle = "Shown within each outsourcing status and income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from White British\nRed dots indicate significant effects"

  ) +
  scale_colour_manual(values = c("black","red")) 




```
```{r}
#| include: false
#| message: false
#| output: false
test <- plot_data %>% 
  mutate(
    wrong = ifelse(boot_mean < ci_lower | boot_mean > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

test2 <- difference_results3 %>% 
  mutate(
    wrong = ifelse(prob_ratio < ci_lower | prob_ratio > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

```

The plot below of predicted probabilities suggests that non-White ethnicities are not more or less likely to be in the low income group regardless of the outsourcing status, compared to White British. That is, the lack of an effect of outsourcing status on low income group membership does not appear to be attributable to a higher likelihood generally of marginalised ethnicities being low paid.


```{r}
ggplot(plot_data, aes(y = Ethnicity_collapsed , x = boot_mean,
                    )) +
  geom_point(position = position_dodge(dodge_val)) +
  geom_errorbar(position = position_dodge(dodge_val), aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  facet_grid(rows = vars(outsourcing_status), cols = vars(income_level)) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1)) +
  labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
       y = "", x = "Predicted Probability",
       colour = "Outsourcing Status") +
  scale_x_continuous(breaks = seq(0,1,0.2))
```

##### Ethnicity 21

```{r}
#| message: false
#| output: false
# Alternative for 3-level variable

ethns_to_drop <- c("Don't think of myself as any of these", "Prefer not to say")

mod_data <- income_data %>%
  filter(!is.na(Ethnicity_collapsed_disaggregated)) %>%
  filter(!(Ethnicity_collapsed_disaggregated %in% ethns_to_drop)) %>%
  mutate(Ethnicity_collapsed_disaggregated = droplevels(Ethnicity_collapsed_disaggregated))

design <- svydesign(
  ids = ~1,
  weights = ~NatRepemployees,
  data = mod_data
)

mod_svy1 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region + BORNUK_labelled,
  design = design,
  family = multinomial(refLevel = "Mid")
)


# Step 2: Fit the model with quasibinomial family
mod_svy2 <- svyVGAM::svy_vglm(
  income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + Has_Degree + Region + BORNUK_labelled + outsourcing_status:Ethnicity_collapsed_disaggregated,
  design = design,
  family = multinomial(refLevel = "Mid")
)


# Extract coefficients and vcov
coefs <- coef(mod_svy2)
vcovs <- vcov(mod_svy2)
coef_names <- grep("outsourcing_status.*:Ethnicity_collapsed_disaggregated", names(coefs), value = TRUE)

# Extract coefficients and covariance sub-matrix
L <- coefs[coef_names]
V <- vcovs[coef_names, coef_names]

# Wald statistic
W <- t(L) %*% solve(V) %*% L

# Degrees of freedom: number of parameters tested
df <- length(L)

# p-value
p <- pchisq(W, df, lower.tail = FALSE)

# Output
W
p
# 
# # Extract coefficients and vcov
# coefs <- coef(mod_svy2)
# vcovs <- vcov(mod_svy2)
# 
# # Remove intercepts
# non_intercept_idx <- !grepl("(Intercept)", names(coefs))
# 
# # Subset coefficients and vcov accordingly
# coefs_non_intercept <- coefs[non_intercept_idx]
# vcovs_non_intercept <- vcovs[non_intercept_idx, non_intercept_idx]
# 
# # Perform Wald test
# wald <- wald.test(
#   Sigma = vcovs_non_intercept, 
#   b = coefs_non_intercept, 
#   L = diag(length(coefs_non_intercept))
# )
# wald_stats <- wald[["result"]][["chi2"]]
# p <- wald_stats[3]

if(p < .001){
  p = "< .001"
} else{
  p = paste0("= ",round(p,3))
}


```

A model including the ethnicity:outsourcing interaction term significantly improved model fit compared to a model without the interaction term, *X\^2*(`r df`) = `r W`, *p* `r p`. The table below shows the model coefficients.

```{r}
tidy_mod <- tidy.svyVGAM(mod_svy2, exponentiate = TRUE, conf.int = TRUE)

tidy_mod %>% 
  dplyr::select(-y.level) %>% 
  rename(income_group = term) %>% 
  mutate(sig = case_when(
    p.value < 0.001 ~ "***",
    p.value < 0.01 ~ "**",
    p.value < 0.05 ~ "*",
    T ~ ""
  )) %>% 
  kable(digits = 3) %>% 
  kable_styling() %>%
  pack_rows("Mid", 1, nrow(tidy_mod)/2) %>% 
  pack_rows("High", nrow(tidy_mod)/2 + 1, nrow(tidy_mod))
```

###### Post-hoc: Outsourcing within ethnicity

```{r}
#| message: false
#| output: false
#| 
# Create prediction data 
pred_data <- expand.grid(
  outsourcing_status = levels(mod_data$outsourcing_status),
  Ethnicity_collapsed_disaggregated = levels(mod_data$Ethnicity_collapsed_disaggregated),
  Age = mean(mod_data$Age, na.rm = TRUE),
  Gender = levels(mod_data$Gender)[1],
  Has_Degree = levels(mod_data$Has_Degree)[1],
  Region = levels(mod_data$Region)[1],
  BORNUK_labelled = levels(mod_data$BORNUK_labelled)[1]
)

# Get predictions
predictions <- predict(mod_svy2$fit, newdata = pred_data, type = "response")

# Create results dataframe - much simpler!
pred_results <- data.frame(
  pred_data[, 1:2],
  predictions
)

# Add prob_ prefix to column names for clarity
income_levels <- levels(mod_svy2)
prob_cols <- paste0("prob_", colnames(predictions))
names(pred_results)[3:ncol(pred_results)] <- prob_cols
  
# Set up parallel backend (choose number of workers if needed)
plan(multisession, workers = 12)  # Or plan(multisession, workers = 4)

bootstrap_predictions <- function(n_boot = 500) {
  library(survey)
  library(svyVGAM)
  
  set.seed(1234)
  boot_results <- future_lapply(1:n_boot, function(i) {
    # Resample with replacement, respecting weights
    n_obs <- nrow(mod_data)
    boot_indices <- sample(
      1:n_obs,
      size = n_obs,
      replace = TRUE,
      prob = mod_data$NatRepemployees / sum(mod_data$NatRepemployees)
    )
    boot_data <- mod_data[boot_indices, ]
    
    # Create new survey design
    boot_design <- svydesign(
      ids = ~1,
      weights = ~NatRepemployees,
      data = boot_data
    )
    
    # Refit model and predict
    tryCatch({
      boot_model <- svyVGAM::svy_vglm(
        income_group ~ outsourcing_status + Ethnicity_collapsed_disaggregated + Age + Gender + 
          Has_Degree + Region + BORNUK_labelled + 
          outsourcing_status:Ethnicity_collapsed_disaggregated,
        design = boot_design,
        family = multinomial(refLevel = "Mid")
      )
      
      boot_pred <- predict(boot_model$fit, newdata = pred_data, type = "response")
      
      boot_results_df <- data.frame(
        pred_data[, 1:2],
        boot_pred
      )
      
      prob_cols <- paste0("prob_", colnames(boot_pred))
      names(boot_results_df)[3:ncol(boot_results_df)] <- prob_cols
      
      return(boot_results_df)
    }, error = function(e) {
      return(NULL)
    })
  }, future.seed = TRUE)
  
  # Remove failed bootstrap samples
  boot_results <- boot_results[!sapply(boot_results, is.null)]
  return(boot_results)
}

# Run or load
filepath <- here("Data", "bootstrap2_1000_3.rds")
if (!file.exists(filepath)) {
  cat("Running bootstrap... this may take a few minutes\n")
  boot_samples <- bootstrap_predictions(n_boot = 2000)
  saveRDS(boot_samples, filepath)
} else {
  cat("Loading previous bootstrap\n")
  boot_samples <- readRDS(filepath)
}

  
# Calculate confidence intervals
calculate_boot_ci <- function(boot_samples, prob_cols) {
  ci_results <- pred_results[, 1:2]  # Keep grouping variables
  
  for(col in prob_cols) {
    # Extract this probability across all bootstrap samples
    boot_probs <- sapply(boot_samples, function(x) {
      if(is.null(x) || !col %in% names(x)) return(NA)
      x[[col]]
    })
  
    # Point estimate from bootstrap (mean)
    ci_results[[paste0(col, "_boot_mean")]] <- rowMeans(boot_probs, na.rm = TRUE)
  
    # Calculate percentile confidence intervals
    ci_lower <- apply(boot_probs, 1, quantile, probs = 0.025, na.rm = TRUE)
    ci_upper <- apply(boot_probs, 1, quantile, probs = 0.975, na.rm = TRUE)
    
    ci_results[[paste0(col, "_ci_lower")]] <- ci_lower
    ci_results[[paste0(col, "_ci_upper")]] <- ci_upper
  }
  
  return(ci_results)
}

# Get confidence intervals
prob_cols <- names(pred_results)[grepl("^prob_", names(pred_results))]
ci_results <- calculate_boot_ci(boot_samples, prob_cols)

# Rename so that it's in format the difference calculation is happy with
boot_mean_results <- ci_results[, 1:2]  # Keep grouping vars
for (col in prob_cols) {
  boot_mean_results[[col]] <- ci_results[[paste0(col, "_boot_mean")]]
}

```

```{r}
#| message: false
#| output: false

# Function to calculate differences and their bootstrap CIs
calculate_differences_with_ci <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)
  # Get point estimates
  ethnicity_groups <- split(pred_data, pred_data$Ethnicity_collapsed_disaggregated)
  
  results <- list()
  
  for(eth in names(ethnicity_groups)) {
    group_data <- ethnicity_groups[[eth]]
    
    if(nrow(group_data) >= 2) {
      outsourcing_levels <- levels(group_data$outsourcing_status)
      
      if(length(outsourcing_levels) == 2) {
        # Point estimate of difference (level 2 - level 1)
        prob_ratio <- group_data[group_data$outsourcing_status == outsourcing_levels[2], prob_col] / 
              group_data[group_data$outsourcing_status == outsourcing_levels[1], prob_col]

        
        # Bootstrap differences
        boot_ratios <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          boot_group <- boot_data[boot_data$Ethnicity_collapsed_disaggregated == eth, ]
          if(nrow(boot_group) >= 2) {
            boot_group[boot_group$outsourcing_status == outsourcing_levels[2], prob_col] / 
            boot_group[boot_group$outsourcing_status == outsourcing_levels[1], prob_col]
          } else {
            NA
          }
        })
        
        # Remove NAs
        boot_ratios <- boot_ratios[!is.na(boot_ratios)]
        
        if(length(boot_ratios) > 2) {  # Need sufficient bootstrap samples
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_ratios)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[eth]] <- data.frame(
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(outsourcing_levels[2], "vs", outsourcing_levels[1])
          )
        }
      }
    }
  }
  
  do.call(rbind, results)
}

income_levels <- levels(mod_data$income_group)
# Calculate differences for each income level
all_differences <- list()
for(level in income_levels) {
  all_differences[[level]] <- calculate_differences_with_ci(boot_mean_results, boot_samples, level)
}

difference_results <- do.call(rbind, all_differences)
rownames(difference_results) <- NULL

# Apply multiple comparison correction
if(nrow(difference_results) > 0) {
  difference_results$p_value_bonferroni <- p.adjust(difference_results$p_value, method = "bonferroni")
  difference_results$p_value_fdr <- p.adjust(difference_results$p_value, method = "fdr")
  difference_results$significant_bonferroni <- difference_results$p_value_bonferroni < 0.05
  difference_results$significant_fdr <- difference_results$p_value_fdr < 0.05
}

# print(difference_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed_disaggregated,
    income_level = income_group
  )

difference_results2 <- difference_results %>% 
  left_join(counts, by = c("ethnicity", "income_level"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("ethnicity","income_level")]

difference_results3 <- difference_results %>%
  anti_join(drop, by = c("ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 


difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

-   `r difference_results_sig$ethnicity[1]` workers are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[2]` workers are `r difference_results_sig$prob_ratio[2]` times as likely to be in the `r difference_results_sig$income_level[2]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[3]` workers are `r difference_results_sig$prob_ratio[3]` times as likely to be in the `r difference_results_sig$income_level[3]` group if they are outsourced compared to not-outsourced
-   `r difference_results_sig$ethnicity[4]` workers are `r difference_results_sig$prob_ratio[4]` times as likely to be in the `r difference_results_sig$income_level[4]` group if they are outsourced compared to not-outsourced

```{r}
# Reshape ci_results
ci_results2 <- ci_results %>%
  pivot_longer(
    cols = starts_with("prob_"),
    names_to = c("income_level", "metric"),
    names_pattern = "prob_(.*)_(ci_.*|boot_mean)",
    values_to = "value"
  ) %>%
  pivot_wider(
    names_from = metric,
    values_from = value
  )

# Reshape data for plotting
plot_data <- ci_results2 %>%
  # pivot_longer(cols = starts_with("prob_"),
  #              names_to = "income_level",
  #              values_to = "probability") %>%
  # mutate(income_level = gsub("prob_", "", income_level)) %>%
  # left_join(ci_results2, by = c("outsourcing_status","Ethnicity_collapsed_disaggregated","income_level")) %>% 

  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))) %>%
  mutate(
    nudge = ifelse(outsourcing_status == "Outsourced", 0.1, -0.1)
  )

# Plot predicted probabilities
ggplot(plot_data, aes(y = Ethnicity_collapsed_disaggregated, x = boot_mean,
                      colour = outsourcing_status)) +
  geom_point(position = position_nudge(y = plot_data$nudge)) +
  geom_errorbar(position = position_nudge(y = plot_data$nudge), aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  facet_grid(rows = vars(income_level)) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1)) +
  labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
       y = "", x = "Predicted Probability",
       colour = "Outsourcing Status") +
  scale_x_continuous(breaks = seq(0,1,0.2))


# Plot differences with confidence intervals

ggplot(difference_results3, aes(x = prob_ratio , y = ethnicity, colour = significant_bonferroni)) +
  geom_point() +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_wrap(~income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each income level",
    x = "Ratio of Predicted Probabilities",
    y = "",
    caption = "Red line indicates no difference from not outsourced\nRed dots show significant effects"
) +
  scale_colour_manual(values = c("black","red"))

```

```{r}
#| include: false
#| message: false
#| output: false
test <- plot_data %>% 
  mutate(
    wrong = ifelse(boot_mean < ci_lower | boot_mean > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

test2 <- difference_results3 %>% 
  mutate(
    wrong = ifelse(prob_ratio < ci_lower | prob_ratio > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

```

###### Post-hoc: Ethnicity within outsourcing

```{r}
calculate_ethnicity_differences_within_outsourcing <- function(pred_data, boot_samples, income_level) {
  prob_col <- paste0("prob_", income_level)

  # Get point estimates
  outsourcing_groups <- split(pred_data, pred_data$outsourcing_status)
  
  results <- list()
  
  for(out_group in names(outsourcing_groups)) {
    group_data <- outsourcing_groups[[out_group]]
    
    # Reference group
    ref_data <- group_data[group_data$Ethnicity_collapsed_disaggregated == "English / Welsh / Scottish / Northern Irish / British", ]
    if(nrow(ref_data) == 0) next
    
    # Loop through other ethnicities
    other_ethnicities <- setdiff(unique(group_data$Ethnicity_collapsed_disaggregated), "English / Welsh / Scottish / Northern Irish / British")
    
    for(eth in other_ethnicities) {
      comp_data <- group_data[group_data$Ethnicity_collapsed_disaggregated == eth, ]
      
      if(nrow(comp_data) > 0) {
        # Point estimate of difference (ethnicity - White British)
        prob_ratio <- comp_data[[prob_col]] / ref_data[[prob_col]]

        
        # Bootstrap differences
        boot_diffs <- sapply(boot_samples, function(boot_data) {
          if(is.null(boot_data) || !prob_col %in% names(boot_data)) return(NA)
          
          boot_group <- boot_data[boot_data$outsourcing_status == out_group, ]
          boot_ref <- boot_group[boot_group$Ethnicity_collapsed_disaggregated == "English / Welsh / Scottish / Northern Irish / British", ]
          boot_eth <- boot_group[boot_group$Ethnicity_collapsed_disaggregated == eth, ]
          
          if(nrow(boot_ref) > 0 && nrow(boot_eth) > 0) {
            boot_eth[[prob_col]] / boot_ref[[prob_col]]

          } else {
            NA
          }
        })

        boot_diffs <- boot_diffs[!is.na(boot_diffs)]
        
        if(length(boot_diffs) > 2) {
          # Log-transform for symmetric CI on ratio scale
          log_ratios <- log(boot_diffs)
          ci_lower <- exp(quantile(log_ratios, 0.025, na.rm = TRUE))
          ci_upper <- exp(quantile(log_ratios, 0.975, na.rm = TRUE))
          
          p_value <- 2 * min(mean(log_ratios > 0, na.rm = TRUE), 
                             mean(log_ratios < 0, na.rm = TRUE))

          
          results[[paste(out_group, eth, sep = "_")]] <- data.frame(
            outsourcing_status = out_group,
            ethnicity = eth,
            income_level = income_level,
            prob_ratio = prob_ratio,
            ci_lower = ci_lower,
            ci_upper = ci_upper,
            p_value = p_value,
            comparison = paste(eth, "vs English / Welsh / Scottish / Northern Irish / British")
          )
        }
      }
    }
  }

  do.call(rbind, results)
}

all_ethnicity_differences <- list()
income_levels <- levels(mod_data$income_group)
for(level in income_levels) {
  all_ethnicity_differences[[level]] <- calculate_ethnicity_differences_within_outsourcing(boot_mean_results, boot_samples, level)
}

ethnicity_diff_results <- do.call(rbind, all_ethnicity_differences)
rownames(ethnicity_diff_results) <- NULL

# Apply multiple comparison correction
if(nrow(ethnicity_diff_results) > 0) {
  ethnicity_diff_results$p_value_bonferroni <- p.adjust(ethnicity_diff_results$p_value, method = "bonferroni")
  ethnicity_diff_results$p_value_fdr <- p.adjust(ethnicity_diff_results$p_value, method = "fdr")
  ethnicity_diff_results$significant_bonferroni <- ethnicity_diff_results$p_value_bonferroni < 0.05
  ethnicity_diff_results$significant_fdr <- ethnicity_diff_results$p_value_fdr < 0.05
}

# print(ethnicity_diff_results)

counts <- mod_data %>% 
  group_by(income_group, outsourcing_status, Ethnicity_collapsed_disaggregated) %>%
  summarise(
    n = n()
  ) %>%
  rename(
    ethnicity = Ethnicity_collapsed_disaggregated,
    income_level = income_group
  )


difference_results2 <- ethnicity_diff_results %>%
  left_join(counts, by = c("ethnicity", "income_level","outsourcing_status"))

drop <- difference_results2[which(difference_results2$n < cell_count_thresh | is.na(difference_results2$n)),c("outsourcing_status","ethnicity","income_level")]

difference_results3 <- ethnicity_diff_results %>%
  anti_join(drop, by = c("outsourcing_status", "ethnicity", "income_level")) %>%
  mutate(
    income_level = factor(income_level, levels = c("Low","Mid","High"))
  ) 

difference_results_sig <- difference_results3 %>%
  filter(significant_bonferroni == TRUE) %>%
  arrange(desc(ethnicity))

```

Comparing ethnicities within outsourcing status,

-   Among `r difference_results_sig$outsourcing_status[1]` workers, people of `r difference_results_sig$ethnicity[1]` ethnicity are `r difference_results_sig$prob_ratio[1]` times as likely to be in the `r difference_results_sig$income_level[1]` group compared to English / Welsh / Scottish / Northern Irish / British people.

```{r}
#| height: 10
ggplot(difference_results3, aes(x = prob_ratio , y = ethnicity, colour = significant_bonferroni)) +
  geom_point(size = 2) +
  geom_errorbar(aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  facet_grid(outsourcing_status ~ income_level) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1),
        strip.text = element_text(face = "bold"),
        legend.position = "none") +
  labs(
    title = "Ethnic Group Differences in Predicted Probability",
    subtitle = "Shown within each outsourcing status and income level",
    y = "",
    x = "Ratio of Predicted Probabilities",
    caption = "Red line indicates no difference from White British\nRed dots indicate significant effects"
  ) +
  scale_colour_manual(values = c("black","red"))


```

```{r}
#| include: false
#| message: false
#| output: false
test <- plot_data %>% 
  mutate(
    wrong = ifelse(boot_mean < ci_lower | boot_mean > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

test2 <- difference_results3 %>% 
  mutate(
    wrong = ifelse(prob_ratio < ci_lower | prob_ratio > ci_upper,1, 0)
  ) %>%
  summarise(
    sum(wrong)
    ) %>%
  pull()

```

As for the aggregated model, there is no evidence to suggest that the lack of a difference for ethnic minorities is due to a higher likelihood of being low paid regardless of outsourcing status.

```{r}
ggplot(plot_data, aes(y = Ethnicity_collapsed_disaggregated, x = boot_mean,
                    )) +
  geom_point(position = position_dodge(dodge_val)) +
  geom_errorbar(position = position_dodge(dodge_val), aes(xmin = ci_lower, xmax = ci_upper), width = 0.2) +
  facet_grid(rows = vars(outsourcing_status), cols = vars(income_level)) +
  theme_minimal() +
  theme(axis.text.x = element_text(hjust = 1)) +
  labs(title = "Predicted Probabilities by Ethnicity and Outsourcing Status",
       y = "", x = "Predicted Probability",
       colour = "Outsourcing Status") +
  scale_x_continuous(breaks = seq(0,1,0.2))
```

# Analysis - Study 2

# Study 2 Overview


Analysis from Study 2 appearing in \[NAME OF REPORT\] primarily employs a descriptive approach to understand the data. We conducted several cross-tabulations focusing on key demographic variables including Migration Status, Low Pay, and Ethnicity.

Due to the extensive number of variables examined, these cross-tabulations are not reproduced in this document. However, researchers can easily recreate these analyses by running the “Crosstabulations.qmd” script available in the GitHub repository associated with this project (see \@reproducibility). The repository contains all necessary data files and code to replicate our findings.

For brevity this document only focuses on the findings which are included in the report (and/or closely related)


Data used for these analysis can be reproduced by runing the data cleaning file in the repository \[link/name\]. The data was then split into two datasets, one containing income outliers and one with income outliers removed. The no outliers dataset is used in any analyses which include pay related variables. The outlier exclusion criteria are the same as those in Study 1. In this dataset 10.1% (183) cases are removed in the no outlier dataset.

```{r setup}
library(tidyverse)
library(crosstable) 
library(flextable)
library(vcd)
library(MASS)
library(forcats)
library(broom)

# Load data
experiential_data <- read_csv("../Data/2025-06-30 - clean_data_jrf_experiential.csv")

# Set reference levels for factors
experiential_data$Ethnicity_Collapsed <- relevel(factor(experiential_data$Ethnicity_Collapsed), ref = "White British")
experiential_data$Sex <- relevel(factor(experiential_data$Sex), ref = "Male")
experiential_data$Region <- relevel(factor(experiential_data$Region), ref = "London")
experiential_data$income_group <- relevel(factor(experiential_data$income_group), ref = "Mid")

# Create filtered dataset excluding income outliers for income-related analyses
# income_drop: 1 = outlier, 0 = not outlier (from data_cleaning.R)
experiential_data_no_income_outliers <- experiential_data %>%
  filter(income_drop == 0)

# Data quality check - Income outlier filtering
cat("Data quality check - Income outlier filtering:\n")
cat("Original dataset:", nrow(experiential_data), "rows\n")
cat("After removing income outliers:", nrow(experiential_data_no_income_outliers), "rows\n")
cat("Income outliers removed:", nrow(experiential_data) - nrow(experiential_data_no_income_outliers), 
    "(", round((nrow(experiential_data) - nrow(experiential_data_no_income_outliers))/nrow(experiential_data)*100, 1), "%)\n\n")
```

## Pay Comparison

First we explore subjective perceptions of Pay, where participants selected whether they believed they were paid more or less than in-house workers. The analysis is conducted using simple crosstabulations across key demographic variables; Sex, Age, Eethnicity, Region, Income group (e.g. High, Low or Middle), Education Band (High, Low, Middle) and Place of Birth (UK, Not UK)

```{r pay-comparison-cross}

Paid_Less_Cross <- crosstable(experiential_data_no_income_outliers %>% 
                                dplyr::select(Pros_And_Cons_Pay, Sex, Age, Ethnicity, Ethnicity_Collapsed, Region, income_group, Education_Band, BORNUK_binary), 
                              by = Pros_And_Cons_Pay,
                              total = "both",
                              showNA = "no", 
                              funs = c("median", "mean", "std dev" = "sd"),
                              percent_digits = 2, 
                              percent_pattern = "{n} ({p_row})") %>%
  as_flextable()

Paid_Less_Cross
```

The pay comparison analysis reveals several notable demographic patterns in perceived pay inequality among outsourced workers. **Sex differences** are evident, with men more likely to report being paid more than in-house workers (31.77%) compared to women (21.35%), while women more frequently report no pay difference (52.25% vs 42.25%). **Age patterns** show that those reporting higher pay tend to be younger (mean age 35.7 years) compared to those reporting lower pay (mean age 38.5 years). **Education disparities** are striking, with highly educated workers much more likely to report being paid more (32.47%) compared to those with low education (16.15%). **Place of birth** differences emerge, with workers not born in the UK more likely to report being paid more (33.41%) than UK-born workers (24.98%), though they also report higher rates of being paid less (21.18% vs 16.06%). **Income group patterns** show that high-income workers are most likely to report being paid more as expected (32.74%), while low-income workers show the highest rates of uncertainty about their pay situation (12.47% "don't know").

## Work Preferences

Next we explore simple counts/percentages of Outsourced workers preferences for in-house vs outsourced work.

```{r work-preferences}
work_pref_table <- experiential_data %>%
  count(Work_Preference) %>%
  mutate(
    Percentage = round(n / sum(n) * 100, 1),
    Display = paste0(n, " (", Percentage, "%)")
  ) %>%
  dplyr::select(Work_Preference, n, Percentage) %>%
  flextable() %>%
  set_header_labels(
    Work_Preference = "Work Preference",
    n = "Count",
    Percentage = "Percentage"
  ) %>%
  theme_vanilla()

work_pref_table
```

The work preferences data show that the largest group of outsourced workers (39.6%) express no preference between in-house and outsourced employment. However, among those with preferences, there is a clear preference for in-house work, with 32.1% preferring in-house positions (16.3% strongly + 15.8% prefer) compared to 17.9% preferring outsourced work (6.9% strongly + 11.0% prefer).

## Job Motivation

Here we examine the motivational factors that influence outsourced workers' decisions to remain in their current roles. Using a descriptive approach, we present the frequency and percentage distribution of responses across eleven distinct motivational categories, ranging from intrinsic factors (job satisfaction, workplace culture) to extrinsic factors (pay, location convenience) and personal circumstances (health conditions, caregiving responsibilities).

```{r job-motivation-setup}

# Create a summary of reasons why outsourced workers are in their current role
why_job_reasons <- data.frame(
  Reason = c(
    "I like doing this kind of work",
    "My job is in a convenient location", 
    "I can work flexibly in a way which suits me",
    "The pay is good",
    "I like my colleagues",
    "I like the workplace culture",
    "It is helping me develop skills and experience I need to progress",
    "This was the best job available to me",
    "I do not have the formal qualifications I need to do another job I would prefer",
    "I can do the job alongside managing my health conditions",
    "I can do the job alongside childcare or caring for others"
  ),
  Variable = c(
    "Why_Job_Like", "Why_Job_Convinient", "Why_Job_Flexibility", "Why_Job_Pay",
    "Why_Job_Collegues", "Why_Job_Culture", "Why_Job_Progress", "Why_Job_BestAvailable",
    "Why_Job_NotQualified", "Why_Job_Health", "Why_Job_Carer"
  )
)

# Count responses for each reason (excluding NAs)
why_job_counts <- data.frame(
  Reason = character(0),
  Count = numeric(0),
  Percentage = numeric(0)
)

for(i in 1:nrow(why_job_reasons)) {
  var_name <- why_job_reasons$Variable[i]
  reason_text <- why_job_reasons$Reason[i]
  
  # Count non-NA responses
  count <- sum(!is.na(experiential_data[[var_name]]))
  total_responses <- nrow(experiential_data)
  percentage <- round(count / total_responses * 100, 1)
  
  why_job_counts <- rbind(why_job_counts, data.frame(
    Reason = reason_text,
    Count = count,
    Percentage = percentage
  ))
}

# Sort by count (descending)
why_job_counts <- why_job_counts[order(why_job_counts$Count, decreasing = TRUE), ]

# Create table
why_job_table <- why_job_counts %>%
  flextable() %>%
  set_header_labels(
    Reason = "Reason for Current Role",
    Count = "Count",
    Percentage = "Percentage"
  ) %>%
  theme_vanilla() %>%
  autofit()

# Create and display plot
why_job_plot <- ggplot(why_job_counts, aes(x = Percentage, y = reorder(Reason, Percentage))) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  geom_text(aes(label = paste0(Percentage, "%")), 
            hjust = -0.05, size = 3) +
  labs(
    title = "Reasons for Current Role",
    x = "Percentage of Total Sample",
    y = "Reason"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 12, face = "bold"),
    axis.text.y = element_text(size = 8),
    axis.title = element_text(size = 10)
  ) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.15)))

```

```{r job-motivation-combined}
#| layout-ncol: 2
#| echo: false
#| out-width: "100%"

# Display table
why_job_table

# Display plot
why_job_plot
```

The job motivation analysis shows the key factors driving outsourced workers' employment decisions. **Practical considerations dominate**, with job location convenience being the most frequently cited reason (41.2%), followed closely by pay satisfaction (40.7%) and intrinsic job satisfaction (40.1%). **Social factors** also play a significant role, with over one-third (35.9%) citing positive relationships with colleagues. **Flexibility**, often assumed to be a primary motivation for outsourced work, ranks fifth at 32.0%. **Workplace culture** is important to just over a quarter (27.7%) of workers. **Necessity-driven motivations** are less common but notable, with 24.1% stating this was the best job available and 23.6% viewing it as a stepping stone for skill development. **Personal circumstances** account for smaller proportions: 14.6% balance the job with caregiving responsibilities, 13.0% manage health conditions, and only 9.0% remain due to qualification constraints (although it is possible that social desirability is playing a role in participants willingness to respond to questions about their level of qualifications and its relation to their employment possibilities).

## Pros and Cons of Outsourced Work

Here we explore outsourced workers' comparative assessments of their employment conditions relative to hypothetical in-house positions. Participants rated fourteen distinct workplace dimensions on a scale ranging from "less/worse" to "more/better" compared to in-house workers.

```{r pros-cons-setup}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Function to categorise pros and cons responses
categorise_response <- function(response) {
  if (is.na(response)) {
    return(NA)
  }
  
  response <- as.character(response)
  
  # Don't know category
  if (grepl("Don't know", response, ignore.case = TRUE)) {
    return("Don't know")
  }
  
  # Neither/No impact category
  if (grepl("Neither|no impact", response, ignore.case = TRUE)) {
    return("No impact / Neither")
  }
  
  # Less/Worse category
  if (grepl("less|worse|harder", response, ignore.case = TRUE)) {
    return("Less / Worse")
  }
  
  # More/Better category  
  if (grepl("more|better|easier", response, ignore.case = TRUE)) {
    return("More / Better")
  }
  
  # Default to Neither for other responses
  return("No impact / Neither")
}


# Define variable labels
pros_cons_labels <- data.frame(
  Variable = c("Pros_And_Cons_Flexibility", "Pros_And_Cons_Pay", "Pros_And_Cons_Hours", 
               "Pros_And_Cons_Holiday", "Pros_And_Cons_Terms", "Pros_And_Cons_Promotion",
               "Pros_And_Cons_Training", "Pros_And_Cons_Security", "Pros_And_Cons_Treatment",
               "Pros_And_Cons_Specialisation", "Pros_And_Cons_Connection",
               "Pros_And_Cons_FeelInvested","Pros_And_Cons_Rights", 
               "Pros_And_Cons_HealthSafety"),
  Label = c("Get to work flexibly", "Pay", "Access to secure working hours",
            "Holiday leave", "Terms and conditions", "Opportunity to progress / promotion",
            "Access to training / development", "Access to job security", "Treatment compared to in-house colleagues",
            "Opportunity to specialise in role or industry", "Feeling connected to people I work with",
            "Feeling invested in my role and my work", "Ease of asserting rights at work",
            "Protection of health and safety at work")
)

# Process each pros and cons variable
pros_cons_data <- data.frame()

for (i in 1:nrow(pros_cons_labels)) {
  var_name <- pros_cons_labels$Variable[i]
  label <- pros_cons_labels$Label[i]
  
  # Categorise responses
  categorised <- sapply(experiential_data[[var_name]], categorise_response)
  
  # Count categories
  counts <- table(categorised, useNA = "no")
  total <- sum(counts)
  
  # Calculate percentages
  for (category in names(counts)) {
    percentage <- round(counts[category] / total * 100, 0)
    pros_cons_data <- rbind(pros_cons_data, data.frame(
      Variable = label,
      Category = category,
      Count = as.numeric(counts[category]),
      Percentage = percentage
    ))
  }
}

# Calculate Less/Worse percentage for ordering
less_worse_pct <- pros_cons_data %>%
  filter(Category == "Less / Worse") %>%
  dplyr::select(Variable, Percentage) %>%
  rename(LessWorse_Pct = Percentage)

# Order by Less/Worse percentage (descending)
variable_order <- less_worse_pct[order(less_worse_pct$LessWorse_Pct, decreasing = TRUE), "Variable"]

# Set factor levels for proper ordering
pros_cons_data$Variable <- factor(pros_cons_data$Variable, levels = variable_order)
pros_cons_data$Category <- factor(pros_cons_data$Category, 
                                  levels = c("Don't know", "No impact / Neither", "More / Better", "Less / Worse"))

# Create the stacked bar chart

pros_cons_plot <- ggplot(pros_cons_data, aes(x = Percentage, y = Variable, fill = Category)) +
  geom_col(position = "stack") +
  geom_text(aes(label = ifelse(Percentage >= 5, paste0(Percentage, "%"), "")), 
            position = position_stack(vjust = 0.5), 
            size = 3, color = "white", fontface = "bold") +
  scale_fill_manual(values = c("Less / Worse" = "#e74c3c", 
                               "More / Better" = "#27ae60", 
                               "No impact / Neither" = "#3498db", 
                               "Don't know" = "#95a5a6")) +
  labs(
    title = "Reflections on the potential benefits and drawbacks of outsourced work",
    subtitle = "Compared to if you were an in-house / non-outsourced worker",
    x = "Percentage",
    y = "",
    fill = ""
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray60"),
    axis.text.y = element_text(size = 9),
    axis.title.x = element_text(size = 11),
    legend.position = "top",
    legend.text = element_text(size = 10),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  ) +
  scale_x_continuous(labels = function(x) paste0(x, "%"), 
                     breaks = seq(0, 100, 10),
                     expand = c(0, 0))

pros_cons_plot
```

The pros and cons suggests areas of disadvantage for outsourced workers compared to hypothetical in-house positions. **Career development emerges as the most problematic area**, with 24% reporting worse opportunities for progression/promotion and 20% citing reduced access to training and development. **Job security concerns** are similarly prominent, with 20% reporting worse access to job security. **Workplace relationships and engagement** show notable deficits, with 19% feeling less connected to colleagues and 17% feeling less invested in their role. **Workers' rights and voice** present challenges, with 19% finding it harder to assert rights at work.

**Flexibility stands out as a key advantage**, with 41.8% reporting better flexibility compared to only 14.2% reporting worse flexibility - making it the strongest positive aspect of outsourced work. **Pay perceptions are mixed**, with 17% reporting worse pay, though this varies significantly by demographic group as shown in the earlier analysis.

**The overall pattern** shows that while outsourced workers may benefit from increased flexibility, they face systematic disadvantages in career development, job security, workplace relationships, and employee voice. Most concerning is that career progression and training opportunities - crucial for long-term economic mobility - rank as the most problematic areas for outsourced workers.

## Cumulative Burden

Here we quantify the cumulative burden of negative work experiences among outsourced workers by transforming the categorical responses from the pros and cons analysis into numerical scores (-1 for negative, 0 for neutral, +1 for positive). We calculate the total number of negative outcomes per respondent across all 14 workplace dimensions and examine the distribution of these counts within the sample. The analysis includes a focused examination of workers who report being paid less than in-house colleagues, investigating whether pay disadvantage is associated with broader patterns of workplace disadvantage.

```{r negative-outcomes-processing}
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"
#| dpi: 300

# Function to transform categorical responses to numeric values
recode_pros_cons <- function(x) {
  case_when(
    grepl("more|better|easier", tolower(x)) ~ 1,
    grepl("less|harder|worse", tolower(x)) ~ -1,
    grepl("neither|no impact", tolower(x)) ~ 0,
    grepl("don't know", tolower(x)) ~ NA_real_,
    # Default case
    TRUE ~ NA_real_
  )
}

# Process the data using the same approach as the Quarto file
experiential_data <- experiential_data %>%
  mutate(across(starts_with("Pros_And_Cons"), 
                ~ recode_pros_cons(as.character(.)),
                .names = "{.col}_numeric"))

## Analysis of Negative Outcomes per Worker (using Quarto approach)

# Count negative outcomes for each respondent using the same method as Quarto file
experiential_data <- experiential_data %>%
  mutate(
    total = rowSums(dplyr::select(., contains("_numeric")), na.rm = TRUE),
    num_neg = rowSums(dplyr::select(., contains("_numeric")) == -1, na.rm = TRUE),
    num_neg_excl_pay = rowSums(dplyr::select(., contains("_numeric"), -Pros_And_Cons_Pay_numeric) == -1, na.rm = TRUE)
  ) %>%
  # Create meaningful categories (same as Quarto file)
  mutate(neg_category = case_when(
    num_neg == 0 ~ "0",
    num_neg == 1 ~ "1",
    num_neg == 2 ~ "2",
    num_neg == 3 ~ "3",
    num_neg == 4 ~ "4",
    num_neg >= 5 ~ "5+"
  )) %>%
  # Create categories excluding pay for the paid less analysis
  mutate(neg_category_excl_pay = case_when(
    num_neg_excl_pay == 0 ~ "0",
    num_neg_excl_pay == 1 ~ "1",
    num_neg_excl_pay == 2 ~ "2",
    num_neg_excl_pay == 3 ~ "3",
    num_neg_excl_pay == 4 ~ "4",
    num_neg_excl_pay >= 5 ~ "5+"
  )) %>%
  # Create readable categories for display
  mutate(
    negative_outcomes_category = case_when(
      num_neg == 0 ~ "No negative Impacts",
      num_neg %in% 1:2 ~ "1-2 negative Impacts", 
      num_neg %in% 3:4 ~ "3-4 negative Impacts",
      num_neg >= 5 ~ "5+ negative Impacts",
      TRUE ~ NA_character_
    )
  )

# Apply the same transformations to the filtered dataset
experiential_data_no_income_outliers <- experiential_data_no_income_outliers %>%
  mutate(across(starts_with("Pros_And_Cons"), 
                ~ recode_pros_cons(as.character(.)),
                .names = "{.col}_numeric")) %>%
  mutate(
    total = rowSums(dplyr::select(., contains("_numeric")), na.rm = TRUE),
    num_neg = rowSums(dplyr::select(., contains("_numeric")) == -1, na.rm = TRUE)
  ) %>%
  mutate(neg_category = case_when(
    num_neg == 0 ~ "0",
    num_neg == 1 ~ "1",
    num_neg == 2 ~ "2",
    num_neg == 3 ~ "3",
    num_neg == 4 ~ "4",
    num_neg >= 5 ~ "5+"
  )) %>%
  mutate(
    negative_outcomes_category = case_when(
      num_neg == 0 ~ "No negative impacts",
      num_neg %in% 1:2 ~ "1-2 negative outcomes", 
      num_neg %in% 3:4 ~ "3-4 negative outcomes",
      num_neg >= 5 ~ "5+ negative outcomes",
      TRUE ~ NA_character_
    )
  )

# Create summary table using the same approach as Quarto file
negative_outcomes_summary <- experiential_data %>%
  count(negative_outcomes_category) %>%
  mutate(
    Percentage = round(n / sum(n) * 100, 1),
    Display = paste0(n, " (", Percentage, "%)")
  ) %>%
  filter(!is.na(negative_outcomes_category)) %>%
  # Reorder for logical presentation
  mutate(negative_outcomes_category = factor(negative_outcomes_category, 
                                           levels = c("No negative impacts", 
                                                     "1-2 negative outcomes",
                                                     "3-4 negative outcomes", 
                                                     "5+ negative outcomes"))) %>%
  arrange(negative_outcomes_category)

# Create table using flextable
negative_outcomes_table <- negative_outcomes_summary %>%
  dplyr::select(negative_outcomes_category, n, Percentage) %>%
  flextable() %>%
  set_header_labels(
    negative_outcomes_category = "Number of Negative Outcomes",
    n = "Count",
    Percentage = "Percentage"
  ) %>%
  theme_vanilla() %>%
  autofit()

negative_outcomes_table

# Create visualisation
negative_outcomes_plot <- ggplot(negative_outcomes_summary, 
                                aes(x = Percentage, y = fct_rev(negative_outcomes_category))) +
  geom_col(fill = c("#27ae60", "#f39c12", "#e67e22", "#e74c3c"), alpha = 0.8) +
  geom_text(aes(label = paste0(Percentage, "%")), 
            hjust = -0.05, size = 4, fontweight = "bold") +
  labs(
    title = "Distribution of Negative Outcomes Among Outsourced Workers",
    subtitle = "Number of negative impacts compared to in-house work",
    x = "Percentage of Workers",
    y = ""
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 12, color = "gray60"),
    axis.text.y = element_text(size = 11),
    axis.title.x = element_text(size = 11),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  ) +
  scale_x_continuous(expand = expansion(mult = c(0, 0.15)))

negative_outcomes_plot
```

The negative Impacts analysis reveals the cumulative burden of workplace disadvantages among outsourced workers. **The distribution shows significant polarisation**: 38.5% of workers report no negative outcomes, while 23.6% experience five or more negative outcomes across the fourteen workplace dimensions (mean = 2.51, median = 1).

```{r negative-outcomes-paid-less}
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"
#| dpi: 300

#Percentage of people reportring they are paid less and number of negative outcomes

# Filter for people paid less and create negative categories (excluding pay)
paid_less_group <- experiential_data %>%
  filter(Pros_And_Cons_Pay == 'I get paid less') %>%
  count(neg_category_excl_pay) %>%
  mutate(percent = (n / sum(n)) * 100)

# Create the bar plot for paid less group
ggplot(paid_less_group, aes(x = neg_category_excl_pay, y = percent, fill = neg_category_excl_pay)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(round(percent, 1), "%")), vjust = -0.5) +
  labs(title = "Additional Negative Outcomes for People Who Say They Are Paid Less",
       subtitle = "Excluding pay disadvantage (showing additional workplace problems)",
       x = "Number of Additional Negative Responses (beyond pay)",
       y = "Percentage of People Paid Less") +
  scale_fill_brewer(palette = "Reds") +
  theme_minimal()
```

**Most striking is the relationship between pay disadvantage and cumulative negative outcomes.** Among workers who report being paid less than in-house colleagues, **96.4% experience at least one additional negative outcome beyond pay** - only 3.6% report pay disadvantage as an isolated issue. The concentration of negative outcomes among this group is severe: **69.7% experience five or more total negative outcomes** (including pay) compared to just 23.6% in the overall population - nearly a threefold difference.

**The pattern suggests that pay disadvantage rarely occurs in isolation** but is typically accompanied by broader workplace disadvantages. Workers reporting pay disadvantage show dramatically higher rates of multiple negative outcomes (10.1% have 4+ negatives including pay vs 7.4% overall), indicating that pay inequity is a marker of comprehensive workplace disadvantage rather than an isolated issue.

## Statistical Analysis

Continuing the analysis of pros and cons of outsourced working this section presents descriptive analysis of mean negative outcomes across demographic groups, followed by regression modeling to identify predictors. The analysis compares Poisson, linear, and negative binomial regression models using fit statistics (AIC, deviance, RMSE) to select the best-fitting model. Results are presented through a model comparison table, coefficients table with rate ratios and confidence intervals, forest plot visualisation of rate ratios, and predicted values for different income groups. The analysis identifies which demographic characteristics are associated with higher rates of negative workplace outcomes among outsourced workers.

The statistical analysis reveals significant demographic predictors of negative workplace outcomes among outsourced workers. **Model selection favoured negative binomial regression** due to overdispersion (ratio = 3.387), with this model showing the best fit (AIC = 6519.5) compared to Poisson (AIC = 8173.4) and linear models (AIC = 7700.3).

```{r statistical-analysis-setup}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# 4. Mean number of negatives by group
means_by_group <- experiential_data_no_income_outliers %>%
  dplyr::select(income_group, Ethnicity_Collapsed, Sex, Education_Band, BORNUK_binary, num_neg) %>%
  pivot_longer(cols = -num_neg, names_to = "demographic", values_to = "group") %>%
  filter(!is.na(group)) %>%
  group_by(demographic, group) %>%
  summarise(
    mean_negatives = round(mean(num_neg, na.rm = TRUE), 2),
    median_negatives = median(num_neg, na.rm = TRUE),
    n = n(),
    .groups = "drop"
  )

# Create visualisation of means
means_plot <- means_by_group %>%
  ggplot(aes(x = group, y = mean_negatives, fill = demographic)) +
  geom_col(alpha = 0.8) +
  geom_text(aes(label = mean_negatives), vjust = -0.5, size = 3) +
  facet_wrap(~ demographic, scales = "free_x") +
  labs(
    title = "Mean Number of Negative Outcomes by Demographic Group",
    x = "",
    y = "Mean Number of Negatives"
  ) +
  theme_minimal() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    legend.position = "none"
  )

means_plot

## Regression Analysis of Demographic Differences

# Ensure we have complete data for regression
regression_data <- experiential_data_no_income_outliers %>%
  filter(!is.na(num_neg), !is.na(income_group), !is.na(Ethnicity_Collapsed),
         !is.na(Sex), !is.na(Education_Band), !is.na(BORNUK_binary),
         !is.na(Region), !is.na(OutsourcedNonOL), !is.na(Age))

demographics <- c("income_group", "Ethnicity_Collapsed", "Sex", "Education_Band", "BORNUK_binary", "Region", "Age", "OutsourcedNonOL")

# 1.1 Univariate Models
univariate_models <- list()
model_summaries <- list()

for (demo in demographics) {
  # Create formula dynamically
  formula_str <- paste("num_neg ~", demo)
  formula_obj <- as.formula(formula_str)
  
  # Poisson regression
  poisson_model <- glm(formula_obj, 
                      data = regression_data, 
                      family = poisson)
  
  # Linear regression for comparison
  linear_model <- lm(formula_obj, 
                    data = regression_data)
  
  # Store models
  univariate_models[[demo]] <- list(
    poisson = poisson_model,
    linear = linear_model
  )
  
  # Extract summary statistics
  poisson_summary <- tidy(poisson_model, conf.int = TRUE)
  linear_summary <- tidy(linear_model, conf.int = TRUE)
  
  model_summaries[[demo]] <- list(
    demographic = demo,
    poisson_aic = AIC(poisson_model),
    linear_r_squared = summary(linear_model)$r.squared,
    poisson_deviance = poisson_model$deviance,
    linear_rmse = sqrt(mean(residuals(linear_model)^2))
  )
}

# 1.2 Multivariate Model
# Poisson regression with all demographics
full_poisson <- glm(num_neg ~ income_group + Ethnicity_Collapsed + Sex + 
                   Education_Band + BORNUK_binary + Age + Region + OutsourcedNonOL, 
                   data = regression_data, 
                   family = poisson)

# Linear regression with all demographics  
full_linear <- lm(num_neg ~ income_group + Ethnicity_Collapsed + Sex + 
                 Education_Band + BORNUK_binary + Age + Region + OutsourcedNonOL, 
                 data = regression_data)

# Check for overdispersion in Poisson model
overdispersion_ratio <- full_poisson$deviance / full_poisson$df.residual
cat("Overdispersion ratio:", round(overdispersion_ratio, 3), "\n")
cat("If > 1.5, consider negative binomial or quasi-Poisson\n")

# If overdispersed, fit negative binomial
if(overdispersion_ratio > 1.5) {
  full_negbin <- glm.nb(num_neg ~ income_group + Ethnicity_Collapsed + Sex + 
                       Education_Band + BORNUK_binary + Age + Region + OutsourcedNonOL, 
                       data = regression_data)
  cat("Negative binomial model fitted due to overdispersion\n")
}

# 1.3 Model Comparison Table
model_comparison <- data.frame(
  Model = c("Full Poisson", "Full Linear", if(exists("full_negbin")) "Full Negative Binomial"),
  AIC = c(AIC(full_poisson), AIC(full_linear), if(exists("full_negbin")) AIC(full_negbin) else NA),
  Deviance = c(full_poisson$deviance, NA, if(exists("full_negbin")) full_negbin$deviance else NA),
  R_Squared = c(NA, summary(full_linear)$r.squared, NA),
  RMSE = c(sqrt(mean(residuals(full_poisson)^2)), 
           sqrt(mean(residuals(full_linear)^2)), 
           if(exists("full_negbin")) sqrt(mean(residuals(full_negbin)^2)) else NA)
) %>%
  filter(!is.na(Model))

# Create model comparison table
model_comparison_table <- model_comparison %>%
  mutate(across(where(is.numeric), ~ round(.x, 3))) %>%
  flextable() %>%
  set_header_labels(
    Model = "Model Type",
    AIC = "AIC",
    Deviance = "Deviance", 
    R_Squared = "R-Squared",
    RMSE = "RMSE"
  ) %>%
  theme_vanilla() %>%
  autofit()

model_comparison_table

# 1.4 Coefficient Analysis (using best model)
best_model <- if(exists("full_negbin")) full_negbin else full_poisson

# Extract coefficients with confidence intervals
coefficients_df <- tidy(best_model, conf.int = TRUE) %>%
  filter(term != "(Intercept)") %>%
  mutate(
    # For Poisson/NegBin: exp(estimate) gives rate ratios
    rate_ratio = exp(estimate),
    rate_ratio_lower = exp(conf.low),
    rate_ratio_upper = exp(conf.high),
    significant = p.value < 0.05
  )

# Create coefficients table
coefficients_table <- coefficients_df %>%
  dplyr::select(term, estimate, std.error, rate_ratio, conf.low, conf.high, p.value, significant) %>%
  mutate(across(where(is.numeric), ~ round(.x, 4))) %>%
  flextable() %>%
  set_header_labels(
    term = "Variable",
    estimate = "Coefficient",
    std.error = "Std Error",
    rate_ratio = "Rate Ratio",
    conf.low = "95% CI Lower",
    conf.high = "95% CI Upper", 
    p.value = "P-Value",
    significant = "Significant"
  ) %>%
  theme_vanilla() %>%
  autofit()

coefficients_table

# 1.5 Forest Plot of Coefficients
forest_plot <- coefficients_df %>%
  mutate(
   term_clean = str_replace_all(term, "BORNUK_binary", ""),
   term_clean = str_replace_all(term_clean, "_", " ")
  ) %>%
  ggplot(aes(x = rate_ratio, y = reorder(term_clean, rate_ratio))) +
  geom_point(size = 3, color = "darkblue") +
  geom_errorbarh(aes(xmin = rate_ratio_lower, xmax = rate_ratio_upper), 
                 height = 0.2, color = "darkblue") +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Rate Ratios for Number of Negative Outcomes",
    subtitle = "Showing 95% confidence intervals",
    x = "Rate Ratio (>1 = higher rate of negatives)",
    y = "",
    caption = "Reference: Male, White British, Mid income, etc."
  ) +
  theme_minimal() +
  theme(
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank()
  )

forest_plot
```

**Education emerges as the strongest predictor**, with both mid-education (rate ratio = 0.738) and low-education workers (rate ratio = 0.649) experiencing significantly fewer negative outcomes than highly educated workers. This counterintuitive finding suggests that **higher education may increase expectations or awareness of workplace disadvantages** rather than protecting against them.

**Place of birth shows significant effects**, with workers not born in the UK experiencing 38% more negative outcomes (rate ratio = 1.38) compared to UK-born workers, while those preferring not to disclose birth status report 56% fewer negative outcomes (rate ratio = 0.436). **Descriptive patterns show** that workers not born in the UK have the highest mean negative outcomes (3.2), while those born in the UK average 2.33 negative outcomes.

**Ethnicity shows some variation**, with Black/African/Caribbean workers reporting 24% fewer negative outcomes than White British workers (rate ratio = 0.761).

**Gender differences are evident**, with female workers experiencing 21% fewer negative outcomes than male workers (rate ratio = 0.789). **Age shows a protective effect**, with each additional year associated with slightly fewer negative outcomes (rate ratio = 0.994).

```{r}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300
# Create prediction data with proper error handling
predicted_data <- expand_grid(
  income_group = levels(factor(regression_data$income_group)),
  Ethnicity_Collapsed = "White British",  # Hold constant
  Sex = "Male",  # Hold constant
  Education_Band = if("Education_Band" %in% names(regression_data)) levels(factor(regression_data$Education_Band))[1] else "High",
  BORNUK_binary = if("BORNUK_binary" %in% names(regression_data)) levels(factor(regression_data$BORNUK_binary))[1] else "Yes",
  Region = if("Region" %in% names(regression_data)) names(sort(table(regression_data$Region), decreasing = TRUE))[1] else "London",
  OutsourcedNonOL = if("OutsourcedNonOL" %in% names(regression_data)) names(sort(table(regression_data$OutsourcedNonOL), decreasing = TRUE))[1] else "Outsourced",
  Age = median(regression_data$Age, na.rm = TRUE)  # Hold constant
)

# Ensure all variables are factors where needed
predicted_data <- predicted_data %>%
  mutate(
    income_group = factor(income_group, levels = levels(factor(regression_data$income_group))),
    Ethnicity_Collapsed = factor(Ethnicity_Collapsed, levels = levels(factor(regression_data$Ethnicity_Collapsed))),
    Sex = factor(Sex, levels = levels(factor(regression_data$Sex))),
    Education_Band = if("Education_Band" %in% names(regression_data)) factor(Education_Band, levels = levels(factor(regression_data$Education_Band))) else Education_Band,
    BORNUK_binary = if("BORNUK_binary" %in% names(regression_data)) factor(BORNUK_binary, levels = levels(factor(regression_data$BORNUK_binary))) else BORNUK_binary,
    Region = if("Region" %in% names(regression_data)) factor(Region, levels = levels(factor(regression_data$Region))) else Region,
    OutsourcedNonOL = if("OutsourcedNonOL" %in% names(regression_data)) factor(OutsourcedNonOL, levels = levels(factor(regression_data$OutsourcedNonOL))) else OutsourcedNonOL
  ) %>%
  mutate(
    predicted_negatives = predict(best_model, newdata = ., type = "response")
  )

# Plot predicted values
predicted_plot <- predicted_data %>%
  ggplot(aes(x = income_group, y = predicted_negatives)) +
  geom_col(fill = "steelblue", alpha = 0.7) +
  geom_text(aes(label = round(predicted_negatives, 2)), vjust = -0.5) +
  labs(
    title = "Predicted Number of Negative Outcomes by Income Group",
    subtitle = "Holding other demographics constant",
    x = "Income Group",
    y = "Predicted Number of Negatives"
  ) +
  theme_minimal()

predicted_plot
```

**Income effects are notable**, with high-income workers experiencing 22% fewer negative outcomes than mid-income workers (rate ratio = 0.777). **The predicted values plot demonstrates this income effect more clearly** by holding all other demographic variables constant. Under these controlled conditions, the model predicts that high-income workers will experience approximately 2.14 negative outcomes compared to 2.75 for mid-income workers and 3.56 for low-income workers - a reduction of 0.61 and 1.42 (respectively) negative outcomes purely attributable to income level.

## Work Conditions

Next we examine specific employment conditions that characterise outsourced work arrangements, focusing on five key dimensions: guaranteed hours, notice periods for working schedules, advance warning of shift cancellations, compensation for cancelled shifts, and sick pay provision. The analysis presents descriptive statistics for each condition and conducts cross-tabulations with demographic variables to identify potential disparities in work conditions across different groups. Statistical tests (chi-square or Fisher's exact tests) are employed to assess the significance of observed associations, with effect sizes calculated using Cramér's V.

```{r work-conditions-setup}
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"
#| dpi: 300
#| echo: false

# Variables to analyze:
work_variables <- c("Guaranteed_Hours", "Notice_Of_Working_Hours", "Notice_Of_Cancelled_Shifts", 
                   "Cancelled_Shift_Pay", "Sick_Pay")

for (var in work_variables) {
  cat("\n", var, ":\n")
  response_counts <- table(experiential_data[[var]], useNA = "ifany")
  print(response_counts)
  cat("Total responses:", sum(response_counts), "\n")
}

# Create percentage summaries for each variable
work_conditions_summary <- list()

for (var in work_variables) {
  # Calculate counts and percentages
  counts <- table(experiential_data[[var]], useNA = "no")  # Exclude NAs from percentage calculation
  total_responses <- sum(counts)
  
  # Create summary dataframe
  summary_df <- data.frame(
    Response = names(counts),
    Count = as.numeric(counts),
    Percentage = round(as.numeric(counts) / total_responses * 100, 1),
    stringsAsFactors = FALSE
  )
  
  # Store in list
  work_conditions_summary[[var]] <- summary_df
}

# Display tables for each variable
library(flextable)

# Variable labels for better presentation
variable_labels <- c(
  "Guaranteed_Hours" = "Guaranteed Hours",
  "Notice_Of_Working_Hours" = "Notice of Working Hours", 
  "Notice_Of_Cancelled_Shifts" = "Notice of Cancelled Shifts",
  "Cancelled_Shift_Pay" = "Cancelled Shift Pay",
  "Sick_Pay" = "Sick Pay"
)

# Create tables for each variable
work_tables <- list()

for (var in work_variables) {
  table_data <- work_conditions_summary[[var]] %>%
    arrange(desc(Percentage))  # Order by percentage descending
  
  work_table <- table_data %>%
    flextable() %>%
    set_header_labels(
      Response = variable_labels[var],
      Count = "Count",
      Percentage = "Percentage (%)"
    ) %>%
    theme_vanilla() %>%
    autofit()
  
  work_tables[[var]] <- work_table
  
  # Print table
  #print(work_table)
}
```

```{r work-conditions-visualisation}
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"
#| dpi: 300

# Create visualisations for each variable
work_plots <- list()

for (var in work_variables) {
  plot_data <- work_conditions_summary[[var]] %>%
    arrange(Percentage) %>%  # Order for horizontal bar chart
    mutate(Response = factor(Response, levels = Response))  # Preserve order
  
  work_plot <- ggplot(plot_data, aes(x = Percentage, y = Response)) +
    geom_col(fill = "steelblue", alpha = 0.7) +
    geom_text(aes(label = paste0(Percentage, "%")), 
              hjust = -0.05, size = 3) +
    labs(
      title = paste("Distribution of Responses:", variable_labels[var]),
      x = "Percentage of Respondents",
      y = ""
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 12, face = "bold"),
      axis.text.y = element_text(size = 9),
      axis.title.x = element_text(size = 10),
      panel.grid.major.y = element_blank(),
      panel.grid.minor = element_blank()
    ) +
    scale_x_continuous(expand = expansion(mult = c(0, 0.15)))
  
  work_plots[[var]] <- work_plot
  
  # Print plot
  print(work_plot)
}

# Create a combined summary showing key statistics
work_summary_stats <- data.frame(
  Variable = variable_labels[work_variables],
  Total_Responses = sapply(work_variables, function(var) {
    sum(table(experiential_data[[var]], useNA = "no"))
  }),
  Missing_Values = sapply(work_variables, function(var) {
    sum(is.na(experiential_data[[var]]))
  }),
  Most_Common_Response = sapply(work_variables, function(var) {
    summary_data <- work_conditions_summary[[var]]
    summary_data$Response[which.max(summary_data$Count)]
  }),
  Most_Common_Percentage = sapply(work_variables, function(var) {
    summary_data <- work_conditions_summary[[var]]
    paste0(max(summary_data$Percentage), "%")
  }),
  stringsAsFactors = FALSE
)

# Create summary table
work_summary_table <- work_summary_stats %>%
  flextable() %>%
  set_header_labels(
    Variable = "Work Condition Variable",
    Total_Responses = "Total Responses",
    Missing_Values = "Missing Values",
    Most_Common_Response = "Most Common Response",
    Most_Common_Percentage = "Percentage"
  ) %>%
  theme_vanilla() %>%
  autofit()

work_summary_table

## Cross-tabulation: Notice of Working Hours by Income Group

# Create simplified categorisation for Notice of Working Hours
experiential_data <- experiential_data %>%
  mutate(Notice_Of_Working_Hours_Simplified = case_when(
    Notice_Of_Working_Hours %in% c("Less than 24 hours", "1-3 days", "4-6 days") ~ "Less than a week",
    TRUE ~ Notice_Of_Working_Hours
  ))

# Apply same simplification to filtered dataset
experiential_data_no_income_outliers <- experiential_data_no_income_outliers %>%
  mutate(Notice_Of_Working_Hours_Simplified = case_when(
    Notice_Of_Working_Hours %in% c("Less than 24 hours", "1-3 days", "4-6 days") ~ "Less than a week",
    TRUE ~ Notice_Of_Working_Hours
  ))

# Cross-tabulation with simplified variable (using filtered dataset for income analysis)
notice_pay_crosstab <- crosstable(experiential_data_no_income_outliers, 
                                  cols = Notice_Of_Working_Hours_Simplified, 
                                  by = income_group,
                                  total = "both",
                                  percent_pattern = "{n} ({p_col})",
                                  percent_digits = 2) %>%
  as_flextable() %>%
  set_caption("Notice of Working Hours by Income Group")

notice_pay_crosstab

## Cross-tabulation: Guaranteed Hours by Income Group

guaranteed_hours_income_crosstab <- crosstable(experiential_data_no_income_outliers, 
                                              cols = Guaranteed_Hours, 
                                              by = income_group,
                                              total = "both",
                                              percent_pattern = "{n} ({p_col})",
                                              percent_digits = 2) %>%
  as_flextable() %>%
  set_caption("Guaranteed Hours by Income Group")

guaranteed_hours_income_crosstab

## Cross-tabulation: Sick Pay by Income Group

sick_pay_income_crosstab <- crosstable(experiential_data_no_income_outliers, 
                                      cols = Sick_Pay, 
                                      by = income_group,
                                      total = "both",
                                      percent_pattern = "{n} ({p_col})",
                                      percent_digits = 2) %>%
  as_flextable() %>%
  set_caption("Sick Pay by Income Group")

sick_pay_income_crosstab

## Notice of Working Hours by Ethnicity
notice_ethnicity_crosstab <- crosstable(experiential_data, 
                                        cols = Notice_Of_Working_Hours_Simplified, 
                                        by = Ethnicity_Collapsed,
                                        total = "both",
                                        percent_pattern = "{n} ({p_col})",
                                        percent_digits = 2) %>%
  as_flextable() %>%
  set_caption("Notice of Working Hours by Ethnicity")

notice_ethnicity_crosstab


# Statistical analysis of notice of working hours by ethnicity
# First check chi-square assumptions
chi_results <- chisq.test(table(experiential_data$Notice_Of_Working_Hours_Simplified, 
                                experiential_data$Ethnicity_Collapsed))

min_expected <- min(chi_results$expected)
cat("Chi-square assumption check - Minimum expected frequency:", round(min_expected, 2))
if(min_expected >= 5) {
  cat(" ✓ Chi-square assumptions met\n")
} else {
  cat(" ✗ Chi-square assumptions violated - using Fisher's exact test\n")
}

# Create contingency table for analysis
contingency_table <- table(experiential_data$Notice_Of_Working_Hours_Simplified, 
                          experiential_data$Ethnicity_Collapsed)

#print(contingency_table)

# Fisher's exact test (appropriate when chi-square assumptions violated)
fisher_results <- fisher.test(contingency_table, simulate.p.value = TRUE, B = 10000)

# Calculate Cramér's V for effect size
library(vcd)
cramers_v <- assocstats(contingency_table)$cramer

# Create comprehensive results summary
fisher_summary <- data.frame(
  Test = "Fisher's exact test",
  `p-value` = ifelse(fisher_results$p.value < 0.001, "< 0.001", 
                     round(fisher_results$p.value, 4)),
  `Cramers V` = round(cramers_v, 3),
  `Effect Size` = case_when(
    cramers_v < 0.1 ~ "Negligible",
    cramers_v < 0.3 ~ "Small",
    cramers_v < 0.5 ~ "Medium", 
    TRUE ~ "Large"
  ),
  Significance = ifelse(fisher_results$p.value < 0.05, "Significant", "Not significant"),
  stringsAsFactors = FALSE
)

# Display results
print(fisher_summary)

# Post-hoc analysis assessment
cat("\nPost-hoc Analysis Assessment:\n")
if(fisher_results$p.value < 0.05) {
  cat("✓ Overall association is significant\n")
  
  # Check if post-hoc tests are warranted
  ethnicity_levels <- length(unique(experiential_data$Ethnicity_Collapsed[!is.na(experiential_data$Ethnicity_Collapsed)]))
  notice_levels <- length(unique(experiential_data$Notice_Of_Working_Hours_Simplified[!is.na(experiential_data$Notice_Of_Working_Hours_Simplified)]))
  
  if(ethnicity_levels > 2 || notice_levels > 2) {
    cat("✓ Multiple categories present - post-hoc pairwise comparisons recommended\n")
    
    # Perform pairwise Fisher's exact tests between ethnicity groups
    cat("\nPairwise Fisher's Exact Tests (Bonferroni corrected):\n")
    
    ethnicity_groups <- unique(experiential_data$Ethnicity_Collapsed[!is.na(experiential_data$Ethnicity_Collapsed)])
    pairwise_results <- list()
    
    # Get all pairwise combinations
    combinations <- combn(ethnicity_groups, 2, simplify = FALSE)
    
    for(i in seq_along(combinations)) {
      group1 <- combinations[[i]][1]
      group2 <- combinations[[i]][2]
      
      # Create pairwise table
      subset_data <- experiential_data[experiential_data$Ethnicity_Collapsed %in% c(group1, group2), ]
      subset_table <- table(subset_data$Notice_Of_Working_Hours_Simplified, 
                           subset_data$Ethnicity_Collapsed, useNA = "no")
      subset_table <- subset_table[rowSums(subset_table) > 0, colSums(subset_table) > 0, drop = FALSE]
      
      if(nrow(subset_table) > 1 && ncol(subset_table) > 1) {
        # Fisher's exact test
        pairwise_fisher <- fisher.test(subset_table, simulate.p.value = TRUE, B = 5000)
        pairwise_cramers <- assocstats(subset_table)$cramer
        
        # Calculate directional interpretation with safe indexing
        direction <- tryCatch({
          # Use safer indexing with existence checks
          row_idx <- which(rownames(subset_table) == "Less than a week")
          col1_idx <- which(colnames(subset_table) == group1)
          col2_idx <- which(colnames(subset_table) == group2)
          
          if(length(row_idx) > 0 && length(col1_idx) > 0 && length(col2_idx) > 0) {
            group1_count <- subset_table[row_idx, col1_idx]
            group2_count <- subset_table[row_idx, col2_idx]
            
            group1_total <- sum(subset_table[, col1_idx])
            group2_total <- sum(subset_table[, col2_idx])
            
            group1_pct <- round(group1_count / group1_total * 100, 1)
            group2_pct <- round(group2_count / group2_total * 100, 1)
            
            if(group1_pct > group2_pct) {
              paste0(group1, " higher (", group1_pct, "% vs ", group2_pct, "%)")
            } else if(group2_pct > group1_pct) {
              paste0(group2, " higher (", group2_pct, "% vs ", group1_pct, "%)")
            } else {
              paste0("Similar (", group1_pct, "% vs ", group2_pct, "%)")
            }
          } else {
            "Cannot calculate - missing categories"
          }
        }, error = function(e) {
          "Error in calculation"
        })
        
        pairwise_results[[i]] <- data.frame(
          Comparison = paste(group1, "vs", group2),
          p_value = pairwise_fisher$p.value,
          cramers_v = round(pairwise_cramers, 3),
          less_than_week_direction = direction,
          stringsAsFactors = FALSE
        )
      }
    }
    
    # Combine results and apply Bonferroni correction
    if(length(pairwise_results) > 0) {
      pairwise_df <- do.call(rbind, pairwise_results)
      pairwise_df$p_adjusted = p.adjust(pairwise_df$p_value, method = "bonferroni")
      pairwise_df$significant_adjusted = pairwise_df$p_adjusted < 0.05
      
      # Add effect size interpretation
      pairwise_df$effect_size = case_when(
        pairwise_df$cramers_v < 0.1 ~ "Negligible",
        pairwise_df$cramers_v < 0.3 ~ "Small",
        pairwise_df$cramers_v < 0.5 ~ "Medium", 
        TRUE ~ "Large"
      )
      
      # Round p-values for display
      pairwise_df$p_value = round(pairwise_df$p_value, 4)
      pairwise_df$p_adjusted = round(pairwise_df$p_adjusted, 4)
      
      # Reorder columns for better readability
      pairwise_df <- pairwise_df[, c("Comparison", "p_value", "p_adjusted", "significant_adjusted", 
                                   "cramers_v", "effect_size", "less_than_week_direction")]
      
      print(pairwise_df)
      
      # Highlight significant findings
      significant_pairs <- pairwise_df[pairwise_df$significant_adjusted, ]
      if(nrow(significant_pairs) > 0) {
        cat("\nSignificant pairwise differences (after Bonferroni correction):\n")
        for(i in 1:nrow(significant_pairs)) {
          cat("•", significant_pairs$Comparison[i], 
              "(p =", significant_pairs$p_adjusted[i], 
              ", Cramér's V =", significant_pairs$cramers_v[i], ")\n")
          cat("  Direction:", significant_pairs$less_than_week_direction[i], "\n")
        }
      } else {
        cat("\nNo significant pairwise differences after Bonferroni correction.\n")
      }
    }
    
  } else {
    cat("→ Only 2 categories in each variable - no post-hoc tests needed\n")
  }
} else {
  cat("→ Overall association not significant - post-hoc tests not recommended\n")
}

## Cross-tabulation and Statistical Analysis: Guaranteed Hours by Ethnicity

# Cross-tabulation table
guaranteed_hours_ethnicity_crosstab <- crosstable(experiential_data, 
                                                 cols = Guaranteed_Hours, 
                                                 by = Ethnicity_Collapsed,
                                                 total = "both",
                                                 percent_pattern = "{n} ({p_col})",
                                                 percent_digits = 2) %>%
  as_flextable() %>%
  set_caption("Guaranteed Hours by Ethnicity")

guaranteed_hours_ethnicity_crosstab

# Statistical analysis of guaranteed hours by ethnicity
# First check chi-square assumptions
chi_results_hours <- chisq.test(table(experiential_data$Guaranteed_Hours, 
                                     experiential_data$Ethnicity_Collapsed))

min_expected_hours <- min(chi_results_hours$expected)
cat("Chi-square assumption check - Minimum expected frequency:", round(min_expected_hours, 2))
if(min_expected_hours >= 5) {
  cat(" ✓ Chi-square assumptions met\n")
} else {
  cat(" ✗ Chi-square assumptions violated - using Fisher's exact test\n")
}

# Create contingency table for analysis
contingency_table_hours <- table(experiential_data$Guaranteed_Hours, 
                                experiential_data$Ethnicity_Collapsed)

print(contingency_table_hours)

# Fisher's exact test (appropriate when chi-square assumptions violated)
fisher_results_hours <- fisher.test(contingency_table_hours, simulate.p.value = TRUE, B = 10000)

# Calculate Cramér's V for effect size
cramers_v_hours <- assocstats(contingency_table_hours)$cramer

# Create comprehensive results summary
fisher_summary_hours <- data.frame(
  Test = "Fisher's exact test",
  `p-value` = ifelse(fisher_results_hours$p.value < 0.001, "< 0.001", 
                     round(fisher_results_hours$p.value, 4)),
  `Cramers V` = round(cramers_v_hours, 3),
  `Effect Size` = case_when(
    cramers_v_hours < 0.1 ~ "Negligible",
    cramers_v_hours < 0.3 ~ "Small",
    cramers_v_hours < 0.5 ~ "Medium", 
    TRUE ~ "Large"
  ),
  Significance = ifelse(fisher_results_hours$p.value < 0.05, "Significant", "Not significant"),
  stringsAsFactors = FALSE
)

# Display results
cat("\nFisher's Exact Test Results:\n")
print(fisher_summary_hours)

# Post-hoc analysis assessment
cat("\nPost-hoc Analysis Assessment:\n")
if(fisher_results_hours$p.value < 0.05) {
  cat("✓ Overall association is significant\n")
  
  # Check if post-hoc tests are warranted
  ethnicity_levels_hours <- length(unique(experiential_data$Ethnicity_Collapsed[!is.na(experiential_data$Ethnicity_Collapsed)]))
  hours_levels <- length(unique(experiential_data$Guaranteed_Hours[!is.na(experiential_data$Guaranteed_Hours)]))
  
  if(ethnicity_levels_hours > 2 || hours_levels > 2) {
    cat("✓ Multiple categories present - post-hoc pairwise comparisons recommended\n")
    
    # Perform pairwise Fisher's exact tests between ethnicity groups
    cat("\nPairwise Fisher's Exact Tests (Bonferroni corrected):\n")
    
    ethnicity_groups_hours <- unique(experiential_data$Ethnicity_Collapsed[!is.na(experiential_data$Ethnicity_Collapsed)])
    pairwise_results_hours <- list()
    
    # Get all pairwise combinations
    combinations_hours <- combn(ethnicity_groups_hours, 2, simplify = FALSE)
    
    for(i in seq_along(combinations_hours)) {
      group1 <- combinations_hours[[i]][1]
      group2 <- combinations_hours[[i]][2]
      
      # Create pairwise table
      subset_data <- experiential_data[experiential_data$Ethnicity_Collapsed %in% c(group1, group2), ]
      subset_table <- table(subset_data$Guaranteed_Hours, 
                           subset_data$Ethnicity_Collapsed, useNA = "no")
      subset_table <- subset_table[rowSums(subset_table) > 0, colSums(subset_table) > 0, drop = FALSE]
      
      if(nrow(subset_table) > 1 && ncol(subset_table) > 1) {
        # Fisher's exact test
        pairwise_fisher <- fisher.test(subset_table, simulate.p.value = TRUE, B = 5000)
        pairwise_cramers <- assocstats(subset_table)$cramer
        
        # Calculate directional interpretation with safe indexing
        # Focus on "35+ hours" as the key category (full-time equivalent)
        direction <- tryCatch({
          # Use safer indexing with existence checks
          row_idx <- which(rownames(subset_table) == "35+ hours")
          col1_idx <- which(colnames(subset_table) == group1)
          col2_idx <- which(colnames(subset_table) == group2)
          
          if(length(row_idx) > 0 && length(col1_idx) > 0 && length(col2_idx) > 0) {
            group1_count <- subset_table[row_idx, col1_idx]
            group2_count <- subset_table[row_idx, col2_idx]
            
            group1_total <- sum(subset_table[, col1_idx])
            group2_total <- sum(subset_table[, col2_idx])
            
            group1_pct <- round(group1_count / group1_total * 100, 1)
            group2_pct <- round(group2_count / group2_total * 100, 1)
            
            if(group1_pct > group2_pct) {
              paste0(group1, " higher 35+ hours (", group1_pct, "% vs ", group2_pct, "%)")
            } else if(group2_pct > group1_pct) {
              paste0(group2, " higher 35+ hours (", group2_pct, "% vs ", group1_pct, "%)")
            } else {
              paste0("Similar 35+ hours (", group1_pct, "% vs ", group2_pct, "%)")
            }
          } else {
            "Cannot calculate - missing categories"
          }
        }, error = function(e) {
          "Error in calculation"
        })
        
        pairwise_results_hours[[i]] <- data.frame(
          Comparison = paste(group1, "vs", group2),
          p_value = pairwise_fisher$p.value,
          cramers_v = round(pairwise_cramers, 3),
          hours_35plus_direction = direction,
          stringsAsFactors = FALSE
        )
      }
    }
    
    # Combine results and apply Bonferroni correction
    if(length(pairwise_results_hours) > 0) {
      pairwise_df_hours <- do.call(rbind, pairwise_results_hours)
      pairwise_df_hours$p_adjusted = p.adjust(pairwise_df_hours$p_value, method = "bonferroni")
      pairwise_df_hours$significant_adjusted = pairwise_df_hours$p_adjusted < 0.05
      
      # Add effect size interpretation
      pairwise_df_hours$effect_size = case_when(
        pairwise_df_hours$cramers_v < 0.1 ~ "Negligible",
        pairwise_df_hours$cramers_v < 0.3 ~ "Small",
        pairwise_df_hours$cramers_v < 0.5 ~ "Medium", 
        TRUE ~ "Large"
      )
      
      # Round p-values for display
      pairwise_df_hours$p_value = round(pairwise_df_hours$p_value, 4)
      pairwise_df_hours$p_adjusted = round(pairwise_df_hours$p_adjusted, 4)
      
      # Reorder columns for better readability
      pairwise_df_hours <- pairwise_df_hours[, c("Comparison", "p_value", "p_adjusted", "significant_adjusted", 
                                               "cramers_v", "effect_size", "hours_35plus_direction")]
      
      print(pairwise_df_hours)
      
      # Highlight significant findings
      significant_pairs_hours <- pairwise_df_hours[pairwise_df_hours$significant_adjusted, ]
      if(nrow(significant_pairs_hours) > 0) {
        cat("\nSignificant pairwise differences (after Bonferroni correction):\n")
        for(i in 1:nrow(significant_pairs_hours)) {
          cat("•", significant_pairs_hours$Comparison[i], 
              "(p =", significant_pairs_hours$p_adjusted[i], 
              ", Cramér's V =", significant_pairs_hours$cramers_v[i], ")\n")
          cat("  Direction:", significant_pairs_hours$hours_35plus_direction[i], "\n")
        }
      } else {
        cat("\nNo significant pairwise differences after Bonferroni correction.\n")
      }
    }
    
  } else {
    cat("→ Only 2 categories in each variable - no post-hoc tests needed\n")
  }
} else {
  cat("→ Overall association not significant - post-hoc tests not recommended\n")
}
```

The work conditions analysis reveals varying degrees of job security and workplace protections among outsourced workers. **Hour guarantees show moderate security**, with 53.6% having 35+ hour contracts, though 6.0% work zero-hours contracts and 23.9% have part-time guarantees (1-24 hours). **Income disparities are stark in hour guarantees**: low-income workers face zero-hours contracts at triple the rate (12.0%) compared to high-income (3.7%) and mid-income workers (4.3%), while only 15.8% of low-income workers have 35+ hour guarantees versus 64.5% of high-income workers.

**Scheduling predictability presents challenges**, with 40.3% of workers receiving less than one week's notice of working hours, while 28.7% receive one week or more notice. **Shift cancellations affect a significant minority**, with 22.4% experiencing cancelled shifts. **Compensation for cancelled shifts shows concerning patterns**: among those experiencing cancellations, 22.6% receive no pay, 45.3% receive partial compensation (1-49%), and only 32.2% receive most or full pay (50-100%).

**Sick pay provision is mixed**, with half (50.6%) receiving full usual pay when sick, but 14.5% having no sick pay access and 13.8% limited to statutory minimum (£116.75/week). **Uncertainty about entitlements** affects 6.3% who don't know their sick pay rights.

**The overall pattern suggests a two-tier system** where higher-income outsourced workers enjoy more stable conditions (guaranteed hours, better scheduling predictability) while lower-income workers face greater insecurity through zero-hours contracts and unpredictable scheduling. This stratification within outsourced work creates differential vulnerabilities across income groups.

## Rights Violations

This analysis examines reported workplace rights violations among outsourced workers, focusing on the prevalence and nature of violations across different categories. The analysis employs descriptive statistics to document the frequency of various rights violations and explores demographic correlates of violation experiences. Cross-tabulations with key variables (income group, ethnicity, employment type) are conducted to identify vulnerable populations, with statistical significance assessed through appropriate tests and effect sizes calculated where applicable.

```{r rights-violations-setup}
#| fig-width: 10
#| fig-height: 6
#| out-width: "100%"
#| dpi: 300

# Create mapping of rights violations variables to readable labels
rights_violations_mapping <- data.frame(
  Label = c(
    "Not being paid on time",
    "Not being paid the full amount I am entitled to for the work I have completed", 
    "Not being given time off that I am entitled to",
    "Not being paid for paid leave that I am entitled to",
    "Not being given pay that I am entitled to while being off sick",
    "Not being provided with a pay slip",
    "Not having adequate health and safety protections"
  ),
  Variable = c(
    "RightsViolations_Paid_On_Time",
    "RightsViolations_Paid_Correct_Amount", 
    "RightsViolations_Leave_Entitlement",
    "RightsViolations_Holiday_Pay",
    "RightsViolations_Sick_Pay", 
    "RightsViolations_Pay_Slip",
    "RightsViolations_Health_Safety"
  )
)

# Define rights variables for analysis
rights_vars <- rights_violations_mapping$Variable

# Count responses for each rights violation (excluding NAs)
rights_violations_counts <- data.frame(
  Label = character(0),
  Count = numeric(0),
  Percentage = numeric(0)
)

for(i in 1:nrow(rights_violations_mapping)) {
  var_name <- rights_violations_mapping$Variable[i]
  label_text <- rights_violations_mapping$Label[i]
  
  # Count non-NA responses (people who experienced this violation)
  count <- sum(!is.na(experiential_data[[var_name]]))
  total_responses <- nrow(experiential_data)
  percentage <- round(count / total_responses * 100, 0)  # Round to whole numbers like reference
  
  rights_violations_counts <- rbind(rights_violations_counts, data.frame(
    Label = label_text,
    Count = count,
    Percentage = percentage
  ))
}

# Sort by percentage (descending order)
rights_violations_counts <- rights_violations_counts[order(rights_violations_counts$Percentage, decreasing = TRUE), ]

# Create the horizontal bar chart
rights_violations_plot <- ggplot(rights_violations_counts, aes(x = Percentage, y = reorder(Label, Percentage))) +
  geom_col(fill = "#8B4A6B", alpha = 0.9) +  # Dark purple/maroon color like reference
  geom_text(aes(label = paste0(Percentage, "%")), 
            hjust = -0.05, size = 3.5, color = "white", fontface = "bold") +
  labs(
    title = "Proportion of outsourced workers who report having\ngone without key entitlements",
    subtitle = "\"Some workers don't receive everything that they are entitled to from their\nemployer. In your current role, have you experienced any of the following –\nplease tick all that apply.\"",
    x = "Percentage of outsourced workers",
    y = ""
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", margin = margin(b = 10)),
    plot.subtitle = element_text(size = 11, color = "gray40", margin = margin(b = 20)),
    axis.text.y = element_text(size = 10),
    axis.title.x = element_text(size = 11),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.x = element_line(color = "gray90", size = 0.5)
  ) +
  scale_x_continuous(labels = function(x) paste0(x, "%"), 
                     breaks = seq(0, 60, 10), 
                     expand = expansion(mult = c(0, 0.1))) +
  coord_cartesian(xlim = c(0, max(rights_violations_counts$Percentage) + 5))

rights_violations_plot

# Create summary table
rights_violations_table <- rights_violations_counts %>%
  flextable() %>%
  set_header_labels(
    Label = "Rights Violation",
    Count = "Count",
    Percentage = "Percentage (%)"
  ) %>%
  theme_vanilla() %>%
  autofit()

rights_violations_table

# Create a custom function to recode experiences
# Regular rights violations are coded as -1 (negative)
# "None" responses are coded as +1 (positive)
# NA values coded as 0 (not experienced)
recode_rights_experiences <- function(x, is_none_column = FALSE) {
  if (is_none_column) {
    # For RightsViolations_None column
    case_when(
      is.na(x) ~ 0,          # NA means not answered
      TRUE ~ 1               # "None" response is positive (+1)
    )
  } else {
    # For all other rights columns
    case_when(
      is.na(x) ~ 0,          # NA means not experienced (0)
      TRUE ~ -1              # Any non-NA value means negative experience (-1)
    )
  }
}

# Process the data - create numeric columns for rights variables
rights_experiential_data <- experiential_data %>%
  # Recode regular rights violations
  mutate(across(starts_with("Rights") & !contains("None"), 
                ~ recode_rights_experiences(as.character(.)),
                .names = "{.col}_numeric")) %>%
  # Special handling for None column
  mutate(RightsViolations_None_numeric = 
           recode_rights_experiences(RightsViolations_None, is_none_column = TRUE)) %>%
  # Select both original and numeric columns plus demographic variables
  dplyr::select(
    starts_with("Rights"),
    contains("_numeric"),
    Sex, Age, Ethnicity, Ethnicity_Collapsed, Region, Education_Band,
    OutsourcedNonOL, BORNUK
  )

rights_summary <- rights_experiential_data %>%
  # Select only the rights violation numeric columns (7 variables only)
  dplyr::select(RightsViolations_Paid_On_Time_numeric,
                RightsViolations_Paid_Correct_Amount_numeric,
                RightsViolations_Leave_Entitlement_numeric,
                RightsViolations_Holiday_Pay_numeric,
                RightsViolations_Sick_Pay_numeric,
                RightsViolations_Pay_Slip_numeric,
                RightsViolations_Health_Safety_numeric) %>% 
  # Remove rows where all rights variables are NA
  filter(rowSums(is.na(.)) < ncol(.)) %>%
  # Count negative responses per person
  mutate(
    num_neg = rowSums(. == -1, na.rm = TRUE)
  ) %>%
  # Categorise by number of negative experiences
  mutate(neg_category = case_when(
    num_neg == 0 ~ "0",
    num_neg == 1 ~ "1",
    num_neg == 2 ~ "2",
    num_neg == 3 ~ "3",
    num_neg == 4 ~ "4",
    num_neg >= 5 ~ "5+"
  )) %>%
  # Count respondents in each category and calculate percentages
  count(neg_category) %>%
  mutate(percent = (n / sum(n)) * 100)

# Visualise the distribution of negative rights experiences
ggplot(rights_summary, aes(x = neg_category, y = percent, fill = neg_category)) +
  geom_bar(stat = "identity", alpha = 0.8) +
  geom_text(aes(label = paste0(round(percent, 1), "%")), vjust = -0.5) +
  labs(title = "Distribution of Negative Responses on Rights",
       x = "Number of Negative Responses (-1s)",
       y = "Percentage of Respondents") +
  scale_fill_brewer(palette = "Reds") +
  theme_minimal()
```

The rights violations analysis reveals that **nearly half of outsourced workers experience at least one workplace rights violation**, with 56.3% reporting no violations. **Leave entitlement issues** are the most prevalent violation (11.2%), followed closely by **payment timing problems** (11.0%) and **sick pay violations** (10.9%). **Health and safety protections** are inadequate for 9.8% of workers, while **pay slip provision** (9.0%) and **correct payment amounts** (9.2%) also represent concerns.

## Discrimination Analysis

This analysis examines reported experiences of discrimination among outsourced workers across multiple dimensions including age, disability, ethnicity, nationality, religion, and sex. The analysis employs descriptive statistics to document the prevalence of different types of discrimination and conducts cross-tabulations with demographic variables to identify patterns and vulnerable populations. Statistical tests assess the significance of observed associations, with particular attention to intersectional effects where multiple forms of discrimination may compound disadvantage among specific groups.

```{r discrimination-function-setup}
# Define the valid discrimination response categories
valid_discrimination_responses <- c("Never", "Rarely", "Sometimes", "Often")

# Define demographic groups structure (reusable across all discrimination variables)
demographic_groups <- list(
  list(var = NULL, value = NULL, name = "All outsourced workers"),
  list(var = "Ethnicity_Collapsed", value = "Black/African/Caribbean/Black British", name = "Black workers"),
  list(var = "Ethnicity_Collapsed", value = "Asian/Asian British", name = "Asian workers"), 
  list(var = "Sex", value = "Female", name = "Female workers"),
  list(var = "BORNUK_binary", value = "Not born in UK", name = "Workers born outside of the UK")
)

# Create master function for discrimination analysis
create_discrimination_analysis <- function(discrimination_var, discrimination_type, data, demographic_groups) {
  cat("\n=== ", toupper(discrimination_type), " DISCRIMINATION ANALYSIS ===\n")
  # Check data availability first
  total_responses <- sum(!is.na(experiential_data[[discrimination_var]]) & 
                        experiential_data[[discrimination_var]] %in% valid_discrimination_responses)
  
  cat("Total valid responses for", discrimination_var, ":", total_responses, "\n")
  
  # Only proceed if we have sufficient data
  if (total_responses < 10) {
    cat("Insufficient data for", discrimination_type, "discrimination analysis (< 10 responses)\n")
    return(NULL)
  }
  
  # Helper function to calculate discrimination percentages by demographic group  
  calculate_discrimination_by_group <- function(data, group_var, group_value = NULL, group_name, discrim_var) {
    
    # Filter data based on group
    if (!is.null(group_var)) {
      filtered_data <- data %>% filter(!!sym(group_var) == group_value)
    } else {
      filtered_data <- data  # For "All outsourced workers"
    }
    
    # Calculate percentages for each discrimination response
    discrimination_counts <- filtered_data %>%
      filter(!!sym(discrim_var) %in% valid_discrimination_responses) %>%
      count(!!sym(discrim_var)) %>%
      mutate(
        Group = group_name,
        Total = sum(n),
        Percentage = round((n / Total) * 100, 0)
      ) %>%
      rename(Response = !!sym(discrim_var))
    
    return(discrimination_counts)
  }
  
  # Calculate discrimination percentages for each demographic group
  discrimination_results <- bind_rows(
    lapply(demographic_groups, function(group) {
      calculate_discrimination_by_group(data, group$var, group$value, group$name, discrimination_var)
    })
  )
  
  # Remove groups with no data
  discrimination_results <- discrimination_results %>% filter(Total > 0)
  
  if (nrow(discrimination_results) == 0) {
    cat("No valid data found for", discrimination_type, "discrimination analysis\n")
    return(NULL)
  }
  
  # Ensure proper ordering of response categories
  discrimination_results$Response <- factor(discrimination_results$Response, 
                                          levels = c("Never", "Rarely", "Sometimes", "Often"))
  
  # Create color palette for response categories (light to dark)
  response_colors <- c("Never" = "#E8F4F8", "Rarely" = "#9ECAE1", "Sometimes" = "#4292C6", "Often" = "#084594")
  
  # Create the faceted horizontal bar chart
  discrimination_plot <- ggplot(discrimination_results, aes(x = Percentage, y = Response, fill = Response)) +
    geom_col(alpha = 0.8) +
    geom_text(aes(label = paste0(Percentage, "%")), 
              hjust = -0.1, size = 3, color = "black") +
    facet_wrap(~ Group, ncol = 2, scales = "free_x") +
    scale_fill_manual(values = response_colors) +
    labs(
      title = paste("Experiences of", discrimination_type, "discrimination from in-house workers"),
      subtitle = "Percentage of workers reporting each level of discrimination experience",
      x = "Percentage of workers",
      y = "Discrimination experience"
    ) +
    theme_minimal() +
    theme(
      plot.title = element_text(size = 14, face = "bold", margin = margin(b = 5)),
      plot.subtitle = element_text(size = 11, color = "gray40", margin = margin(b = 15)),
      strip.text = element_text(size = 10, face = "bold"),
      axis.text.y = element_text(size = 9),
      axis.title = element_text(size = 10),
      legend.position = "none",
      panel.grid.major.y = element_blank(),
      panel.grid.minor = element_blank(),
      panel.grid.major.x = element_line(color = "gray90", size = 0.3)
    ) +
    scale_x_continuous(expand = expansion(mult = c(0, 0.15)))
  
  print(discrimination_plot)
  
  # Create summary table
  discrimination_table <- discrimination_results %>%
    dplyr::select(Group, Response, n, Percentage) %>%
    rename(
      "Demographic Group" = Group,
      "Response Category" = Response,
      "Count" = n,
      "Percentage (%)" = Percentage
    ) %>%
    flextable() %>%
    add_header_lines(paste(toupper(discrimination_type), "DISCRIMINATION SUMMARY")) %>%
    theme_vanilla() %>%
    autofit()
  
  #print(discrimination_table)
  
  # Return results for potential further analysis
  return(list(
    plot = discrimination_plot,
    table = discrimination_table,
    data = discrimination_results
  ))
}
```

```{r discrimination-variables-config}
# Define discrimination variables to analyze
discrimination_vars <- list(
  list(var = "Inhouse_Discrimination_Sex", type = "sex-based"),
  list(var = "Inhouse_Discrimination_Ethnicity", type = "ethnicity-based"),
  list(var = "Inhouse_Discrimination_Age", type = "age-based"),
  list(var = "Inhouse_Discrimination_Disability", type = "disability-based"),
  list(var = "Inhouse_Discrimination_Nationality", type = "nationality-based")
)
```

### Sex-based Discrimination

```{r discrimination-sex-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Run sex-based discrimination analysis
sex_discrimination_result <- create_discrimination_analysis(
  discrimination_var = "Inhouse_Discrimination_Sex",
  discrimination_type = "sex-based",
  data = experiential_data,
  demographic_groups = demographic_groups
)
```

The sex-based discrimination analysis reveals significant variation in discrimination experiences across demographic groups, with **Black workers** reporting the highest rates of sex-based discrimination (42.9% experienced discrimination), followed by **workers born outside the UK** (41.9%). **Asian workers** also face elevated rates (38.2%), while **female workers** report discrimination at 31.3%. The overall rate among all outsourced workers is 30.8%. Notably, **Black workers** show the lowest percentage reporting "Never" experiencing discrimination (57%), compared to the overall average of 69%, suggesting more pervasive experiences of sex-based discrimination within this group. The pattern indicates that **ethnicity and migration status intersect with gender** to create heightened vulnerability to discriminatory treatment.

### Ethnicity-based Discrimination

```{r discrimination-ethnicity-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Run ethnicity-based discrimination analysis
ethnicity_discrimination_result <- create_discrimination_analysis(
  discrimination_var = "Inhouse_Discrimination_Ethnicity",
  discrimination_type = "ethnicity-based",
  data = experiential_data,
  demographic_groups = demographic_groups
)
```

The ethnicity-based discrimination analysis reveals **the highest discrimination rates** among all forms examined, with **Black workers** and **workers born outside the UK** both experiencing discrimination at 52.5% and 52.3% respectively. **Asian workers** also face substantial discrimination (45.6%), while the overall rate among all outsourced workers is 30.0%. The data shows particularly concerning patterns for **Black workers**, with only 48% reporting "Never" experiencing ethnicity-based discrimination, compared to 70% overall. Similarly, **workers born outside the UK** show only 48% reporting "Never" experiencing discrimination. Notably, **Black workers** report the highest rates of frequent discrimination, with 24% experiencing it "Sometimes" and 10% "Often". This pattern suggests that **ethnicity-based discrimination is the most pervasive form of discrimination** faced by outsourced workers, with **Black workers and migrants** bearing the heaviest burden.

### Age-based Discrimination

```{r discrimination-age-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Run age-based discrimination analysis
age_discrimination_result <- create_discrimination_analysis(
  discrimination_var = "Inhouse_Discrimination_Age",
  discrimination_type = "age-based",
  data = experiential_data,
  demographic_groups = demographic_groups
)
```

The age-based discrimination analysis shows **moderate discrimination rates** across demographic groups, with **Black workers** experiencing the highest rates (44.9%), followed by **workers born outside the UK** (44.1%). **Asian workers** report discrimination at 35.8%, while the overall rate among all outsourced workers is 35.2%. **Female workers** experience age-based discrimination at 34.6%. The data reveals that **Black workers** have the lowest percentage reporting "Never" experiencing discrimination (55%), compared to 65% overall. **Workers born outside the UK** also show elevated vulnerability with 56% reporting "Never" experiencing discrimination. Age-based discrimination appears to be **the second most common form of discrimination** after ethnicity-based discrimination, with **Black workers and migrants** again showing heightened exposure to discriminatory treatment.

### Disability-based Discrimination

```{r discrimination-disability-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Run disability-based discrimination analysis
disability_discrimination_result <- create_discrimination_analysis(
  discrimination_var = "Inhouse_Discrimination_Disability",
  discrimination_type = "disability-based",
  data = experiential_data,
  demographic_groups = demographic_groups
)
```

The disability-based discrimination analysis shows **lower overall discrimination rates** compared to other forms, with **workers born outside the UK** experiencing the highest rates (31.9%), followed by **Asian workers** (27.5%) and **Black workers** (25.1%). The overall rate among all outsourced workers is 22.5%, while **female workers** report the lowest rate at 20.0%. The data shows that **workers born outside the UK** have the lowest percentage reporting "Never" experiencing discrimination (68%), compared to 77% overall. Notably, **Asian workers** show relatively high rates of frequent discrimination, with 14% experiencing it "Sometimes" and 6% "Often". While disability-based discrimination is **the least prevalent form** among those examined, it still affects **nearly one in four outsourced workers overall**, with **migrant workers** showing particular vulnerability.

### Nationality-based Discrimination

```{r discrimination-nationality-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Run nationality-based discrimination analysis
nationality_discrimination_result <- create_discrimination_analysis(
  discrimination_var = "Inhouse_Discrimination_Nationality",
  discrimination_type = "nationality-based",
  data = experiential_data,
  demographic_groups = demographic_groups
)
```

The nationality-based discrimination analysis reveals **high discrimination rates** that mirror the ethnicity-based patterns, with **Black workers** and **workers born outside the UK** both experiencing discrimination at 52.5% and 52.4% respectively. **Asian workers** face substantial discrimination at 43.1%, while the overall rate among all outsourced workers is 31.0%. **Female workers** report discrimination at 28.7%. The data shows that **Black workers** and **workers born outside the UK** both have only 48% reporting "Never" experiencing discrimination, compared to 69% overall. **Black workers** and **workers born outside the UK** also show the highest rates of frequent discrimination, with **Black workers** experiencing it "Sometimes" (24%) and "Often" (7%), while **workers born outside the UK** report similar patterns (21% "Sometimes", 8% "Often"). The pattern confirms that **nationality-based discrimination closely parallels ethnicity-based discrimination**, suggesting these forms of discrimination are **interconnected and particularly target migrant and ethnic minority workers**.

## Clarity Questions Analysis

We also explored workplace clarity among outsourced workers across eleven key dimensions including clarity about reporting structures for pay problems, rights and entitlements, time-off approval processes, promotion pathways, and role responsibilities. The analysis also assesses communication effectiveness between organisations, workers' confidence in raising workplace improvements, and management responsiveness to discrimination, bullying, and racism complaints. Descriptive statistics and cross-tabulations with demographic variables identify patterns in workplace clarity and potential disparities in organisational transparency across different groups of outsourced workers.

```{r clarity-questions-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300

# Define the clarity questions with their descriptions
clarity_questions <- data.frame(
  Variable = paste0("Clarity", 1:11),
  Question = c(
    "Clear about who to speak to about pay problems",
    "Clear about who to speak to about other rights/entitlements", 
    "Straightforward to understand who approves time off",
    "Clear about who to speak to about promotion",
    "Clear communication between organisations",
    "Clear about role responsibilities",
    "Confident can communicate improvements to right people",
    "Confident opinion will be respected about improvements",
    "Management prevents discrimination",
    "Management takes bullying complaints seriously",
    "Management takes racism complaints seriously"
  ),
  stringsAsFactors = FALSE
)

# Prepare data for visualisation - convert to long format
clarity_long <- experiential_data %>%
  dplyr::select(all_of(paste0("Clarity", 1:11))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "Variable",
    values_to = "Response"
  ) %>%
  filter(!is.na(Response)) %>%
  left_join(clarity_questions, by = "Variable") %>%
  mutate(
    # Ensure consistent response order
    Response = factor(Response, levels = c(
      "Strongly disagree", "Somewhat disagree", "Neither agree nor disagree", 
      "Somewhat agree", "Strongly agree"
    )),
    # Create shorter question labels for plotting
    Question_Short = case_when(
      Variable == "Clarity1" ~ "Pay problems contact",
      Variable == "Clarity2" ~ "Rights/entitlements contact", 
      Variable == "Clarity3" ~ "Time off approval",
      Variable == "Clarity4" ~ "Promotion contact",
      Variable == "Clarity5" ~ "Organisational communication",
      Variable == "Clarity6" ~ "Role responsibilities",
      Variable == "Clarity7" ~ "Can suggest improvements",
      Variable == "Clarity8" ~ "Opinion will be respected",
      Variable == "Clarity9" ~ "Management prevents discrimination",
      Variable == "Clarity10" ~ "Management handles bullying",
      Variable == "Clarity11" ~ "Management handles racism"
    )
  )

# Calculate percentages for each question and response
clarity_summary <- clarity_long %>%
  group_by(Question_Short, Response) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(Question_Short) %>%
  mutate(
    total = sum(count),
    percentage = round(count / total * 100, 1)
  ) %>%
  ungroup()

# Create horizontal bar chart
clarity_plot <- ggplot(clarity_summary, aes(x = percentage, y = reorder(Question_Short, desc(Question_Short)), fill = Response)) +
  geom_col(position = "stack", width = 0.7) +
  scale_fill_manual(
    values = c(
      "Strongly disagree" = "#d73027",
      "Somewhat disagree" = "#fc8d59", 
      "Neither agree nor disagree" = "#fee08b",
      "Somewhat agree" = "#91bfdb",
      "Strongly agree" = "#4575b4"
    ),
    name = "Response"
  ) +
  labs(
    title = "Clarity and Confidence at Work: Response Distribution",
    subtitle = "How clearly do outsourced workers understand workplace processes and feel confident about communication?",
    x = "Percentage",
    y = "Question Areas",
    caption = "Data: JRF Experiential Survey"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  ) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE))

print(clarity_plot)

# Create summary table
clarity_table <- clarity_long %>%
  group_by(Question_Short) %>%
  summarise(
    Total_Responses = n(),
    `Strongly Agree %` = round(mean(Response == "Strongly agree", na.rm = TRUE) * 100, 1),
    `Somewhat Agree %` = round(mean(Response == "Somewhat agree", na.rm = TRUE) * 100, 1),
    `Neither %` = round(mean(Response == "Neither agree nor disagree", na.rm = TRUE) * 100, 1),
    `Somewhat Disagree %` = round(mean(Response == "Somewhat disagree", na.rm = TRUE) * 100, 1),
    `Strongly Disagree %` = round(mean(Response == "Strongly disagree", na.rm = TRUE) * 100, 1),
    .groups = "drop"
  ) %>%
  arrange(desc(`Strongly Agree %`))

clarity_table_formatted <- clarity_table %>%
  flextable() %>%
  set_header_labels(
    Question_Short = "Question Area",
    Total_Responses = "Total Responses",
    `Strongly Agree %` = "Strongly Agree (%)",
    `Somewhat Agree %` = "Somewhat Agree (%)",
    `Neither %` = "Neither (%)",
    `Somewhat Disagree %` = "Somewhat Disagree (%)",
    `Strongly Disagree %` = "Strongly Disagree (%)"
  ) %>%
  theme_vanilla() %>%
  autofit()

cat("\nClarity Questions Summary Table:\n")
clarity_table_formatted

## CLARITY BY INCOME GROUP ANALYSIS

cat("\n=== CLARITY QUESTIONS BY INCOME GROUP ===\n")

# Prepare data with income group information
clarity_income_long <- experiential_data_no_income_outliers %>%
  dplyr::filter(!is.na(income_group)) %>%
  dplyr::select(all_of(paste0("Clarity", 1:11)), income_group) %>%
  pivot_longer(
    cols = starts_with("Clarity"),
    names_to = "Variable",
    values_to = "Response"
  ) %>%
  filter(!is.na(Response)) %>%
  left_join(clarity_questions, by = "Variable") %>%
  mutate(
    Response = factor(Response, levels = c(
      "Strongly disagree", "Somewhat disagree", "Neither agree nor disagree", 
      "Somewhat agree", "Strongly agree"
    )),
    Question_Short = case_when(
      Variable == "Clarity1" ~ "Pay problems contact",
      Variable == "Clarity2" ~ "Rights/entitlements contact", 
      Variable == "Clarity3" ~ "Time off approval",
      Variable == "Clarity4" ~ "Promotion contact",
      Variable == "Clarity5" ~ "Organisational communication",
      Variable == "Clarity6" ~ "Role responsibilities",
      Variable == "Clarity7" ~ "Can suggest improvements",
      Variable == "Clarity8" ~ "Opinion will be respected",
      Variable == "Clarity9" ~ "Management prevents discrimination",
      Variable == "Clarity10" ~ "Management handles bullying",
      Variable == "Clarity11" ~ "Management handles racism"
    )
  )

# Calculate percentages by income group for selected key questions
key_clarity_questions <- c("Clarity1", "Clarity2", "Clarity3", "Clarity4", "Clarity5",
                           "Clarity6", "Clarity7", "Clarity8","Clarity9", "Clarity10", "Clarity11")
key_question_labels <- c(
  "Clarity1" = "Pay problems contact",
  "Clarity2" = "Rights/entitlements contact", 
  "Clarity3" ~ "Time off approval",
  "Clarity4" = "Promotion contact",
  "Clarity5" ~ "Organizational communication",
  "Clarity6" ~ "Role responsibilities",
  "Clarity7" = "Can suggest improvements",
  "Clarity8" = "Opinion will be respected",
  "Clarity9" ~ "Management prevents discrimination",
  "Clarity10" ~ "Management handles bullying",
  "Clarity11" ~ "Management handles racism"
)



clarity_income_summary <- clarity_income_long %>%
  dplyr::filter(Variable %in% key_clarity_questions) %>%
  group_by(income_group, Question_Short, Response) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(income_group, Question_Short) %>%
  mutate(
    total = sum(count),
    percentage = round(count / total * 100, 1)
  ) %>%
  ungroup()

# Create faceted plot by income group
clarity_income_plot <- ggplot(clarity_income_summary, aes(x = percentage, y = income_group, fill = Response)) +
  geom_col(position = "stack", width = 0.7) +
  facet_wrap(~Question_Short, ncol = 2, scales = "free_x") +
  scale_fill_manual(
    values = c(
      "Strongly disagree" = "#d73027",
      "Somewhat disagree" = "#fc8d59", 
      "Neither agree nor disagree" = "#fee08b",
      "Somewhat agree" = "#91bfdb",
      "Strongly agree" = "#4575b4"
    ),
    name = "Response"
  ) +
  labs(
    title = "Workplace Clarity by Income Group",
    subtitle = "Key clarity questions showing differences across income levels",
    x = "Percentage",
    y = "Income Group",
    caption = "Data: JRF Experiential Survey (excluding income outliers)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 9),
    legend.title = element_text(size = 10, face = "bold"),
    legend.text = element_text(size = 9),
    strip.text = element_text(size = 10, face = "bold"),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    legend.position = "bottom"
  ) +
  guides(fill = guide_legend(nrow = 2, byrow = TRUE))

print(clarity_income_plot)

# Create summary comparison table
clarity_by_income_comparison <- clarity_income_long %>%
  filter(Variable %in% key_clarity_questions) %>%
  group_by(income_group, Question_Short) %>%
  summarise(
    Total_Responses = n(),
    `Agree %` = round(mean(Response %in% c("Strongly agree", "Somewhat agree"), na.rm = TRUE) * 100, 1),
    `Disagree %` = round(mean(Response %in% c("Strongly disagree", "Somewhat disagree"), na.rm = TRUE) * 100, 1),
    `Neither %` = round(mean(Response == "Neither agree nor disagree", na.rm = TRUE) * 100, 1),
    .groups = "drop"
  ) %>%
  arrange(Question_Short, desc(`Agree %`))

clarity_income_table <- clarity_by_income_comparison %>%
  flextable() %>%
  set_header_labels(
    income_group = "Income Group",
    Question_Short = "Question Area",
    Total_Responses = "Total",
    `Agree %` = "Agree (%)",
    `Disagree %` = "Disagree (%)",
    `Neither %` = "Neither (%)"
  ) %>%
  theme_vanilla() %>%
  autofit()

cat("\nClarity by Income Group Summary:\n")
clarity_income_table

## Clarity regression
Clarity.fit1<- (lm(Clarity_Overall_Mean ~ 
                     Age +
                     Sex +
                     Ethnicity_Collapsed +
                     BORNUK_binary +
                     Region +
                     income_group, weights = Outsourced, experiential_data_no_income_outliers)) 

#summary(Clarity.fit1) # some significant

## CLARITY REGRESSION RESULTS VISUALIsATION

# Load broom for tidy regression results
library(broom)

# Extract regression results
clarity_results <- tidy(Clarity.fit1, conf.int = TRUE) %>%
  filter(term != "(Intercept)") %>%
  mutate(
    # Create clean variable labels for non-technical audience
    Variable_Clean = case_when(
      term == "Age" ~ "Age (per year)",
      term == "SexFemale" ~ "Female (vs Male)",
      term == "Ethnicity_CollapsedAsian/Asian British" ~ "Asian/Asian British (vs White British)",
      term == "Ethnicity_CollapsedBlack/African/Caribbean/Black British" ~ "Black/African/Caribbean (vs White British)",
      term == "Ethnicity_CollapsedMixed/Multiple ethnic groups" ~ "Mixed/Multiple ethnicities (vs White British)",
      term == "Ethnicity_CollapsedWhite Other" ~ "White Other (vs White British)",
      term == "Ethnicity_CollapsedArab" ~ "Arab (vs White British)",
      term == "Ethnicity_CollapsedOther ethnic group" ~ "Other ethnic group (vs White British)",
      term == "BORNUK_binaryNot born in UK" ~ "Not born in UK (vs Born in UK)",
      term == "BORNUK_binaryPrefer not to say" ~ "Prefer not to say: Birth country",
      str_starts(term, "Region") ~ str_replace(term, "Region", "Region: "),
      term == "income_groupLow" ~ "Low income (vs Mid income)",
      term == "income_groupHigh" ~ "High income (vs Mid income)",
      TRUE ~ term
    ),
    # Create significance indicators
    Significance = case_when(
      p.value < 0.001 ~ "***",
      p.value < 0.01 ~ "**", 
      p.value < 0.05 ~ "*",
      TRUE ~ ""
    ),
    # Round estimates and confidence intervals
    estimate_round = round(estimate, 3),
    conf.low_round = round(conf.low, 3),
    conf.high_round = round(conf.high, 3)
  ) %>%
  arrange(desc(abs(estimate)))

# Create forest plot
forest_plot <- ggplot(clarity_results, aes(x = estimate, y = reorder(Variable_Clean, estimate))) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "gray50", alpha = 0.7) +
  geom_pointrange(
    aes(xmin = conf.low, xmax = conf.high),
    size = 0.8,
    color = "#2c3e50",
    fill = "#3498db",
    shape = 21,
    stroke = 0.5
  ) +
  geom_text(
    aes(x = conf.high + 0.02, label = paste0(estimate_round, Significance)),
    hjust = 0,
    size = 3,
    color = "#2c3e50"
  ) +
  labs(
    title = "Factors Associated with Workplace Clarity and Confidence",
    subtitle = "Regression coefficients showing how different factors relate to overall clarity scores",
    x = "Effect on Clarity Score (95% Confidence Interval)",
    y = "Factors",
    caption = "*** p<0.001, ** p<0.01, * p<0.05\nData: JRF Experiential Survey. Reference groups: Male, White British, Born in UK, Mid income, London region"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 11, color = "gray40"),
    axis.text.y = element_text(size = 10),
    axis.text.x = element_text(size = 9),
    panel.grid.major.x = element_line(color = "gray90", size = 0.3),
    panel.grid.minor.x = element_blank(),
    panel.grid.major.y = element_blank(),
    plot.caption = element_text(size = 8, color = "gray50", hjust = 0)
  )

print(forest_plot)

# Create summary table of key results
key_results <- clarity_results %>%
  filter(p.value < 0.05) %>%  # Only significant 
  dplyr::select(Variable_Clean, estimate_round, conf.low_round, conf.high_round, p.value, Significance) %>%
  arrange(p.value)

if(nrow(key_results) > 0) {
  key_results_table <- key_results %>%
    mutate(
      `P-value` = case_when(
        p.value < 0.001 ~ "<0.001",
        TRUE ~ as.character(round(p.value, 3))
      )
    ) %>%
   dplyr::select(-p.value) %>%
    flextable() %>%
    set_header_labels(
      Variable_Clean = "Factor",
      estimate_round = "Effect",
      conf.low_round = "95% CI Lower",
      conf.high_round = "95% CI Upper",
      Significance = "Sig.",
      `P-value` = "P-value"
    ) %>%
    theme_vanilla() %>%
    autofit()
  
  cat("\nStatistically Significant Results (p < 0.1):\n")
  key_results_table
} else {
  cat("\nNo statistically significant results found at p < 0.05 level.\n")
}
```

The clarity analysis reveals **significant variation in workplace transparency** across different domains and income groups. **Role responsibilities** show the highest clarity (77.5% agreement), followed by **time off approval** (72.8%) and **pay problems contact** (71.6%), indicating that basic operational processes are generally well-understood. However, areas requiring **higher-level organisational engagement** show concerning gaps: **opinion will be respected** (64.1%), **management prevents discrimination** (64.4%), and **promotion contact** (64.7%) have the lowest agreement rates.

**Income-based disparities** are particularly stark, with **high-income workers** consistently reporting greater clarity than **low-income workers** across all domains. The largest gaps appear in **management prevents discrimination** (18.5 percentage point difference), **opinion will be respected** (17.1 points), and **management handles bullying** (16.9 points). These patterns suggest that **organisational transparency and confidence in management responsiveness decrease substantially as income levels fall**, potentially reflecting **differential treatment** or **reduced organisational investment** in communication with lower-paid outsourced workers. The consistency of these income-based disparities across multiple domains points to **systemic inequalities** in workplace clarity rather than isolated communication issues.

## Work Preference by Income Group

Finally we examine the relationship between income levels and work preferences among outsourced workers, comparing preferences for in-house versus outsourced employment across low, mid, and high income groups. The analysis employs cross-tabulations and statistical tests to identify whether income level influences workers' preferences for employment arrangements, with particular attention to understanding how economic circumstances may shape attitudes toward outsourcing.

```{r work-preference-analysis}
#| fig-width: 12
#| fig-height: 8
#| out-width: "100%"
#| dpi: 300


# Create work preference by income group cross-tabulation
work_pref_crosstab <- crosstable(
  experiential_data_no_income_outliers %>% 
    dplyr::select(Work_Preference, income_group),
  by = income_group,
  total = "both",
  showNA = "no",
  percent_digits = 1,
  percent_pattern = "{n} ({p_col})"
) %>%
  as_flextable() %>%
  theme_vanilla() %>%
  set_header_labels(
    label = "Work Preference",
    Low = "Low Income",
    Mid = "Mid Income", 
    High = "High Income",
    Total = "Total"
  ) %>%
  autofit()

cat("Work Preference by Income Group Cross-tabulation:\n")
work_pref_crosstab

# Prepare data for visualisation
work_pref_data <- experiential_data_no_income_outliers %>%
  filter(!is.na(Work_Preference) & !is.na(income_group)) %>%
  count(income_group, Work_Preference) %>%
  group_by(income_group) %>%
  mutate(
    total = sum(n),
    percentage = round(n / total * 100, 1)
  ) %>%
  ungroup()

# Create stacked bar chart
work_pref_plot <- ggplot(work_pref_data, aes(x = percentage, y = income_group, fill = Work_Preference)) +
  geom_col(position = "stack", width = 0.7) +
  scale_fill_manual(
    values = c(
      "I would strongly prefer to be an in-house worker" = "#2166ac",
      "I would prefer to be an in-house worker" = "#4393c3", 
      "I have no preference" = "#cccccc",
      "Not sure" = "#999999",
      "I would prefer to be an outsourced worker" = "#fdbf6f",
      "I would strongly prefer to be an outsourced worker" = "#ff7f00"
    ),
    name = "Work Preference"
  ) +
  labs(
    title = "Work Preferences by Income Group",
    subtitle = "Percentage distribution within each income group",
    x = "Percentage (%)",
    y = "Income Group",
    caption = "Source: JRF Experiential Survey 2025"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 14, face = "bold", hjust = 0),
    plot.subtitle = element_text(size = 12, color = "gray60", hjust = 0),
    axis.title = element_text(size = 11, face = "bold"),
    axis.text = element_text(size = 10),
    legend.title = element_text(size = 11, face = "bold"),
    legend.text = element_text(size = 9),
    legend.position = "bottom",
    legend.key.size = unit(0.8, "lines"),
    panel.grid.major.y = element_blank(),
    panel.grid.minor = element_blank(),
    plot.caption = element_text(size = 9, color = "gray50", hjust = 1)
  ) +
  guides(fill = guide_legend(nrow = 3, byrow = TRUE)) +
  scale_x_continuous(labels = function(x) paste0(x, "%"), expand = c(0, 0))

# Display the plot
print(work_pref_plot)

# Statistical test for association
cat("\n=== Statistical Analysis: Work Preference by Income Group ===\n")

# Create contingency table for statistical testing
work_pref_table_test <- table(experiential_data_no_income_outliers$Work_Preference, experiential_data_no_income_outliers$income_group)

# Remove rows/columns with all zeros if any
work_pref_table_test <- work_pref_table_test[rowSums(work_pref_table_test) > 0, colSums(work_pref_table_test) > 0]

# Standardised Fisher's exact test function
format_fisher_test <- function(contingency_table, test_name = "Fisher's Exact Test") {
  
  # Determine if simulation is needed
  use_simulation <- nrow(contingency_table) > 2 || ncol(contingency_table) > 2
  
  # Perform Fisher's exact test
  if(use_simulation) {
    fisher_result <- fisher.test(contingency_table, simulate.p.value = TRUE, B = 10000)
    test_method <- "Fisher's Exact Test (simulated)"
    simulation_note <- "Monte Carlo simulation with 10,000 replicates"
  } else {
    fisher_result <- fisher.test(contingency_table)
    test_method <- "Fisher's Exact Test (exact)"
    simulation_note <- "Exact calculation"
  }
  
  # Format p-value
  p_formatted <- if(fisher_result$p.value < 0.001) {
    "< 0.001"
  } else {
    formatC(fisher_result$p.value, format = "f", digits = 3)
  }
  
  # Determine significance level
  significance <- case_when(
    fisher_result$p.value < 0.001 ~ "***",
    fisher_result$p.value < 0.01 ~ "**",
    fisher_result$p.value < 0.05 ~ "*",
    TRUE ~ ""
  )
  
  # Calculate effect size (Cramér's V)
  if(require(vcd, quietly = TRUE)) {
    assoc_stats <- vcd::assocstats(contingency_table)
    cramers_v <- round(assoc_stats$cramer, 3)
    
    # Interpret effect size
    effect_interpretation <- case_when(
      cramers_v < 0.1 ~ "Negligible",
      cramers_v < 0.3 ~ "Small",
      cramers_v < 0.5 ~ "Medium",
      TRUE ~ "Large"
    )
  } else {
    cramers_v <- NA
    effect_interpretation <- "Unable to calculate"
  }
  
  # Create results data frame
  results_df <- data.frame(
    Statistic = c("Test Method", "Sample Size", "P-value", "Significance", "Cramér's V", "Effect Size", "Method Details"),
    Value = c(
      test_method,
      as.character(sum(contingency_table)),
      p_formatted,
      significance,
      as.character(cramers_v),
      effect_interpretation,
      simulation_note
    ),
    stringsAsFactors = FALSE
  )
  
  # Create formatted table
  results_table <- results_df %>%
    flextable() %>%
    set_header_labels(
      Statistic = "Statistic",
      Value = "Value"
    ) %>%
    theme_vanilla() %>%
    width(j = 1, width = 2) %>%
    width(j = 2, width = 2.5) %>%
    align(align = "left", part = "all") %>%
    add_header_lines(paste("Statistical Test Results:", test_name)) %>%
    autofit()
  
  return(list(
    test_result = fisher_result,
    formatted_table = results_table,
    p_value = fisher_result$p.value,
    cramers_v = cramers_v,
    effect_interpretation = effect_interpretation
  ))
}

# Apply standardised Fisher's test
work_pref_fisher_results <- format_fisher_test(work_pref_table_test, "Work Preference by Income Group")

# Display results
work_pref_fisher_results$formatted_table

# Summary statistics
cat("\n=== Summary Statistics ===\n")
work_pref_summary <- experiential_data_no_income_outliers %>%
  filter(!is.na(Work_Preference) & !is.na(income_group)) %>%
  count(income_group, Work_Preference) %>%
  group_by(income_group) %>%
  mutate(
    total = sum(n),
    percentage = round(n / total * 100, 1)
  ) %>%
  ungroup()

# Print key findings
cat("Key findings:\n")
for(income_grp in c("Low", "Mid", "High")) {
  grp_data <- work_pref_summary %>% filter(income_group == income_grp)
  inhouse_total <- sum(grp_data$percentage[grepl("in-house", grp_data$Work_Preference)])
  outsourced_total <- sum(grp_data$percentage[grepl("outsourced", grp_data$Work_Preference)])
  
  cat(sprintf("- %s income: %.1f%% prefer in-house, %.1f%% prefer outsourced\n", 
              income_grp, inhouse_total, outsourced_total))
}

```

The work preference analysis reveals **clear patterns in employment arrangement preferences across income groups**, with **statistical significance** confirmed by Fisher's exact test (p \< 0.001, Cramér's V = 0.104, small effect size). **No preference** dominates across all income groups (approximately 41%), but meaningful differences emerge in definitive preferences and uncertainty levels.

**Income-based preference patterns** show that **higher-income workers increasingly prefer in-house employment**: low-income workers prefer in-house work at 27.4%, rising to 33.0% for mid-income and 35.2% for high-income workers. Conversely, **outsourced work preferences remain relatively stable** across income groups (14.8% to 17.8%), suggesting that **income level primarily influences attraction to in-house employment rather than satisfaction with outsourcing**.

The most striking pattern appears in **uncertainty levels**, where **low-income workers show dramatically higher "not sure" responses** (16.5%) compared to mid-income (8.4%) and high-income workers (5.4%). This **11.1 percentage point gap** between low and high-income groups suggests that **economic insecurity may contribute to greater uncertainty about employment preferences**, potentially reflecting **limited exposure to alternative employment arrangements** or **anxiety about job security** that makes definitive preferences more difficult to form. The consistent **2:1 ratio favoring in-house work** across all income groups indicates that while income influences preference strength, the fundamental appeal of in-house employment remains broadly consistent.


# Limitations and Future Research?

-   [ ] Discuss the limitations of the data and the analysis
-   [ ] If something is really burning we can suggest some further analysis that people can do

# Reproducibility {#reproducibility}

All analyses presented in this report can be fully reproduced using the code and data provided in the [Just Knowlegde GitHub repository.](https://github.com/JustKnowledge-UK/jrf_nat_rep/tree/main "GitHub")

------------------------------------------------------------------------

# Appendices

## Study 1 - Age

The table below shows weighted descriptive statistics of the sample, and the figure below shows the frequency of respondents at each single year of age.

```{r}
age_statistics %>%
  dplyr::select(contains('wtd')) %>%
  knitr::kable(
             digits = 2,
             col.names = c("Mean",
                           "Median",
                           "Min",
                           "Max",
                           "Standard dev.")) %>%
  kable_styling(full_width = F)

age_range <- max(data$Age) - min(data$Age)
interval <- 1
n_bins <- (age_range / interval) + 1

data %>%
  ggplot(.,aes(Age)) +
  geom_histogram(colour="black",alpha = .7, bins = n_bins) +
  geom_vline(data =age_statistics, aes(xintercept=median), colour="red") +
  scale_x_continuous(breaks = seq(16, 80, 4)) +
  theme_minimal() +
  scale_colour_manual(values=colours, name = "Outsourcing status") +
  scale_fill_manual(values=colours, name = "Outsourcing status") +
  ylab("Count")
  

```

## Study 1 - Gender

The table below shows the weighted gender breakdown of the sample

```{r}
gender_statistics %>%
  dplyr::select(-percentage) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum)) %>%
  kable(col.names = c(
    "Gender",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```

## Study 1 - Ethnicity {#sec-ethnicity}

The table below shows the weighted ethnicity breakdown using the full range of Census 2021 categories. Note that 'NA' indicates non-responses.

```{r}
ethnicity_statistics %>%
  dplyr::select(-percentage) %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum)) %>%
  kable(col.names = c(
    "Ethnicity",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```

We also make use of an aggregated ethnicity variable that groups ethnicities into fewer categories. The table below shows how the Census categories map onto the aggregated categories.

```{r}
ethnicity_cat <- data %>%
  dplyr::select(contains("ethnicity")) %>%
  distinct() %>%
  arrange(Ethnicity) %>%
  dplyr::select(-c(1:2,Ethnicity_collapsed_disaggregated, Ethnicity_binary))

write_csv(ethnicity_cat, file="../outputs/methodology/data/ethnicity_aggregation_mapping.csv")

ethn_colnames = c(
  "Census categories",
  "Aggregated categories"
)
ethnicity_cat %>%
  kable(col.names = ethn_colnames) %>%
  kable_styling(full_width=FALSE)
```

The table below shows the weighted ethnicity breakdown using the aggregated set of categories

```{r}
ethnicity_statistics_collapsed <- data %>%
  group_by(Ethnicity_collapsed) %>%
  summarise(
    n = n(), # count cases
    Frequency = sum(NatRepemployees) # count weighted cases
  ) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    Percentage = 100 * (Frequency / Sum),
    Ethnicity_short = Ethnicity_collapsed
  )

write_csv(ethnicity_statistics_collapsed, file="../outputs/methodology/data/ethnicity_statistics_aggregated.csv")

ethnicity_statistics_collapsed %>%
  mutate(across(where(is.numeric), ~ round(.x, 2))) %>%
  dplyr::select(-c(n, N, Sum, Ethnicity_short)) %>%
  kable(col.names = c(
    "Ethnicity",
    "Weighted frequency",
    "Weighted percentage"
  )) %>%
  kable_styling(full_width = F)
```

## Study 1 - Income by outsourcing and income group

```{r}
plot_income <- function(data, frequency = "weekly"){
  income_var <- case_when(frequency == "weekly" ~ "income_weekly_all",
                          frequency == "hourly" ~ "income_hourly_all",
                          TRUE ~ "income_annual_all"
  )
                          
  
  sector_summary_paysplit <- data %>%
  filter(income_drop_all == 0) %>%
  group_by(SectorName, SectorName_labelled, income_group, outsourcing_status) %>%
  drop_na(income_group) %>%
  summarise(
    n = n(),
    Frequency = sum(NatRepemployees),
    avg_income = mean(!!!rlang::syms(income_var), na.rm=T),
    wtd_avg_income = weighted.mean(!!!rlang::syms(income_var), w = NatRepemployees, na.rm=T)
  ) %>% 
  ungroup() %>%
  group_by(SectorName, income_group) %>%
  mutate(
    N = sum(n),
    Sum = sum(Frequency),
    perc = 100 * (Frequency/Sum),
    SectorName_labelled = case_when(SectorName_labelled == "NA" ~ NA,
                                    TRUE ~ SectorName_labelled),
    SectorName_short = SectorName_labelled
  ) %>%
  # make the sector names more readable
  separate_wider_delim(SectorName_short, names = c("SectorName_short", "SectorName_short_detail"), delim=";",
                       too_few = "align_start") %>%
  mutate(
    SectorName_short = factor(stringr::str_to_sentence(SectorName_short)),
    SectorName_short_detail = factor(stringr::str_to_sentence(SectorName_short_detail)),
  )
  
  plot_data <- sector_summary_paysplit %>%
    drop_na(SectorName_short) %>%
    droplevels() %>%
    ungroup()
  
    
  # Filter for 'outsourced' level and reorder SectorName_short
  not_outsourced_levels <- plot_data %>%
    filter(outsourcing_status == 'Not outsourced') %>%
    mutate(SectorName_short = forcats::fct_reorder(SectorName_short, perc, .desc = TRUE))
  
  # outsourced <- plot_data %>%
  #   filter(outsourcing_status == 'Outsourced') %>%
  #   mutate(
  #     rank = rank(desc(perc))
  #   )
  
  # Apply the reordered levels back to the original data - uses original orders for ease of comparison
  plot_data <- plot_data %>%
    mutate(
      SectorName_short = factor(SectorName_short, levels = levels(not_outsourced_levels$SectorName_short)),
           )
  
  annotation_df <- plot_data %>%
    #filter(outsourcing_status == "Not outsourced") %>%
    select(SectorName_short, n) %>%
    group_by(SectorName_short) %>%
    summarise(
      N = sum(n)
    ) %>%
      mutate(
      ypos = max(plot_data$wtd_avg_income, na.rm=T) * 1.2
    ) 


  plot_data %>%
    # mutate(
    #   SectorName = as.factor(SectorName)
    # ) %>%
    ggplot(., aes(wtd_avg_income,SectorName_short, size = perc, colour = outsourcing_status, shape = income_group)) +
      geom_point(position = "dodge") + 
    theme_minimal() +
    theme(legend.position = "bottom",
          legend.title = element_blank())+
        #coord_flip() +
    # scale_x_continuous(breaks=seq(0,max(plot_data$wtd_avg_income), 10000)) +
    scale_colour_manual(values=colours) +
    geom_text(inherit.aes=F,data=annotation_df, aes(x=ypos, y=SectorName_short, label = paste0("N = ", N)), hjust=1) +
    geom_text_repel(inherit.aes = F, aes(wtd_avg_income, SectorName_short, colour = outsourcing_status, label=paste0("n=",n)), size=2) +
    guides(size=FALSE) + # remove size legend as gauging size is difficult 
    xlab(paste0("Weighted average ", frequency, " income")) + ylab("Sector") +
    labs(caption = "Size of bubble represents the size of the respective workforce")
}
  
plot_income(data, "annual")
plot_income(data, "weekly")
plot_income(data, "hourly")
```

